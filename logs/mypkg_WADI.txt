2024-05-01 13:13:24.303148: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-05-01 13:13:24.303177: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-05-01 13:13:24.303182: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-05-01 13:13:24.307325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
{'dataset': 'mypkg_WADI', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'gru_n_layers': 1, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 30, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}
load data of: mypkg_WADI
train:  0 None
test:  0 None
Data normalized
Data normalized
train set shape:  (784571, 128)
test set shape:  (172801, 128)
test set label shape:  (172801,)
Will forecast and reconstruct all 128 input features
train_size: 706024
validation_size: 78447
test_size: 172701
Init total train loss: 0.887899
Init total val loss: 0.88816
Training model for 30 epochs..
[Epoch 1] forecast_loss = 0.10860, recon_loss = 0.08857, total_loss = 0.19718 ---- val_forecast_loss = 0.06194, val_recon_loss = 0.05673, val_total_loss = 0.11867 [664.5s]
[Epoch 2] forecast_loss = 0.07826, recon_loss = 0.05468, total_loss = 0.13294 ---- val_forecast_loss = 0.05424, val_recon_loss = 0.05107, val_total_loss = 0.10531 [666.8s]
[Epoch 3] forecast_loss = 0.07491, recon_loss = 0.04862, total_loss = 0.12353 ---- val_forecast_loss = 0.05244, val_recon_loss = 0.04615, val_total_loss = 0.09859 [666.6s]
[Epoch 4] forecast_loss = 0.07371, recon_loss = 0.04589, total_loss = 0.11960 ---- val_forecast_loss = 0.05074, val_recon_loss = 0.04452, val_total_loss = 0.09526 [667.1s]
[Epoch 5] forecast_loss = 0.07296, recon_loss = 0.04459, total_loss = 0.11756 ---- val_forecast_loss = 0.05002, val_recon_loss = 0.04259, val_total_loss = 0.09260 [667.0s]
[Epoch 6] forecast_loss = 0.07258, recon_loss = 0.04255, total_loss = 0.11513 ---- val_forecast_loss = 0.05110, val_recon_loss = 0.06312, val_total_loss = 0.11422 [664.3s]
[Epoch 7] forecast_loss = 0.07229, recon_loss = 0.04240, total_loss = 0.11469 ---- val_forecast_loss = 0.04895, val_recon_loss = 0.04076, val_total_loss = 0.08971 [664.8s]
[Epoch 8] forecast_loss = 0.07201, recon_loss = 0.04068, total_loss = 0.11269 ---- val_forecast_loss = 0.04909, val_recon_loss = 0.03920, val_total_loss = 0.08829 [664.0s]
[Epoch 9] forecast_loss = 0.07181, recon_loss = 0.03951, total_loss = 0.11132 ---- val_forecast_loss = 0.04840, val_recon_loss = 0.03871, val_total_loss = 0.08711 [663.8s]
[Epoch 10] forecast_loss = 0.07167, recon_loss = 0.03964, total_loss = 0.11131 ---- val_forecast_loss = 0.04819, val_recon_loss = 0.03802, val_total_loss = 0.08621 [663.8s]
[Epoch 11] forecast_loss = 0.07153, recon_loss = 0.04008, total_loss = 0.11162 ---- val_forecast_loss = 0.04791, val_recon_loss = 0.03783, val_total_loss = 0.08575 [663.7s]
[Epoch 12] forecast_loss = 0.07133, recon_loss = 0.03885, total_loss = 0.11018 ---- val_forecast_loss = 0.04841, val_recon_loss = 0.03757, val_total_loss = 0.08598 [662.7s]
[Epoch 13] forecast_loss = 0.07138, recon_loss = 0.03921, total_loss = 0.11059 ---- val_forecast_loss = 0.04770, val_recon_loss = 0.03677, val_total_loss = 0.08447 [661.3s]
[Epoch 14] forecast_loss = 0.07204, recon_loss = 0.05216, total_loss = 0.12421 ---- val_forecast_loss = 0.04841, val_recon_loss = 0.04843, val_total_loss = 0.09684 [655.7s]
[Epoch 15] forecast_loss = 0.07121, recon_loss = 0.04283, total_loss = 0.11404 ---- val_forecast_loss = 0.04776, val_recon_loss = 0.04289, val_total_loss = 0.09064 [657.2s]
[Epoch 16] forecast_loss = 0.07111, recon_loss = 0.04048, total_loss = 0.11160 ---- val_forecast_loss = 0.04722, val_recon_loss = 0.03917, val_total_loss = 0.08638 [656.3s]
[Epoch 17] forecast_loss = 0.07098, recon_loss = 0.03910, total_loss = 0.11008 ---- val_forecast_loss = 0.04722, val_recon_loss = 0.03796, val_total_loss = 0.08518 [655.1s]
[Epoch 18] forecast_loss = 0.07369, recon_loss = 0.04553, total_loss = 0.11922 ---- val_forecast_loss = 0.04798, val_recon_loss = 0.04061, val_total_loss = 0.08859 [654.2s]
[Epoch 19] forecast_loss = 0.07191, recon_loss = 0.04075, total_loss = 0.11266 ---- val_forecast_loss = 0.04779, val_recon_loss = 0.03883, val_total_loss = 0.08663 [653.9s]
[Epoch 20] forecast_loss = 0.07286, recon_loss = 0.05330, total_loss = 0.12616 ---- val_forecast_loss = 0.04872, val_recon_loss = 0.05093, val_total_loss = 0.09965 [653.5s]
[Epoch 21] forecast_loss = 0.07171, recon_loss = 0.04717, total_loss = 0.11888 ---- val_forecast_loss = 0.04716, val_recon_loss = 0.04681, val_total_loss = 0.09397 [654.5s]
[Epoch 22] forecast_loss = 0.07715, recon_loss = 0.04754, total_loss = 0.12469 ---- val_forecast_loss = 0.05126, val_recon_loss = 0.04445, val_total_loss = 0.09571 [653.0s]
[Epoch 23] forecast_loss = 0.07398, recon_loss = 0.04351, total_loss = 0.11749 ---- val_forecast_loss = 0.04933, val_recon_loss = 0.04284, val_total_loss = 0.09218 [651.6s]
[Epoch 24] forecast_loss = 0.07341, recon_loss = 0.04196, total_loss = 0.11538 ---- val_forecast_loss = 0.04913, val_recon_loss = 0.04143, val_total_loss = 0.09056 [651.2s]
[Epoch 25] forecast_loss = 0.07331, recon_loss = 0.04120, total_loss = 0.11452 ---- val_forecast_loss = 0.04967, val_recon_loss = 0.04089, val_total_loss = 0.09056 [652.0s]
[Epoch 26] forecast_loss = 0.07352, recon_loss = 0.04054, total_loss = 0.11406 ---- val_forecast_loss = 0.04889, val_recon_loss = 0.03996, val_total_loss = 0.08885 [652.0s]
[Epoch 27] forecast_loss = 0.07289, recon_loss = 0.03995, total_loss = 0.11283 ---- val_forecast_loss = 0.04819, val_recon_loss = 0.03942, val_total_loss = 0.08761 [652.5s]
[Epoch 28] forecast_loss = 0.07280, recon_loss = 0.03950, total_loss = 0.11230 ---- val_forecast_loss = 0.04823, val_recon_loss = 0.03917, val_total_loss = 0.08739 [652.1s]
[Epoch 29] forecast_loss = 0.07271, recon_loss = 0.03923, total_loss = 0.11194 ---- val_forecast_loss = 0.04878, val_recon_loss = 0.03934, val_total_loss = 0.08811 [653.6s]
[Epoch 30] forecast_loss = 0.07285, recon_loss = 0.03904, total_loss = 0.11189 ---- val_forecast_loss = 0.04852, val_recon_loss = 0.03907, val_total_loss = 0.08759 [652.0s]
-- Training done in 19750s.
Test forecast loss: 17.49930
Test reconstruction loss: 17.49647
Test total loss: 34.99577
Predicting and calculating anomaly scores..
  0%|          | 0/3065 [00:00<?, ?it/s]  0%|          | 1/3065 [00:00<09:58,  5.12it/s]  0%|          | 2/3065 [00:00<09:58,  5.11it/s]  0%|          | 3/3065 [00:00<09:59,  5.11it/s]  0%|          | 4/3065 [00:00<10:04,  5.07it/s]  0%|          | 5/3065 [00:00<10:07,  5.04it/s]  0%|          | 6/3065 [00:01<10:08,  5.03it/s]  0%|          | 7/3065 [00:01<10:09,  5.02it/s]  0%|          | 8/3065 [00:01<10:09,  5.01it/s]  0%|          | 9/3065 [00:01<10:10,  5.01it/s]  0%|          | 10/3065 [00:01<10:09,  5.01it/s]  0%|          | 11/3065 [00:02<10:10,  5.01it/s]  0%|          | 12/3065 [00:02<10:09,  5.01it/s]  0%|          | 13/3065 [00:02<10:09,  5.00it/s]  0%|          | 14/3065 [00:02<10:09,  5.01it/s]  0%|          | 15/3065 [00:02<10:09,  5.00it/s]  1%|          | 16/3065 [00:03<10:09,  5.00it/s]  1%|          | 17/3065 [00:03<10:09,  5.00it/s]  1%|          | 18/3065 [00:03<10:09,  5.00it/s]  1%|          | 19/3065 [00:03<10:09,  5.00it/s]  1%|          | 20/3065 [00:03<10:08,  5.00it/s]  1%|          | 21/3065 [00:04<10:08,  5.00it/s]  1%|          | 22/3065 [00:04<10:08,  5.00it/s]  1%|          | 23/3065 [00:04<10:08,  5.00it/s]  1%|          | 24/3065 [00:04<10:08,  5.00it/s]  1%|          | 25/3065 [00:04<10:08,  5.00it/s]  1%|          | 26/3065 [00:05<10:07,  5.00it/s]  1%|          | 27/3065 [00:05<10:07,  5.00it/s]  1%|          | 28/3065 [00:05<10:07,  5.00it/s]  1%|          | 29/3065 [00:05<10:06,  5.00it/s]  1%|          | 30/3065 [00:05<10:06,  5.01it/s]  1%|          | 31/3065 [00:06<10:06,  5.01it/s]  1%|          | 32/3065 [00:06<10:06,  5.00it/s]  1%|          | 33/3065 [00:06<10:06,  5.00it/s]  1%|          | 34/3065 [00:06<10:05,  5.00it/s]  1%|          | 35/3065 [00:06<10:05,  5.00it/s]  1%|          | 36/3065 [00:07<10:05,  5.00it/s]  1%|          | 37/3065 [00:07<10:05,  5.00it/s]  1%|          | 38/3065 [00:07<10:04,  5.00it/s]  1%|▏         | 39/3065 [00:07<10:04,  5.01it/s]  1%|▏         | 40/3065 [00:07<10:04,  5.01it/s]  1%|▏         | 41/3065 [00:08<10:04,  5.00it/s]  1%|▏         | 42/3065 [00:08<10:04,  5.00it/s]  1%|▏         | 43/3065 [00:08<10:04,  5.00it/s]  1%|▏         | 44/3065 [00:08<10:04,  5.00it/s]  1%|▏         | 45/3065 [00:08<10:04,  5.00it/s]  2%|▏         | 46/3065 [00:09<10:04,  5.00it/s]  2%|▏         | 47/3065 [00:09<10:03,  5.00it/s]  2%|▏         | 48/3065 [00:09<10:03,  5.00it/s]  2%|▏         | 49/3065 [00:09<10:03,  5.00it/s]  2%|▏         | 50/3065 [00:09<10:02,  5.00it/s]  2%|▏         | 51/3065 [00:10<10:02,  5.00it/s]  2%|▏         | 52/3065 [00:10<10:02,  5.00it/s]  2%|▏         | 53/3065 [00:10<10:02,  5.00it/s]  2%|▏         | 54/3065 [00:10<10:01,  5.00it/s]  2%|▏         | 55/3065 [00:10<10:01,  5.00it/s]  2%|▏         | 56/3065 [00:11<10:01,  5.00it/s]  2%|▏         | 57/3065 [00:11<10:01,  5.00it/s]  2%|▏         | 58/3065 [00:11<10:01,  5.00it/s]  2%|▏         | 59/3065 [00:11<10:00,  5.00it/s]  2%|▏         | 60/3065 [00:11<10:00,  5.00it/s]  2%|▏         | 61/3065 [00:12<10:00,  5.00it/s]  2%|▏         | 62/3065 [00:12<10:00,  5.00it/s]  2%|▏         | 63/3065 [00:12<10:00,  5.00it/s]  2%|▏         | 64/3065 [00:12<09:59,  5.00it/s]  2%|▏         | 65/3065 [00:12<09:59,  5.00it/s]  2%|▏         | 66/3065 [00:13<09:59,  5.00it/s]  2%|▏         | 67/3065 [00:13<09:59,  5.00it/s]  2%|▏         | 68/3065 [00:13<09:59,  5.00it/s]  2%|▏         | 69/3065 [00:13<09:58,  5.00it/s]  2%|▏         | 70/3065 [00:13<09:58,  5.00it/s]  2%|▏         | 71/3065 [00:14<09:58,  5.00it/s]  2%|▏         | 72/3065 [00:14<09:58,  5.00it/s]  2%|▏         | 73/3065 [00:14<09:58,  5.00it/s]  2%|▏         | 74/3065 [00:14<09:57,  5.00it/s]  2%|▏         | 75/3065 [00:14<09:57,  5.00it/s]  2%|▏         | 76/3065 [00:15<09:57,  5.00it/s]  3%|▎         | 77/3065 [00:15<09:57,  5.00it/s]  3%|▎         | 78/3065 [00:15<09:56,  5.00it/s]  3%|▎         | 79/3065 [00:15<09:56,  5.00it/s]  3%|▎         | 80/3065 [00:15<09:56,  5.00it/s]  3%|▎         | 81/3065 [00:16<09:56,  5.00it/s]  3%|▎         | 82/3065 [00:16<09:56,  5.00it/s]  3%|▎         | 83/3065 [00:16<09:56,  5.00it/s]  3%|▎         | 84/3065 [00:16<09:55,  5.00it/s]  3%|▎         | 85/3065 [00:16<09:56,  5.00it/s]  3%|▎         | 86/3065 [00:17<09:56,  5.00it/s]  3%|▎         | 87/3065 [00:17<09:55,  5.00it/s]  3%|▎         | 88/3065 [00:17<09:55,  5.00it/s]  3%|▎         | 89/3065 [00:17<09:55,  5.00it/s]  3%|▎         | 90/3065 [00:17<09:54,  5.00it/s]  3%|▎         | 91/3065 [00:18<09:54,  5.00it/s]  3%|▎         | 92/3065 [00:18<09:54,  5.00it/s]  3%|▎         | 93/3065 [00:18<09:54,  5.00it/s]  3%|▎         | 94/3065 [00:18<09:53,  5.01it/s]  3%|▎         | 95/3065 [00:18<09:53,  5.00it/s]  3%|▎         | 96/3065 [00:19<09:53,  5.00it/s]  3%|▎         | 97/3065 [00:19<09:53,  5.00it/s]  3%|▎         | 98/3065 [00:19<09:53,  5.00it/s]  3%|▎         | 99/3065 [00:19<09:53,  5.00it/s]  3%|▎         | 100/3065 [00:19<09:53,  5.00it/s]  3%|▎         | 101/3065 [00:20<09:52,  5.00it/s]  3%|▎         | 102/3065 [00:20<09:52,  5.00it/s]  3%|▎         | 103/3065 [00:20<09:51,  5.00it/s]  3%|▎         | 104/3065 [00:20<09:51,  5.00it/s]  3%|▎         | 105/3065 [00:20<09:51,  5.00it/s]  3%|▎         | 106/3065 [00:21<09:51,  5.00it/s]  3%|▎         | 107/3065 [00:21<09:51,  5.00it/s]  4%|▎         | 108/3065 [00:21<09:51,  5.00it/s]  4%|▎         | 109/3065 [00:21<09:51,  5.00it/s]  4%|▎         | 110/3065 [00:21<09:50,  5.00it/s]  4%|▎         | 111/3065 [00:22<09:50,  5.00it/s]  4%|▎         | 112/3065 [00:22<09:50,  5.00it/s]  4%|▎         | 113/3065 [00:22<09:49,  5.00it/s]  4%|▎         | 114/3065 [00:22<09:49,  5.00it/s]  4%|▍         | 115/3065 [00:22<09:49,  5.00it/s]  4%|▍         | 116/3065 [00:23<09:49,  5.00it/s]  4%|▍         | 117/3065 [00:23<09:49,  5.00it/s]  4%|▍         | 118/3065 [00:23<09:49,  5.00it/s]  4%|▍         | 119/3065 [00:23<09:49,  5.00it/s]  4%|▍         | 120/3065 [00:23<09:49,  5.00it/s]  4%|▍         | 121/3065 [00:24<09:48,  5.00it/s]  4%|▍         | 122/3065 [00:24<09:47,  5.01it/s]  4%|▍         | 123/3065 [00:24<09:47,  5.00it/s]  4%|▍         | 124/3065 [00:24<09:48,  5.00it/s]  4%|▍         | 125/3065 [00:24<09:47,  5.00it/s]  4%|▍         | 126/3065 [00:25<09:47,  5.00it/s]  4%|▍         | 127/3065 [00:25<09:47,  5.00it/s]  4%|▍         | 128/3065 [00:25<09:47,  5.00it/s]  4%|▍         | 129/3065 [00:25<09:46,  5.00it/s]  4%|▍         | 130/3065 [00:25<09:46,  5.00it/s]  4%|▍         | 131/3065 [00:26<09:45,  5.01it/s]  4%|▍         | 132/3065 [00:26<09:45,  5.01it/s]  4%|▍         | 133/3065 [00:26<09:45,  5.01it/s]  4%|▍         | 134/3065 [00:26<09:45,  5.00it/s]  4%|▍         | 135/3065 [00:26<09:46,  5.00it/s]  4%|▍         | 136/3065 [00:27<09:45,  5.00it/s]  4%|▍         | 137/3065 [00:27<09:45,  5.00it/s]  5%|▍         | 138/3065 [00:27<09:45,  5.00it/s]  5%|▍         | 139/3065 [00:27<09:44,  5.00it/s]  5%|▍         | 140/3065 [00:27<09:44,  5.00it/s]  5%|▍         | 141/3065 [00:28<09:44,  5.00it/s]  5%|▍         | 142/3065 [00:28<09:44,  5.00it/s]  5%|▍         | 143/3065 [00:28<09:44,  5.00it/s]  5%|▍         | 144/3065 [00:28<09:44,  5.00it/s]  5%|▍         | 145/3065 [00:28<09:43,  5.00it/s]  5%|▍         | 146/3065 [00:29<09:43,  5.00it/s]  5%|▍         | 147/3065 [00:29<09:43,  5.00it/s]  5%|▍         | 148/3065 [00:29<09:43,  5.00it/s]  5%|▍         | 149/3065 [00:29<09:43,  5.00it/s]  5%|▍         | 150/3065 [00:29<09:42,  5.00it/s]  5%|▍         | 151/3065 [00:30<09:42,  5.00it/s]  5%|▍         | 152/3065 [00:30<09:42,  5.00it/s]  5%|▍         | 153/3065 [00:30<09:42,  5.00it/s]  5%|▌         | 154/3065 [00:30<09:41,  5.00it/s]  5%|▌         | 155/3065 [00:30<09:41,  5.00it/s]  5%|▌         | 156/3065 [00:31<09:41,  5.00it/s]  5%|▌         | 157/3065 [00:31<09:41,  5.00it/s]  5%|▌         | 158/3065 [00:31<09:41,  5.00it/s]  5%|▌         | 159/3065 [00:31<09:41,  5.00it/s]  5%|▌         | 160/3065 [00:31<09:40,  5.00it/s]  5%|▌         | 161/3065 [00:32<09:40,  5.00it/s]  5%|▌         | 162/3065 [00:32<09:40,  5.00it/s]  5%|▌         | 163/3065 [00:32<09:40,  5.00it/s]  5%|▌         | 164/3065 [00:32<09:40,  5.00it/s]  5%|▌         | 165/3065 [00:32<09:39,  5.00it/s]  5%|▌         | 166/3065 [00:33<09:39,  5.00it/s]  5%|▌         | 167/3065 [00:33<09:39,  5.00it/s]  5%|▌         | 168/3065 [00:33<09:38,  5.00it/s]  6%|▌         | 169/3065 [00:33<09:38,  5.00it/s]  6%|▌         | 170/3065 [00:33<09:38,  5.00it/s]  6%|▌         | 171/3065 [00:34<09:38,  5.00it/s]  6%|▌         | 172/3065 [00:34<09:38,  5.00it/s]  6%|▌         | 173/3065 [00:34<09:38,  5.00it/s]  6%|▌         | 174/3065 [00:34<09:38,  5.00it/s]  6%|▌         | 175/3065 [00:34<09:37,  5.00it/s]  6%|▌         | 176/3065 [00:35<09:37,  5.00it/s]  6%|▌         | 177/3065 [00:35<09:37,  5.00it/s]  6%|▌         | 178/3065 [00:35<09:37,  5.00it/s]  6%|▌         | 179/3065 [00:35<09:37,  5.00it/s]  6%|▌         | 180/3065 [00:35<09:37,  5.00it/s]  6%|▌         | 181/3065 [00:36<09:36,  5.00it/s]  6%|▌         | 182/3065 [00:36<09:36,  5.00it/s]  6%|▌         | 183/3065 [00:36<09:36,  5.00it/s]  6%|▌         | 184/3065 [00:36<09:36,  5.00it/s]  6%|▌         | 185/3065 [00:36<09:35,  5.00it/s]  6%|▌         | 186/3065 [00:37<09:35,  5.00it/s]  6%|▌         | 187/3065 [00:37<09:35,  5.00it/s]  6%|▌         | 188/3065 [00:37<09:35,  5.00it/s]  6%|▌         | 189/3065 [00:37<09:34,  5.01it/s]  6%|▌         | 190/3065 [00:37<09:34,  5.00it/s]  6%|▌         | 191/3065 [00:38<09:33,  5.01it/s]  6%|▋         | 192/3065 [00:38<09:34,  5.01it/s]  6%|▋         | 193/3065 [00:38<09:34,  5.00it/s]  6%|▋         | 194/3065 [00:38<09:33,  5.00it/s]  6%|▋         | 195/3065 [00:38<09:33,  5.00it/s]  6%|▋         | 196/3065 [00:39<09:33,  5.00it/s]  6%|▋         | 197/3065 [00:39<09:33,  5.00it/s]  6%|▋         | 198/3065 [00:39<09:33,  5.00it/s]  6%|▋         | 199/3065 [00:39<09:32,  5.00it/s]  7%|▋         | 200/3065 [00:39<09:32,  5.00it/s]  7%|▋         | 201/3065 [00:40<09:32,  5.00it/s]  7%|▋         | 202/3065 [00:40<09:32,  5.00it/s]  7%|▋         | 203/3065 [00:40<09:32,  5.00it/s]  7%|▋         | 204/3065 [00:40<09:32,  5.00it/s]  7%|▋         | 205/3065 [00:40<09:31,  5.00it/s]  7%|▋         | 206/3065 [00:41<09:31,  5.00it/s]  7%|▋         | 207/3065 [00:41<09:30,  5.01it/s]  7%|▋         | 208/3065 [00:41<09:31,  5.00it/s]  7%|▋         | 209/3065 [00:41<09:31,  5.00it/s]  7%|▋         | 210/3065 [00:41<09:30,  5.00it/s]  7%|▋         | 211/3065 [00:42<09:30,  5.00it/s]  7%|▋         | 212/3065 [00:42<09:30,  5.00it/s]  7%|▋         | 213/3065 [00:42<09:30,  5.00it/s]  7%|▋         | 214/3065 [00:42<09:29,  5.00it/s]  7%|▋         | 215/3065 [00:42<09:29,  5.00it/s]  7%|▋         | 216/3065 [00:43<09:29,  5.00it/s]  7%|▋         | 217/3065 [00:43<09:29,  5.00it/s]  7%|▋         | 218/3065 [00:43<09:29,  5.00it/s]  7%|▋         | 219/3065 [00:43<09:29,  5.00it/s]  7%|▋         | 220/3065 [00:43<09:29,  5.00it/s]  7%|▋         | 221/3065 [00:44<09:28,  5.00it/s]  7%|▋         | 222/3065 [00:44<09:28,  5.00it/s]  7%|▋         | 223/3065 [00:44<09:28,  5.00it/s]  7%|▋         | 224/3065 [00:44<09:27,  5.00it/s]  7%|▋         | 225/3065 [00:44<09:27,  5.00it/s]  7%|▋         | 226/3065 [00:45<09:27,  5.00it/s]  7%|▋         | 227/3065 [00:45<09:27,  5.00it/s]  7%|▋         | 228/3065 [00:45<09:27,  5.00it/s]  7%|▋         | 229/3065 [00:45<09:27,  5.00it/s]  8%|▊         | 230/3065 [00:45<09:26,  5.00it/s]  8%|▊         | 231/3065 [00:46<09:26,  5.00it/s]  8%|▊         | 232/3065 [00:46<09:26,  5.00it/s]  8%|▊         | 233/3065 [00:46<09:26,  5.00it/s]  8%|▊         | 234/3065 [00:46<09:26,  5.00it/s]  8%|▊         | 235/3065 [00:46<09:25,  5.00it/s]  8%|▊         | 236/3065 [00:47<09:25,  5.00it/s]  8%|▊         | 237/3065 [00:47<09:25,  5.00it/s]  8%|▊         | 238/3065 [00:47<09:25,  5.00it/s]  8%|▊         | 239/3065 [00:47<09:24,  5.00it/s]  8%|▊         | 240/3065 [00:47<09:24,  5.00it/s]  8%|▊         | 241/3065 [00:48<09:24,  5.00it/s]  8%|▊         | 242/3065 [00:48<09:24,  5.00it/s]  8%|▊         | 243/3065 [00:48<09:24,  5.00it/s]  8%|▊         | 244/3065 [00:48<09:24,  5.00it/s]  8%|▊         | 245/3065 [00:48<09:23,  5.00it/s]  8%|▊         | 246/3065 [00:49<09:23,  5.00it/s]  8%|▊         | 247/3065 [00:49<09:23,  5.00it/s]  8%|▊         | 248/3065 [00:49<09:22,  5.01it/s]  8%|▊         | 249/3065 [00:49<09:22,  5.00it/s]  8%|▊         | 250/3065 [00:49<09:22,  5.00it/s]  8%|▊         | 251/3065 [00:50<09:22,  5.00it/s]  8%|▊         | 252/3065 [00:50<09:22,  5.00it/s]  8%|▊         | 253/3065 [00:50<09:22,  5.00it/s]  8%|▊         | 254/3065 [00:50<09:22,  5.00it/s]  8%|▊         | 255/3065 [00:50<09:21,  5.00it/s]  8%|▊         | 256/3065 [00:51<09:21,  5.00it/s]  8%|▊         | 257/3065 [00:51<09:21,  5.00it/s]  8%|▊         | 258/3065 [00:51<09:21,  5.00it/s]  8%|▊         | 259/3065 [00:51<09:21,  5.00it/s]  8%|▊         | 260/3065 [00:51<09:20,  5.00it/s]  9%|▊         | 261/3065 [00:52<09:20,  5.00it/s]  9%|▊         | 262/3065 [00:52<09:20,  5.00it/s]  9%|▊         | 263/3065 [00:52<09:20,  5.00it/s]  9%|▊         | 264/3065 [00:52<09:20,  5.00it/s]  9%|▊         | 265/3065 [00:52<09:20,  5.00it/s]  9%|▊         | 266/3065 [00:53<09:20,  5.00it/s]  9%|▊         | 267/3065 [00:53<09:19,  5.00it/s]  9%|▊         | 268/3065 [00:53<09:19,  5.00it/s]  9%|▉         | 269/3065 [00:53<09:18,  5.00it/s]  9%|▉         | 270/3065 [00:53<09:18,  5.00it/s]  9%|▉         | 271/3065 [00:54<09:18,  5.00it/s]  9%|▉         | 272/3065 [00:54<09:18,  5.00it/s]  9%|▉         | 273/3065 [00:54<09:18,  5.00it/s]  9%|▉         | 274/3065 [00:54<09:18,  5.00it/s]  9%|▉         | 275/3065 [00:54<09:17,  5.00it/s]  9%|▉         | 276/3065 [00:55<09:17,  5.00it/s]  9%|▉         | 277/3065 [00:55<09:17,  5.00it/s]  9%|▉         | 278/3065 [00:55<09:17,  5.00it/s]  9%|▉         | 279/3065 [00:55<09:17,  5.00it/s]  9%|▉         | 280/3065 [00:55<09:16,  5.00it/s]  9%|▉         | 281/3065 [00:56<09:16,  5.00it/s]  9%|▉         | 282/3065 [00:56<09:16,  5.00it/s]  9%|▉         | 283/3065 [00:56<09:15,  5.00it/s]  9%|▉         | 284/3065 [00:56<09:15,  5.00it/s]  9%|▉         | 285/3065 [00:56<09:16,  5.00it/s]  9%|▉         | 286/3065 [00:57<09:15,  5.00it/s]  9%|▉         | 287/3065 [00:57<09:15,  5.00it/s]  9%|▉         | 288/3065 [00:57<09:15,  5.00it/s]  9%|▉         | 289/3065 [00:57<09:14,  5.00it/s]  9%|▉         | 290/3065 [00:57<09:14,  5.00it/s]  9%|▉         | 291/3065 [00:58<09:14,  5.00it/s] 10%|▉         | 292/3065 [00:58<09:14,  5.01it/s] 10%|▉         | 293/3065 [00:58<09:14,  5.00it/s] 10%|▉         | 294/3065 [00:58<09:14,  5.00it/s] 10%|▉         | 295/3065 [00:58<09:14,  5.00it/s] 10%|▉         | 296/3065 [00:59<09:14,  5.00it/s] 10%|▉         | 297/3065 [00:59<09:13,  5.00it/s] 10%|▉         | 298/3065 [00:59<09:13,  5.00it/s] 10%|▉         | 299/3065 [00:59<09:13,  5.00it/s] 10%|▉         | 300/3065 [00:59<09:12,  5.01it/s] 10%|▉         | 301/3065 [01:00<09:12,  5.01it/s] 10%|▉         | 302/3065 [01:00<09:12,  5.00it/s] 10%|▉         | 303/3065 [01:00<09:12,  5.00it/s] 10%|▉         | 304/3065 [01:00<09:11,  5.00it/s] 10%|▉         | 305/3065 [01:00<09:11,  5.00it/s] 10%|▉         | 306/3065 [01:01<09:11,  5.00it/s] 10%|█         | 307/3065 [01:01<09:11,  5.00it/s] 10%|█         | 308/3065 [01:01<09:11,  5.00it/s] 10%|█         | 309/3065 [01:01<09:10,  5.00it/s] 10%|█         | 310/3065 [01:01<09:11,  5.00it/s] 10%|█         | 311/3065 [01:02<09:10,  5.00it/s] 10%|█         | 312/3065 [01:02<09:10,  5.00it/s] 10%|█         | 313/3065 [01:02<09:09,  5.01it/s] 10%|█         | 314/3065 [01:02<09:09,  5.00it/s] 10%|█         | 315/3065 [01:02<09:09,  5.00it/s] 10%|█         | 316/3065 [01:03<09:09,  5.00it/s] 10%|█         | 317/3065 [01:03<09:09,  5.00it/s] 10%|█         | 318/3065 [01:03<09:09,  5.00it/s] 10%|█         | 319/3065 [01:03<09:09,  5.00it/s] 10%|█         | 320/3065 [01:03<09:09,  5.00it/s] 10%|█         | 321/3065 [01:04<09:09,  5.00it/s] 11%|█         | 322/3065 [01:04<09:08,  5.00it/s] 11%|█         | 323/3065 [01:04<09:08,  5.00it/s] 11%|█         | 324/3065 [01:04<09:08,  5.00it/s] 11%|█         | 325/3065 [01:04<09:07,  5.01it/s] 11%|█         | 326/3065 [01:05<09:07,  5.00it/s] 11%|█         | 327/3065 [01:05<09:07,  5.00it/s] 11%|█         | 328/3065 [01:05<09:07,  5.00it/s] 11%|█         | 329/3065 [01:05<09:06,  5.00it/s] 11%|█         | 330/3065 [01:05<09:06,  5.00it/s] 11%|█         | 331/3065 [01:06<09:06,  5.00it/s] 11%|█         | 332/3065 [01:06<09:06,  5.00it/s] 11%|█         | 333/3065 [01:06<09:06,  5.00it/s] 11%|█         | 334/3065 [01:06<09:05,  5.00it/s] 11%|█         | 335/3065 [01:06<09:06,  5.00it/s] 11%|█         | 336/3065 [01:07<09:05,  5.00it/s] 11%|█         | 337/3065 [01:07<09:05,  5.00it/s] 11%|█         | 338/3065 [01:07<09:05,  5.00it/s] 11%|█         | 339/3065 [01:07<09:05,  5.00it/s] 11%|█         | 340/3065 [01:07<09:04,  5.00it/s] 11%|█         | 341/3065 [01:08<09:04,  5.00it/s] 11%|█         | 342/3065 [01:08<09:04,  5.00it/s] 11%|█         | 343/3065 [01:08<09:04,  5.00it/s] 11%|█         | 344/3065 [01:08<09:04,  5.00it/s] 11%|█▏        | 345/3065 [01:08<09:03,  5.00it/s] 11%|█▏        | 346/3065 [01:09<09:03,  5.00it/s] 11%|█▏        | 347/3065 [01:09<09:03,  5.00it/s] 11%|█▏        | 348/3065 [01:09<09:03,  5.00it/s] 11%|█▏        | 349/3065 [01:09<09:03,  5.00it/s] 11%|█▏        | 350/3065 [01:09<09:02,  5.00it/s] 11%|█▏        | 351/3065 [01:10<09:02,  5.00it/s] 11%|█▏        | 352/3065 [01:10<09:02,  5.00it/s] 12%|█▏        | 353/3065 [01:10<09:02,  5.00it/s] 12%|█▏        | 354/3065 [01:10<09:02,  5.00it/s] 12%|█▏        | 355/3065 [01:10<09:01,  5.00it/s] 12%|█▏        | 356/3065 [01:11<09:01,  5.00it/s] 12%|█▏        | 357/3065 [01:11<09:01,  5.00it/s] 12%|█▏        | 358/3065 [01:11<09:01,  5.00it/s] 12%|█▏        | 359/3065 [01:11<09:01,  5.00it/s] 12%|█▏        | 360/3065 [01:11<09:00,  5.00it/s] 12%|█▏        | 361/3065 [01:12<09:00,  5.00it/s] 12%|█▏        | 362/3065 [01:12<09:00,  5.00it/s] 12%|█▏        | 363/3065 [01:12<09:00,  5.00it/s] 12%|█▏        | 364/3065 [01:12<08:59,  5.00it/s] 12%|█▏        | 365/3065 [01:12<08:59,  5.00it/s] 12%|█▏        | 366/3065 [01:13<08:59,  5.00it/s] 12%|█▏        | 367/3065 [01:13<08:59,  5.00it/s] 12%|█▏        | 368/3065 [01:13<08:59,  5.00it/s] 12%|█▏        | 369/3065 [01:13<08:59,  5.00it/s] 12%|█▏        | 370/3065 [01:13<08:58,  5.00it/s] 12%|█▏        | 371/3065 [01:14<08:58,  5.00it/s] 12%|█▏        | 372/3065 [01:14<08:58,  5.00it/s] 12%|█▏        | 373/3065 [01:14<08:58,  5.00it/s] 12%|█▏        | 374/3065 [01:14<08:58,  5.00it/s] 12%|█▏        | 375/3065 [01:14<08:57,  5.00it/s] 12%|█▏        | 376/3065 [01:15<08:57,  5.00it/s] 12%|█▏        | 377/3065 [01:15<08:57,  5.00it/s] 12%|█▏        | 378/3065 [01:15<08:57,  5.00it/s] 12%|█▏        | 379/3065 [01:15<08:57,  5.00it/s] 12%|█▏        | 380/3065 [01:15<08:56,  5.01it/s] 12%|█▏        | 381/3065 [01:16<08:56,  5.01it/s] 12%|█▏        | 382/3065 [01:16<08:56,  5.00it/s] 12%|█▏        | 383/3065 [01:16<08:56,  5.00it/s] 13%|█▎        | 384/3065 [01:16<08:56,  5.00it/s] 13%|█▎        | 385/3065 [01:16<08:55,  5.00it/s] 13%|█▎        | 386/3065 [01:17<08:55,  5.00it/s] 13%|█▎        | 387/3065 [01:17<08:55,  5.00it/s] 13%|█▎        | 388/3065 [01:17<08:55,  5.00it/s] 13%|█▎        | 389/3065 [01:17<08:54,  5.00it/s] 13%|█▎        | 390/3065 [01:17<08:54,  5.00it/s] 13%|█▎        | 391/3065 [01:18<08:54,  5.00it/s] 13%|█▎        | 392/3065 [01:18<08:54,  5.00it/s] 13%|█▎        | 393/3065 [01:18<08:54,  5.00it/s] 13%|█▎        | 394/3065 [01:18<08:53,  5.00it/s] 13%|█▎        | 395/3065 [01:18<08:53,  5.00it/s] 13%|█▎        | 396/3065 [01:19<08:53,  5.00it/s] 13%|█▎        | 397/3065 [01:19<08:53,  5.00it/s] 13%|█▎        | 398/3065 [01:19<08:53,  5.00it/s] 13%|█▎        | 399/3065 [01:19<08:52,  5.00it/s] 13%|█▎        | 400/3065 [01:19<08:52,  5.00it/s] 13%|█▎        | 401/3065 [01:20<08:52,  5.00it/s] 13%|█▎        | 402/3065 [01:20<08:52,  5.00it/s] 13%|█▎        | 403/3065 [01:20<08:52,  5.00it/s] 13%|█▎        | 404/3065 [01:20<08:51,  5.00it/s] 13%|█▎        | 405/3065 [01:20<08:51,  5.00it/s] 13%|█▎        | 406/3065 [01:21<08:51,  5.00it/s] 13%|█▎        | 407/3065 [01:21<08:51,  5.00it/s] 13%|█▎        | 408/3065 [01:21<08:51,  5.00it/s] 13%|█▎        | 409/3065 [01:21<08:50,  5.00it/s] 13%|█▎        | 410/3065 [01:21<08:50,  5.00it/s] 13%|█▎        | 411/3065 [01:22<08:50,  5.00it/s] 13%|█▎        | 412/3065 [01:22<08:50,  5.00it/s] 13%|█▎        | 413/3065 [01:22<08:50,  5.00it/s] 14%|█▎        | 414/3065 [01:22<08:50,  5.00it/s] 14%|█▎        | 415/3065 [01:22<08:50,  5.00it/s] 14%|█▎        | 416/3065 [01:23<08:49,  5.00it/s] 14%|█▎        | 417/3065 [01:23<08:49,  5.00it/s] 14%|█▎        | 418/3065 [01:23<08:49,  5.00it/s] 14%|█▎        | 419/3065 [01:23<08:49,  5.00it/s] 14%|█▎        | 420/3065 [01:23<08:48,  5.00it/s] 14%|█▎        | 421/3065 [01:24<08:48,  5.00it/s] 14%|█▍        | 422/3065 [01:24<08:48,  5.00it/s] 14%|█▍        | 423/3065 [01:24<08:48,  5.00it/s] 14%|█▍        | 424/3065 [01:24<08:47,  5.00it/s] 14%|█▍        | 425/3065 [01:24<08:47,  5.01it/s] 14%|█▍        | 426/3065 [01:25<08:47,  5.00it/s] 14%|█▍        | 427/3065 [01:25<08:47,  5.00it/s] 14%|█▍        | 428/3065 [01:25<08:47,  5.00it/s] 14%|█▍        | 429/3065 [01:25<08:47,  5.00it/s] 14%|█▍        | 430/3065 [01:25<08:46,  5.00it/s] 14%|█▍        | 431/3065 [01:26<08:46,  5.00it/s] 14%|█▍        | 432/3065 [01:26<08:46,  5.00it/s] 14%|█▍        | 433/3065 [01:26<08:46,  5.00it/s] 14%|█▍        | 434/3065 [01:26<08:45,  5.00it/s] 14%|█▍        | 435/3065 [01:26<08:46,  5.00it/s] 14%|█▍        | 436/3065 [01:27<08:45,  5.00it/s] 14%|█▍        | 437/3065 [01:27<08:45,  5.00it/s] 14%|█▍        | 438/3065 [01:27<08:45,  5.00it/s] 14%|█▍        | 439/3065 [01:27<08:45,  5.00it/s] 14%|█▍        | 440/3065 [01:27<08:44,  5.00it/s] 14%|█▍        | 441/3065 [01:28<08:44,  5.00it/s] 14%|█▍        | 442/3065 [01:28<08:44,  5.00it/s] 14%|█▍        | 443/3065 [01:28<08:44,  5.00it/s] 14%|█▍        | 444/3065 [01:28<08:43,  5.00it/s] 15%|█▍        | 445/3065 [01:28<08:43,  5.00it/s] 15%|█▍        | 446/3065 [01:29<08:43,  5.00it/s] 15%|█▍        | 447/3065 [01:29<08:43,  5.00it/s] 15%|█▍        | 448/3065 [01:29<08:43,  5.00it/s] 15%|█▍        | 449/3065 [01:29<08:42,  5.01it/s] 15%|█▍        | 450/3065 [01:29<08:42,  5.00it/s] 15%|█▍        | 451/3065 [01:30<08:42,  5.00it/s] 15%|█▍        | 452/3065 [01:30<08:42,  5.00it/s] 15%|█▍        | 453/3065 [01:30<08:42,  5.00it/s] 15%|█▍        | 454/3065 [01:30<08:42,  5.00it/s] 15%|█▍        | 455/3065 [01:30<08:41,  5.00it/s] 15%|█▍        | 456/3065 [01:31<08:41,  5.00it/s] 15%|█▍        | 457/3065 [01:31<08:41,  5.00it/s] 15%|█▍        | 458/3065 [01:31<08:41,  5.00it/s] 15%|█▍        | 459/3065 [01:31<08:40,  5.00it/s] 15%|█▌        | 460/3065 [01:31<08:40,  5.00it/s] 15%|█▌        | 461/3065 [01:32<08:40,  5.00it/s] 15%|█▌        | 462/3065 [01:32<08:40,  5.00it/s] 15%|█▌        | 463/3065 [01:32<08:40,  5.00it/s] 15%|█▌        | 464/3065 [01:32<08:40,  5.00it/s] 15%|█▌        | 465/3065 [01:32<08:39,  5.00it/s] 15%|█▌        | 466/3065 [01:33<08:39,  5.00it/s] 15%|█▌        | 467/3065 [01:33<08:39,  5.00it/s] 15%|█▌        | 468/3065 [01:33<08:39,  5.00it/s] 15%|█▌        | 469/3065 [01:33<08:39,  5.00it/s] 15%|█▌        | 470/3065 [01:33<08:38,  5.00it/s] 15%|█▌        | 471/3065 [01:34<08:38,  5.00it/s] 15%|█▌        | 472/3065 [01:34<08:38,  5.00it/s] 15%|█▌        | 473/3065 [01:34<08:38,  5.00it/s] 15%|█▌        | 474/3065 [01:34<08:38,  5.00it/s] 15%|█▌        | 475/3065 [01:34<08:37,  5.00it/s] 16%|█▌        | 476/3065 [01:35<08:37,  5.00it/s] 16%|█▌        | 477/3065 [01:35<08:37,  5.00it/s] 16%|█▌        | 478/3065 [01:35<08:36,  5.00it/s] 16%|█▌        | 479/3065 [01:35<08:37,  5.00it/s] 16%|█▌        | 480/3065 [01:35<08:36,  5.00it/s] 16%|█▌        | 481/3065 [01:36<08:36,  5.00it/s] 16%|█▌        | 482/3065 [01:36<08:36,  5.00it/s] 16%|█▌        | 483/3065 [01:36<08:36,  5.00it/s] 16%|█▌        | 484/3065 [01:36<08:36,  5.00it/s] 16%|█▌        | 485/3065 [01:36<08:35,  5.00it/s] 16%|█▌        | 486/3065 [01:37<08:35,  5.00it/s] 16%|█▌        | 487/3065 [01:37<08:35,  5.00it/s] 16%|█▌        | 488/3065 [01:37<08:35,  5.00it/s] 16%|█▌        | 489/3065 [01:37<08:34,  5.00it/s] 16%|█▌        | 490/3065 [01:37<08:34,  5.00it/s] 16%|█▌        | 491/3065 [01:38<08:35,  5.00it/s] 16%|█▌        | 492/3065 [01:38<08:34,  5.00it/s] 16%|█▌        | 493/3065 [01:38<08:34,  5.00it/s] 16%|█▌        | 494/3065 [01:38<08:34,  5.00it/s] 16%|█▌        | 495/3065 [01:38<08:33,  5.00it/s] 16%|█▌        | 496/3065 [01:39<08:33,  5.00it/s] 16%|█▌        | 497/3065 [01:39<08:33,  5.00it/s] 16%|█▌        | 498/3065 [01:39<08:33,  5.00it/s] 16%|█▋        | 499/3065 [01:39<08:33,  5.00it/s] 16%|█▋        | 500/3065 [01:39<08:33,  5.00it/s] 16%|█▋        | 501/3065 [01:40<08:32,  5.00it/s] 16%|█▋        | 502/3065 [01:40<08:32,  5.00it/s] 16%|█▋        | 503/3065 [01:40<08:32,  5.00it/s] 16%|█▋        | 504/3065 [01:40<08:32,  5.00it/s] 16%|█▋        | 505/3065 [01:40<08:31,  5.00it/s] 17%|█▋        | 506/3065 [01:41<08:31,  5.00it/s] 17%|█▋        | 507/3065 [01:41<08:31,  5.00it/s] 17%|█▋        | 508/3065 [01:41<08:31,  5.00it/s] 17%|█▋        | 509/3065 [01:41<08:30,  5.00it/s] 17%|█▋        | 510/3065 [01:41<08:30,  5.00it/s] 17%|█▋        | 511/3065 [01:42<08:30,  5.00it/s] 17%|█▋        | 512/3065 [01:42<08:30,  5.00it/s] 17%|█▋        | 513/3065 [01:42<08:30,  5.00it/s] 17%|█▋        | 514/3065 [01:42<08:30,  5.00it/s] 17%|█▋        | 515/3065 [01:42<08:29,  5.00it/s] 17%|█▋        | 516/3065 [01:43<08:29,  5.00it/s] 17%|█▋        | 517/3065 [01:43<08:29,  5.00it/s] 17%|█▋        | 518/3065 [01:43<08:29,  5.00it/s] 17%|█▋        | 519/3065 [01:43<08:28,  5.00it/s] 17%|█▋        | 520/3065 [01:43<08:28,  5.00it/s] 17%|█▋        | 521/3065 [01:44<08:28,  5.01it/s] 17%|█▋        | 522/3065 [01:44<08:28,  5.00it/s] 17%|█▋        | 523/3065 [01:44<08:28,  5.00it/s] 17%|█▋        | 524/3065 [01:44<08:28,  5.00it/s] 17%|█▋        | 525/3065 [01:44<08:28,  4.99it/s] 17%|█▋        | 526/3065 [01:45<08:27,  5.00it/s] 17%|█▋        | 527/3065 [01:45<08:27,  5.00it/s] 17%|█▋        | 528/3065 [01:45<08:27,  5.00it/s] 17%|█▋        | 529/3065 [01:45<08:27,  5.00it/s] 17%|█▋        | 530/3065 [01:45<08:27,  5.00it/s] 17%|█▋        | 531/3065 [01:46<08:26,  5.00it/s] 17%|█▋        | 532/3065 [01:46<08:26,  5.00it/s] 17%|█▋        | 533/3065 [01:46<08:26,  5.00it/s] 17%|█▋        | 534/3065 [01:46<08:25,  5.00it/s] 17%|█▋        | 535/3065 [01:46<08:25,  5.00it/s] 17%|█▋        | 536/3065 [01:47<08:25,  5.00it/s] 18%|█▊        | 537/3065 [01:47<08:25,  5.00it/s] 18%|█▊        | 538/3065 [01:47<08:25,  5.00it/s] 18%|█▊        | 539/3065 [01:47<08:25,  5.00it/s] 18%|█▊        | 540/3065 [01:47<08:24,  5.00it/s] 18%|█▊        | 541/3065 [01:48<08:24,  5.01it/s] 18%|█▊        | 542/3065 [01:48<08:24,  5.01it/s] 18%|█▊        | 543/3065 [01:48<08:24,  5.00it/s] 18%|█▊        | 544/3065 [01:48<08:23,  5.01it/s] 18%|█▊        | 545/3065 [01:48<08:23,  5.00it/s] 18%|█▊        | 546/3065 [01:49<08:23,  5.00it/s] 18%|█▊        | 547/3065 [01:49<08:23,  5.00it/s] 18%|█▊        | 548/3065 [01:49<08:23,  5.00it/s] 18%|█▊        | 549/3065 [01:49<08:23,  5.00it/s] 18%|█▊        | 550/3065 [01:49<08:23,  5.00it/s] 18%|█▊        | 551/3065 [01:50<08:22,  5.00it/s] 18%|█▊        | 552/3065 [01:50<08:22,  5.00it/s] 18%|█▊        | 553/3065 [01:50<08:22,  5.00it/s] 18%|█▊        | 554/3065 [01:50<08:22,  5.00it/s] 18%|█▊        | 555/3065 [01:50<08:22,  5.00it/s] 18%|█▊        | 556/3065 [01:51<08:21,  5.00it/s] 18%|█▊        | 557/3065 [01:51<08:21,  5.00it/s] 18%|█▊        | 558/3065 [01:51<08:21,  5.00it/s] 18%|█▊        | 559/3065 [01:51<08:21,  5.00it/s] 18%|█▊        | 560/3065 [01:51<08:20,  5.00it/s] 18%|█▊        | 561/3065 [01:52<08:20,  5.00it/s] 18%|█▊        | 562/3065 [01:52<08:20,  5.00it/s] 18%|█▊        | 563/3065 [01:52<08:20,  5.00it/s] 18%|█▊        | 564/3065 [01:52<08:20,  5.00it/s] 18%|█▊        | 565/3065 [01:52<08:19,  5.00it/s] 18%|█▊        | 566/3065 [01:53<08:19,  5.00it/s] 18%|█▊        | 567/3065 [01:53<08:19,  5.00it/s] 19%|█▊        | 568/3065 [01:53<08:19,  5.00it/s] 19%|█▊        | 569/3065 [01:53<08:18,  5.00it/s] 19%|█▊        | 570/3065 [01:53<08:18,  5.00it/s] 19%|█▊        | 571/3065 [01:54<08:18,  5.00it/s] 19%|█▊        | 572/3065 [01:54<08:18,  5.00it/s] 19%|█▊        | 573/3065 [01:54<08:18,  5.00it/s] 19%|█▊        | 574/3065 [01:54<08:18,  5.00it/s] 19%|█▉        | 575/3065 [01:54<08:17,  5.00it/s] 19%|█▉        | 576/3065 [01:55<08:17,  5.00it/s] 19%|█▉        | 577/3065 [01:55<08:17,  5.00it/s] 19%|█▉        | 578/3065 [01:55<08:17,  5.00it/s] 19%|█▉        | 579/3065 [01:55<08:17,  5.00it/s] 19%|█▉        | 580/3065 [01:55<08:16,  5.00it/s] 19%|█▉        | 581/3065 [01:56<08:16,  5.00it/s] 19%|█▉        | 582/3065 [01:56<08:16,  5.00it/s] 19%|█▉        | 583/3065 [01:56<08:16,  5.00it/s] 19%|█▉        | 584/3065 [01:56<08:16,  5.00it/s] 19%|█▉        | 585/3065 [01:56<08:15,  5.00it/s] 19%|█▉        | 586/3065 [01:57<08:15,  5.00it/s] 19%|█▉        | 587/3065 [01:57<08:15,  5.00it/s] 19%|█▉        | 588/3065 [01:57<08:15,  5.00it/s] 19%|█▉        | 589/3065 [01:57<08:15,  5.00it/s] 19%|█▉        | 590/3065 [01:57<08:15,  5.00it/s] 19%|█▉        | 591/3065 [01:58<08:15,  5.00it/s] 19%|█▉        | 592/3065 [01:58<08:14,  5.00it/s] 19%|█▉        | 593/3065 [01:58<08:14,  5.00it/s] 19%|█▉        | 594/3065 [01:58<08:13,  5.00it/s] 19%|█▉        | 595/3065 [01:58<08:13,  5.00it/s] 19%|█▉        | 596/3065 [01:59<08:13,  5.00it/s] 19%|█▉        | 597/3065 [01:59<08:13,  5.00it/s] 20%|█▉        | 598/3065 [01:59<08:12,  5.01it/s] 20%|█▉        | 599/3065 [01:59<08:12,  5.00it/s] 20%|█▉        | 600/3065 [01:59<08:12,  5.00it/s] 20%|█▉        | 601/3065 [02:00<08:12,  5.00it/s] 20%|█▉        | 602/3065 [02:00<08:12,  5.00it/s] 20%|█▉        | 603/3065 [02:00<08:12,  5.00it/s] 20%|█▉        | 604/3065 [02:00<08:11,  5.00it/s] 20%|█▉        | 605/3065 [02:00<08:11,  5.00it/s] 20%|█▉        | 606/3065 [02:01<08:11,  5.00it/s] 20%|█▉        | 607/3065 [02:01<08:11,  5.00it/s] 20%|█▉        | 608/3065 [02:01<08:11,  5.00it/s] 20%|█▉        | 609/3065 [02:01<08:10,  5.00it/s] 20%|█▉        | 610/3065 [02:01<08:10,  5.00it/s] 20%|█▉        | 611/3065 [02:02<08:10,  5.00it/s] 20%|█▉        | 612/3065 [02:02<08:10,  5.00it/s] 20%|██        | 613/3065 [02:02<08:10,  5.00it/s] 20%|██        | 614/3065 [02:02<08:10,  5.00it/s] 20%|██        | 615/3065 [02:02<08:09,  5.00it/s] 20%|██        | 616/3065 [02:03<08:09,  5.00it/s] 20%|██        | 617/3065 [02:03<08:09,  5.00it/s] 20%|██        | 618/3065 [02:03<08:09,  5.00it/s] 20%|██        | 619/3065 [02:03<08:08,  5.00it/s] 20%|██        | 620/3065 [02:03<08:08,  5.00it/s] 20%|██        | 621/3065 [02:04<08:08,  5.00it/s] 20%|██        | 622/3065 [02:04<08:08,  5.00it/s] 20%|██        | 623/3065 [02:04<08:08,  5.00it/s] 20%|██        | 624/3065 [02:04<08:08,  5.00it/s] 20%|██        | 625/3065 [02:04<08:08,  5.00it/s] 20%|██        | 626/3065 [02:05<08:07,  5.00it/s] 20%|██        | 627/3065 [02:05<08:07,  5.00it/s] 20%|██        | 628/3065 [02:05<08:07,  5.00it/s] 21%|██        | 629/3065 [02:05<08:07,  5.00it/s] 21%|██        | 630/3065 [02:05<08:06,  5.00it/s] 21%|██        | 631/3065 [02:06<08:06,  5.00it/s] 21%|██        | 632/3065 [02:06<08:06,  5.00it/s] 21%|██        | 633/3065 [02:06<08:06,  5.00it/s] 21%|██        | 634/3065 [02:06<08:05,  5.00it/s] 21%|██        | 635/3065 [02:06<08:05,  5.00it/s] 21%|██        | 636/3065 [02:07<08:05,  5.00it/s] 21%|██        | 637/3065 [02:07<08:05,  5.00it/s] 21%|██        | 638/3065 [02:07<08:05,  5.00it/s] 21%|██        | 639/3065 [02:07<08:04,  5.00it/s] 21%|██        | 640/3065 [02:07<08:04,  5.00it/s] 21%|██        | 641/3065 [02:08<08:04,  5.00it/s] 21%|██        | 642/3065 [02:08<08:04,  5.00it/s] 21%|██        | 643/3065 [02:08<08:04,  5.00it/s] 21%|██        | 644/3065 [02:08<08:04,  5.00it/s] 21%|██        | 645/3065 [02:08<08:03,  5.00it/s] 21%|██        | 646/3065 [02:09<08:03,  5.00it/s] 21%|██        | 647/3065 [02:09<08:03,  5.00it/s] 21%|██        | 648/3065 [02:09<08:03,  5.00it/s] 21%|██        | 649/3065 [02:09<08:03,  5.00it/s] 21%|██        | 650/3065 [02:09<08:03,  5.00it/s] 21%|██        | 651/3065 [02:10<08:02,  5.00it/s] 21%|██▏       | 652/3065 [02:10<08:02,  5.00it/s] 21%|██▏       | 653/3065 [02:10<08:02,  5.00it/s] 21%|██▏       | 654/3065 [02:10<08:02,  5.00it/s] 21%|██▏       | 655/3065 [02:10<08:01,  5.00it/s] 21%|██▏       | 656/3065 [02:11<08:01,  5.00it/s] 21%|██▏       | 657/3065 [02:11<08:01,  5.00it/s] 21%|██▏       | 658/3065 [02:11<08:01,  5.00it/s] 22%|██▏       | 659/3065 [02:11<08:00,  5.00it/s] 22%|██▏       | 660/3065 [02:11<08:00,  5.00it/s] 22%|██▏       | 661/3065 [02:12<08:00,  5.00it/s] 22%|██▏       | 662/3065 [02:12<08:00,  5.00it/s] 22%|██▏       | 663/3065 [02:12<08:00,  5.00it/s] 22%|██▏       | 664/3065 [02:12<08:00,  5.00it/s] 22%|██▏       | 665/3065 [02:12<07:59,  5.00it/s] 22%|██▏       | 666/3065 [02:13<07:59,  5.00it/s] 22%|██▏       | 667/3065 [02:13<07:58,  5.01it/s] 22%|██▏       | 668/3065 [02:13<07:58,  5.01it/s] 22%|██▏       | 669/3065 [02:13<07:58,  5.00it/s] 22%|██▏       | 670/3065 [02:13<07:58,  5.00it/s] 22%|██▏       | 671/3065 [02:14<07:58,  5.00it/s] 22%|██▏       | 672/3065 [02:14<07:58,  5.00it/s] 22%|██▏       | 673/3065 [02:14<07:58,  5.00it/s] 22%|██▏       | 674/3065 [02:14<07:58,  5.00it/s] 22%|██▏       | 675/3065 [02:14<07:58,  5.00it/s] 22%|██▏       | 676/3065 [02:15<07:57,  5.00it/s] 22%|██▏       | 677/3065 [02:15<07:57,  5.00it/s] 22%|██▏       | 678/3065 [02:15<07:57,  5.00it/s] 22%|██▏       | 679/3065 [02:15<07:56,  5.00it/s] 22%|██▏       | 680/3065 [02:15<07:56,  5.00it/s] 22%|██▏       | 681/3065 [02:16<07:56,  5.00it/s] 22%|██▏       | 682/3065 [02:16<07:56,  5.00it/s] 22%|██▏       | 683/3065 [02:16<07:56,  5.00it/s] 22%|██▏       | 684/3065 [02:16<07:56,  5.00it/s] 22%|██▏       | 685/3065 [02:16<07:55,  5.00it/s] 22%|██▏       | 686/3065 [02:17<07:56,  5.00it/s] 22%|██▏       | 687/3065 [02:17<07:55,  5.00it/s] 22%|██▏       | 688/3065 [02:17<07:55,  5.00it/s] 22%|██▏       | 689/3065 [02:17<07:55,  5.00it/s] 23%|██▎       | 690/3065 [02:17<07:54,  5.00it/s] 23%|██▎       | 691/3065 [02:18<07:54,  5.00it/s] 23%|██▎       | 692/3065 [02:18<07:54,  5.00it/s] 23%|██▎       | 693/3065 [02:18<07:54,  5.00it/s] 23%|██▎       | 694/3065 [02:18<07:53,  5.00it/s] 23%|██▎       | 695/3065 [02:18<07:53,  5.00it/s] 23%|██▎       | 696/3065 [02:19<07:53,  5.00it/s] 23%|██▎       | 697/3065 [02:19<07:53,  5.00it/s] 23%|██▎       | 698/3065 [02:19<07:53,  5.00it/s] 23%|██▎       | 699/3065 [02:19<07:53,  5.00it/s] 23%|██▎       | 700/3065 [02:19<07:52,  5.00it/s] 23%|██▎       | 701/3065 [02:20<07:52,  5.00it/s] 23%|██▎       | 702/3065 [02:20<07:52,  5.00it/s] 23%|██▎       | 703/3065 [02:20<07:52,  5.00it/s] 23%|██▎       | 704/3065 [02:20<07:51,  5.00it/s] 23%|██▎       | 705/3065 [02:20<07:51,  5.00it/s] 23%|██▎       | 706/3065 [02:21<07:51,  5.00it/s] 23%|██▎       | 707/3065 [02:21<07:51,  5.00it/s] 23%|██▎       | 708/3065 [02:21<07:51,  5.00it/s] 23%|██▎       | 709/3065 [02:21<07:50,  5.00it/s] 23%|██▎       | 710/3065 [02:21<07:50,  5.00it/s] 23%|██▎       | 711/3065 [02:22<07:50,  5.00it/s] 23%|██▎       | 712/3065 [02:22<07:50,  5.00it/s] 23%|██▎       | 713/3065 [02:22<07:50,  5.00it/s] 23%|██▎       | 714/3065 [02:22<07:49,  5.00it/s] 23%|██▎       | 715/3065 [02:22<07:49,  5.00it/s] 23%|██▎       | 716/3065 [02:23<07:49,  5.00it/s] 23%|██▎       | 717/3065 [02:23<07:49,  5.00it/s] 23%|██▎       | 718/3065 [02:23<07:49,  5.00it/s] 23%|██▎       | 719/3065 [02:23<07:49,  5.00it/s] 23%|██▎       | 720/3065 [02:23<07:49,  5.00it/s] 24%|██▎       | 721/3065 [02:24<07:48,  5.00it/s] 24%|██▎       | 722/3065 [02:24<07:48,  5.00it/s] 24%|██▎       | 723/3065 [02:24<07:48,  5.00it/s] 24%|██▎       | 724/3065 [02:24<07:47,  5.01it/s] 24%|██▎       | 725/3065 [02:24<07:47,  5.00it/s] 24%|██▎       | 726/3065 [02:25<07:47,  5.00it/s] 24%|██▎       | 727/3065 [02:25<07:47,  5.00it/s] 24%|██▍       | 728/3065 [02:25<07:47,  5.00it/s] 24%|██▍       | 729/3065 [02:25<07:46,  5.00it/s] 24%|██▍       | 730/3065 [02:25<07:46,  5.00it/s] 24%|██▍       | 731/3065 [02:26<07:46,  5.00it/s] 24%|██▍       | 732/3065 [02:26<07:46,  5.00it/s] 24%|██▍       | 733/3065 [02:26<07:46,  5.00it/s] 24%|██▍       | 734/3065 [02:26<07:46,  5.00it/s] 24%|██▍       | 735/3065 [02:26<07:46,  5.00it/s] 24%|██▍       | 736/3065 [02:27<07:45,  5.00it/s] 24%|██▍       | 737/3065 [02:27<07:45,  5.00it/s] 24%|██▍       | 738/3065 [02:27<07:45,  5.00it/s] 24%|██▍       | 739/3065 [02:27<07:44,  5.00it/s] 24%|██▍       | 740/3065 [02:27<07:44,  5.01it/s] 24%|██▍       | 741/3065 [02:28<07:44,  5.01it/s] 24%|██▍       | 742/3065 [02:28<07:44,  5.00it/s] 24%|██▍       | 743/3065 [02:28<07:44,  5.00it/s] 24%|██▍       | 744/3065 [02:28<07:43,  5.00it/s] 24%|██▍       | 745/3065 [02:28<07:43,  5.00it/s] 24%|██▍       | 746/3065 [02:29<07:43,  5.00it/s] 24%|██▍       | 747/3065 [02:29<07:43,  5.00it/s] 24%|██▍       | 748/3065 [02:29<07:43,  5.00it/s] 24%|██▍       | 749/3065 [02:29<07:42,  5.00it/s] 24%|██▍       | 750/3065 [02:29<07:42,  5.00it/s] 25%|██▍       | 751/3065 [02:30<07:42,  5.00it/s] 25%|██▍       | 752/3065 [02:30<09:02,  4.26it/s] 25%|██▍       | 753/3065 [02:30<08:35,  4.49it/s] 25%|██▍       | 754/3065 [02:30<08:16,  4.65it/s] 25%|██▍       | 755/3065 [02:31<08:02,  4.79it/s] 25%|██▍       | 756/3065 [02:31<07:54,  4.86it/s] 25%|██▍       | 757/3065 [02:31<07:50,  4.91it/s] 25%|██▍       | 758/3065 [02:31<07:47,  4.94it/s] 25%|██▍       | 759/3065 [02:31<07:45,  4.96it/s] 25%|██▍       | 760/3065 [02:32<07:43,  4.97it/s] 25%|██▍       | 761/3065 [02:32<07:42,  4.98it/s] 25%|██▍       | 762/3065 [02:32<07:41,  4.99it/s] 25%|██▍       | 763/3065 [02:32<07:41,  4.99it/s] 25%|██▍       | 764/3065 [02:32<07:40,  4.99it/s] 25%|██▍       | 765/3065 [02:33<07:40,  5.00it/s] 25%|██▍       | 766/3065 [02:33<07:39,  5.00it/s] 25%|██▌       | 767/3065 [02:33<07:39,  5.00it/s] 25%|██▌       | 768/3065 [02:33<07:39,  5.00it/s] 25%|██▌       | 769/3065 [02:33<07:39,  5.00it/s] 25%|██▌       | 770/3065 [02:34<07:39,  5.00it/s] 25%|██▌       | 771/3065 [02:34<07:38,  5.00it/s] 25%|██▌       | 772/3065 [02:34<07:38,  5.00it/s] 25%|██▌       | 773/3065 [02:34<07:38,  5.00it/s] 25%|██▌       | 774/3065 [02:34<07:38,  5.00it/s] 25%|██▌       | 775/3065 [02:35<07:37,  5.00it/s] 25%|██▌       | 776/3065 [02:35<07:37,  5.00it/s] 25%|██▌       | 777/3065 [02:35<07:37,  5.00it/s] 25%|██▌       | 778/3065 [02:35<07:37,  5.00it/s] 25%|██▌       | 779/3065 [02:35<07:37,  5.00it/s] 25%|██▌       | 780/3065 [02:36<07:37,  5.00it/s] 25%|██▌       | 781/3065 [02:36<07:36,  5.00it/s] 26%|██▌       | 782/3065 [02:36<07:36,  5.00it/s] 26%|██▌       | 783/3065 [02:36<07:36,  5.00it/s] 26%|██▌       | 784/3065 [02:36<07:36,  5.00it/s] 26%|██▌       | 785/3065 [02:37<07:35,  5.00it/s] 26%|██▌       | 786/3065 [02:37<07:35,  5.00it/s] 26%|██▌       | 787/3065 [02:37<07:35,  5.01it/s] 26%|██▌       | 788/3065 [02:37<07:35,  5.00it/s] 26%|██▌       | 789/3065 [02:37<07:35,  5.00it/s] 26%|██▌       | 790/3065 [02:38<07:35,  5.00it/s] 26%|██▌       | 791/3065 [02:38<07:34,  5.00it/s] 26%|██▌       | 792/3065 [02:38<07:34,  5.00it/s] 26%|██▌       | 793/3065 [02:38<07:34,  5.00it/s] 26%|██▌       | 794/3065 [02:38<07:34,  5.00it/s] 26%|██▌       | 795/3065 [02:39<07:33,  5.01it/s] 26%|██▌       | 796/3065 [02:39<07:33,  5.00it/s] 26%|██▌       | 797/3065 [02:39<07:33,  5.00it/s] 26%|██▌       | 798/3065 [02:39<07:33,  5.00it/s] 26%|██▌       | 799/3065 [02:39<07:33,  5.00it/s] 26%|██▌       | 800/3065 [02:40<07:32,  5.00it/s] 26%|██▌       | 801/3065 [02:40<07:32,  5.00it/s] 26%|██▌       | 802/3065 [02:40<07:32,  5.00it/s] 26%|██▌       | 803/3065 [02:40<07:31,  5.00it/s] 26%|██▌       | 804/3065 [02:40<07:31,  5.00it/s] 26%|██▋       | 805/3065 [02:41<07:31,  5.00it/s] 26%|██▋       | 806/3065 [02:41<07:31,  5.00it/s] 26%|██▋       | 807/3065 [02:41<07:31,  5.00it/s] 26%|██▋       | 808/3065 [02:41<07:31,  5.00it/s] 26%|██▋       | 809/3065 [02:41<07:31,  5.00it/s] 26%|██▋       | 810/3065 [02:42<07:30,  5.00it/s] 26%|██▋       | 811/3065 [02:42<07:30,  5.00it/s] 26%|██▋       | 812/3065 [02:42<07:30,  5.00it/s] 27%|██▋       | 813/3065 [02:42<07:30,  5.00it/s] 27%|██▋       | 814/3065 [02:42<07:30,  5.00it/s] 27%|██▋       | 815/3065 [02:43<07:29,  5.00it/s] 27%|██▋       | 816/3065 [02:43<07:29,  5.00it/s] 27%|██▋       | 817/3065 [02:43<07:29,  5.00it/s] 27%|██▋       | 818/3065 [02:43<07:29,  5.00it/s] 27%|██▋       | 819/3065 [02:43<07:29,  5.00it/s] 27%|██▋       | 820/3065 [02:44<07:29,  5.00it/s] 27%|██▋       | 821/3065 [02:44<07:28,  5.00it/s] 27%|██▋       | 822/3065 [02:44<07:28,  5.00it/s] 27%|██▋       | 823/3065 [02:44<07:28,  5.00it/s] 27%|██▋       | 824/3065 [02:44<07:27,  5.00it/s] 27%|██▋       | 825/3065 [02:45<07:27,  5.00it/s] 27%|██▋       | 826/3065 [02:45<07:27,  5.00it/s] 27%|██▋       | 827/3065 [02:45<07:27,  5.00it/s] 27%|██▋       | 828/3065 [02:45<07:27,  5.00it/s] 27%|██▋       | 829/3065 [02:45<07:27,  5.00it/s] 27%|██▋       | 830/3065 [02:46<07:26,  5.00it/s] 27%|██▋       | 831/3065 [02:46<07:26,  5.01it/s] 27%|██▋       | 832/3065 [02:46<07:26,  5.00it/s] 27%|██▋       | 833/3065 [02:46<07:26,  5.00it/s] 27%|██▋       | 834/3065 [02:46<07:26,  5.00it/s] 27%|██▋       | 835/3065 [02:47<07:25,  5.00it/s] 27%|██▋       | 836/3065 [02:47<07:25,  5.00it/s] 27%|██▋       | 837/3065 [02:47<07:25,  5.00it/s] 27%|██▋       | 838/3065 [02:47<07:25,  5.00it/s] 27%|██▋       | 839/3065 [02:47<07:24,  5.00it/s] 27%|██▋       | 840/3065 [02:48<07:24,  5.00it/s] 27%|██▋       | 841/3065 [02:48<07:24,  5.00it/s] 27%|██▋       | 842/3065 [02:48<07:24,  5.00it/s] 28%|██▊       | 843/3065 [02:48<07:24,  5.00it/s] 28%|██▊       | 844/3065 [02:48<07:23,  5.01it/s] 28%|██▊       | 845/3065 [02:49<07:23,  5.00it/s] 28%|██▊       | 846/3065 [02:49<07:23,  5.00it/s] 28%|██▊       | 847/3065 [02:49<07:23,  5.00it/s] 28%|██▊       | 848/3065 [02:49<07:23,  5.00it/s] 28%|██▊       | 849/3065 [02:49<07:22,  5.01it/s] 28%|██▊       | 850/3065 [02:50<07:22,  5.00it/s] 28%|██▊       | 851/3065 [02:50<07:22,  5.00it/s] 28%|██▊       | 852/3065 [02:50<07:22,  5.00it/s] 28%|██▊       | 853/3065 [02:50<07:22,  5.00it/s] 28%|██▊       | 854/3065 [02:50<07:22,  5.00it/s] 28%|██▊       | 855/3065 [02:51<07:21,  5.00it/s] 28%|██▊       | 856/3065 [02:51<07:21,  5.00it/s] 28%|██▊       | 857/3065 [02:51<07:21,  5.00it/s] 28%|██▊       | 858/3065 [02:51<07:21,  5.00it/s] 28%|██▊       | 859/3065 [02:51<07:21,  5.00it/s] 28%|██▊       | 860/3065 [02:52<07:21,  5.00it/s] 28%|██▊       | 861/3065 [02:52<07:20,  5.00it/s] 28%|██▊       | 862/3065 [02:52<07:20,  5.00it/s] 28%|██▊       | 863/3065 [02:52<07:20,  5.00it/s] 28%|██▊       | 864/3065 [02:52<07:19,  5.00it/s] 28%|██▊       | 865/3065 [02:53<07:19,  5.00it/s] 28%|██▊       | 866/3065 [02:53<07:19,  5.00it/s] 28%|██▊       | 867/3065 [02:53<07:19,  5.00it/s] 28%|██▊       | 868/3065 [02:53<07:19,  5.00it/s] 28%|██▊       | 869/3065 [02:53<07:18,  5.00it/s] 28%|██▊       | 870/3065 [02:54<07:18,  5.00it/s] 28%|██▊       | 871/3065 [02:54<07:18,  5.00it/s] 28%|██▊       | 872/3065 [02:54<07:18,  5.00it/s] 28%|██▊       | 873/3065 [02:54<07:18,  5.00it/s] 29%|██▊       | 874/3065 [02:54<07:17,  5.00it/s] 29%|██▊       | 875/3065 [02:55<07:17,  5.00it/s] 29%|██▊       | 876/3065 [02:55<07:17,  5.00it/s] 29%|██▊       | 877/3065 [02:55<07:17,  5.00it/s] 29%|██▊       | 878/3065 [02:55<07:17,  5.00it/s] 29%|██▊       | 879/3065 [02:55<07:17,  5.00it/s] 29%|██▊       | 880/3065 [02:56<07:16,  5.00it/s] 29%|██▊       | 881/3065 [02:56<07:16,  5.00it/s] 29%|██▉       | 882/3065 [02:56<07:16,  5.00it/s] 29%|██▉       | 883/3065 [02:56<07:16,  5.00it/s] 29%|██▉       | 884/3065 [02:56<07:16,  5.00it/s] 29%|██▉       | 885/3065 [02:57<07:15,  5.00it/s] 29%|██▉       | 886/3065 [02:57<07:15,  5.00it/s] 29%|██▉       | 887/3065 [02:57<07:15,  5.00it/s] 29%|██▉       | 888/3065 [02:57<07:15,  5.00it/s] 29%|██▉       | 889/3065 [02:57<07:15,  5.00it/s] 29%|██▉       | 890/3065 [02:58<07:15,  5.00it/s] 29%|██▉       | 891/3065 [02:58<07:14,  5.00it/s] 29%|██▉       | 892/3065 [02:58<07:14,  5.00it/s] 29%|██▉       | 893/3065 [02:58<07:14,  5.00it/s] 29%|██▉       | 894/3065 [02:58<07:14,  5.00it/s] 29%|██▉       | 895/3065 [02:59<07:13,  5.00it/s] 29%|██▉       | 896/3065 [02:59<07:13,  5.00it/s] 29%|██▉       | 897/3065 [02:59<07:13,  5.00it/s] 29%|██▉       | 898/3065 [02:59<07:13,  5.00it/s] 29%|██▉       | 899/3065 [02:59<07:12,  5.00it/s] 29%|██▉       | 900/3065 [03:00<07:12,  5.00it/s] 29%|██▉       | 901/3065 [03:00<07:12,  5.00it/s] 29%|██▉       | 902/3065 [03:00<07:12,  5.00it/s] 29%|██▉       | 903/3065 [03:00<07:12,  5.00it/s] 29%|██▉       | 904/3065 [03:00<07:12,  5.00it/s] 30%|██▉       | 905/3065 [03:01<07:11,  5.00it/s] 30%|██▉       | 906/3065 [03:01<07:11,  5.00it/s] 30%|██▉       | 907/3065 [03:01<07:11,  5.00it/s] 30%|██▉       | 908/3065 [03:01<07:11,  5.00it/s] 30%|██▉       | 909/3065 [03:01<07:11,  5.00it/s] 30%|██▉       | 910/3065 [03:02<07:10,  5.00it/s] 30%|██▉       | 911/3065 [03:02<07:10,  5.00it/s] 30%|██▉       | 912/3065 [03:02<07:10,  5.00it/s] 30%|██▉       | 913/3065 [03:02<07:10,  5.00it/s] 30%|██▉       | 914/3065 [03:02<07:09,  5.01it/s] 30%|██▉       | 915/3065 [03:03<07:09,  5.01it/s] 30%|██▉       | 916/3065 [03:03<07:09,  5.00it/s] 30%|██▉       | 917/3065 [03:03<07:09,  5.00it/s] 30%|██▉       | 918/3065 [03:03<07:09,  5.00it/s] 30%|██▉       | 919/3065 [03:03<07:08,  5.00it/s] 30%|███       | 920/3065 [03:04<07:08,  5.00it/s] 30%|███       | 921/3065 [03:04<07:08,  5.00it/s] 30%|███       | 922/3065 [03:04<07:08,  5.00it/s] 30%|███       | 923/3065 [03:04<07:08,  5.00it/s] 30%|███       | 924/3065 [03:04<07:08,  4.99it/s] 30%|███       | 925/3065 [03:05<07:08,  4.99it/s] 30%|███       | 926/3065 [03:05<07:08,  5.00it/s] 30%|███       | 927/3065 [03:05<07:07,  5.00it/s] 30%|███       | 928/3065 [03:05<07:07,  5.00it/s] 30%|███       | 929/3065 [03:05<07:07,  5.00it/s] 30%|███       | 930/3065 [03:06<07:07,  5.00it/s] 30%|███       | 931/3065 [03:06<07:06,  5.00it/s] 30%|███       | 932/3065 [03:06<07:06,  5.00it/s] 30%|███       | 933/3065 [03:06<07:06,  5.00it/s] 30%|███       | 934/3065 [03:06<07:05,  5.00it/s] 31%|███       | 935/3065 [03:07<07:05,  5.01it/s] 31%|███       | 936/3065 [03:07<07:05,  5.01it/s] 31%|███       | 937/3065 [03:07<07:05,  5.01it/s] 31%|███       | 938/3065 [03:07<07:05,  5.00it/s] 31%|███       | 939/3065 [03:07<07:04,  5.00it/s] 31%|███       | 940/3065 [03:08<07:04,  5.00it/s] 31%|███       | 941/3065 [03:08<07:04,  5.00it/s] 31%|███       | 942/3065 [03:08<07:04,  5.00it/s] 31%|███       | 943/3065 [03:08<07:04,  5.00it/s] 31%|███       | 944/3065 [03:08<07:03,  5.00it/s] 31%|███       | 945/3065 [03:09<07:03,  5.00it/s] 31%|███       | 946/3065 [03:09<07:03,  5.00it/s] 31%|███       | 947/3065 [03:09<07:03,  5.00it/s] 31%|███       | 948/3065 [03:09<07:03,  5.00it/s] 31%|███       | 949/3065 [03:09<07:03,  5.00it/s] 31%|███       | 950/3065 [03:10<07:02,  5.00it/s] 31%|███       | 951/3065 [03:10<07:02,  5.00it/s] 31%|███       | 952/3065 [03:10<07:02,  5.00it/s] 31%|███       | 953/3065 [03:10<07:02,  5.00it/s] 31%|███       | 954/3065 [03:10<07:02,  5.00it/s] 31%|███       | 955/3065 [03:11<07:01,  5.00it/s] 31%|███       | 956/3065 [03:11<07:01,  5.00it/s] 31%|███       | 957/3065 [03:11<07:01,  5.00it/s] 31%|███▏      | 958/3065 [03:11<07:01,  5.00it/s] 31%|███▏      | 959/3065 [03:11<07:00,  5.00it/s] 31%|███▏      | 960/3065 [03:12<07:00,  5.00it/s] 31%|███▏      | 961/3065 [03:12<07:01,  5.00it/s] 31%|███▏      | 962/3065 [03:12<07:00,  5.00it/s] 31%|███▏      | 963/3065 [03:12<07:00,  5.00it/s] 31%|███▏      | 964/3065 [03:12<07:00,  5.00it/s] 31%|███▏      | 965/3065 [03:13<06:59,  5.00it/s] 32%|███▏      | 966/3065 [03:13<06:59,  5.00it/s] 32%|███▏      | 967/3065 [03:13<06:59,  5.00it/s] 32%|███▏      | 968/3065 [03:13<06:59,  5.00it/s] 32%|███▏      | 969/3065 [03:13<06:59,  5.00it/s] 32%|███▏      | 970/3065 [03:14<06:58,  5.00it/s] 32%|███▏      | 971/3065 [03:14<06:58,  5.00it/s] 32%|███▏      | 972/3065 [03:14<06:58,  5.00it/s] 32%|███▏      | 973/3065 [03:14<06:58,  5.00it/s] 32%|███▏      | 974/3065 [03:14<06:58,  5.00it/s] 32%|███▏      | 975/3065 [03:15<06:57,  5.00it/s] 32%|███▏      | 976/3065 [03:15<06:57,  5.00it/s] 32%|███▏      | 977/3065 [03:15<06:57,  5.00it/s] 32%|███▏      | 978/3065 [03:15<06:57,  5.00it/s] 32%|███▏      | 979/3065 [03:15<06:56,  5.00it/s] 32%|███▏      | 980/3065 [03:16<06:56,  5.00it/s] 32%|███▏      | 981/3065 [03:16<06:56,  5.00it/s] 32%|███▏      | 982/3065 [03:16<06:56,  5.00it/s] 32%|███▏      | 983/3065 [03:16<06:55,  5.01it/s] 32%|███▏      | 984/3065 [03:16<06:55,  5.01it/s] 32%|███▏      | 985/3065 [03:17<06:55,  5.00it/s] 32%|███▏      | 986/3065 [03:17<06:55,  5.01it/s] 32%|███▏      | 987/3065 [03:17<06:55,  5.00it/s] 32%|███▏      | 988/3065 [03:17<06:55,  5.00it/s] 32%|███▏      | 989/3065 [03:17<06:55,  5.00it/s] 32%|███▏      | 990/3065 [03:18<06:55,  5.00it/s] 32%|███▏      | 991/3065 [03:18<06:54,  5.00it/s] 32%|███▏      | 992/3065 [03:18<06:54,  5.00it/s] 32%|███▏      | 993/3065 [03:18<06:54,  5.00it/s] 32%|███▏      | 994/3065 [03:18<06:53,  5.00it/s] 32%|███▏      | 995/3065 [03:19<06:53,  5.00it/s] 32%|███▏      | 996/3065 [03:19<06:53,  5.00it/s] 33%|███▎      | 997/3065 [03:19<06:53,  5.00it/s] 33%|███▎      | 998/3065 [03:19<06:53,  5.00it/s] 33%|███▎      | 999/3065 [03:19<06:53,  5.00it/s] 33%|███▎      | 1000/3065 [03:20<06:52,  5.00it/s] 33%|███▎      | 1001/3065 [03:20<06:52,  5.00it/s] 33%|███▎      | 1002/3065 [03:20<06:52,  5.00it/s] 33%|███▎      | 1003/3065 [03:20<06:52,  5.00it/s] 33%|███▎      | 1004/3065 [03:20<06:52,  5.00it/s] 33%|███▎      | 1005/3065 [03:21<06:51,  5.00it/s] 33%|███▎      | 1006/3065 [03:21<06:51,  5.00it/s] 33%|███▎      | 1007/3065 [03:21<06:51,  5.00it/s] 33%|███▎      | 1008/3065 [03:21<06:51,  5.00it/s] 33%|███▎      | 1009/3065 [03:21<06:51,  5.00it/s] 33%|███▎      | 1010/3065 [03:22<06:50,  5.00it/s] 33%|███▎      | 1011/3065 [03:22<06:50,  5.00it/s] 33%|███▎      | 1012/3065 [03:22<06:50,  5.00it/s] 33%|███▎      | 1013/3065 [03:22<06:50,  5.00it/s] 33%|███▎      | 1014/3065 [03:22<06:50,  5.00it/s] 33%|███▎      | 1015/3065 [03:23<06:49,  5.00it/s] 33%|███▎      | 1016/3065 [03:23<06:49,  5.00it/s] 33%|███▎      | 1017/3065 [03:23<06:49,  5.00it/s] 33%|███▎      | 1018/3065 [03:23<06:49,  5.00it/s] 33%|███▎      | 1019/3065 [03:23<06:48,  5.01it/s] 33%|███▎      | 1020/3065 [03:24<06:48,  5.00it/s] 33%|███▎      | 1021/3065 [03:24<06:48,  5.00it/s] 33%|███▎      | 1022/3065 [03:24<06:48,  5.00it/s] 33%|███▎      | 1023/3065 [03:24<06:48,  5.00it/s] 33%|███▎      | 1024/3065 [03:24<06:47,  5.00it/s] 33%|███▎      | 1025/3065 [03:25<06:47,  5.00it/s] 33%|███▎      | 1026/3065 [03:25<06:47,  5.00it/s] 34%|███▎      | 1027/3065 [03:25<06:47,  5.00it/s] 34%|███▎      | 1028/3065 [03:25<06:47,  5.00it/s] 34%|███▎      | 1029/3065 [03:25<06:47,  5.00it/s] 34%|███▎      | 1030/3065 [03:26<06:47,  5.00it/s] 34%|███▎      | 1031/3065 [03:26<06:46,  5.00it/s] 34%|███▎      | 1032/3065 [03:26<06:46,  5.00it/s] 34%|███▎      | 1033/3065 [03:26<06:46,  5.00it/s] 34%|███▎      | 1034/3065 [03:26<06:46,  5.00it/s] 34%|███▍      | 1035/3065 [03:27<06:45,  5.00it/s] 34%|███▍      | 1036/3065 [03:27<06:45,  5.00it/s] 34%|███▍      | 1037/3065 [03:27<06:45,  5.00it/s] 34%|███▍      | 1038/3065 [03:27<06:45,  5.00it/s] 34%|███▍      | 1039/3065 [03:27<06:44,  5.01it/s] 34%|███▍      | 1040/3065 [03:28<06:44,  5.00it/s] 34%|███▍      | 1041/3065 [03:28<06:44,  5.00it/s] 34%|███▍      | 1042/3065 [03:28<06:44,  5.00it/s] 34%|███▍      | 1043/3065 [03:28<06:44,  5.00it/s] 34%|███▍      | 1044/3065 [03:28<06:44,  5.00it/s] 34%|███▍      | 1045/3065 [03:29<06:44,  5.00it/s] 34%|███▍      | 1046/3065 [03:29<06:44,  5.00it/s] 34%|███▍      | 1047/3065 [03:29<06:43,  5.00it/s] 34%|███▍      | 1048/3065 [03:29<06:43,  5.00it/s] 34%|███▍      | 1049/3065 [03:29<06:42,  5.00it/s] 34%|███▍      | 1050/3065 [03:30<06:42,  5.00it/s] 34%|███▍      | 1051/3065 [03:30<06:42,  5.00it/s] 34%|███▍      | 1052/3065 [03:30<06:42,  5.00it/s] 34%|███▍      | 1053/3065 [03:30<06:42,  5.00it/s] 34%|███▍      | 1054/3065 [03:30<06:42,  5.00it/s] 34%|███▍      | 1055/3065 [03:31<06:41,  5.00it/s] 34%|███▍      | 1056/3065 [03:31<06:41,  5.00it/s] 34%|███▍      | 1057/3065 [03:31<06:41,  5.00it/s] 35%|███▍      | 1058/3065 [03:31<06:41,  5.00it/s] 35%|███▍      | 1059/3065 [03:31<06:41,  5.00it/s] 35%|███▍      | 1060/3065 [03:32<06:40,  5.00it/s] 35%|███▍      | 1061/3065 [03:32<06:40,  5.00it/s] 35%|███▍      | 1062/3065 [03:32<06:40,  5.00it/s] 35%|███▍      | 1063/3065 [03:32<06:40,  5.00it/s] 35%|███▍      | 1064/3065 [03:32<06:40,  5.00it/s] 35%|███▍      | 1065/3065 [03:33<06:39,  5.00it/s] 35%|███▍      | 1066/3065 [03:33<06:39,  5.00it/s] 35%|███▍      | 1067/3065 [03:33<06:39,  5.00it/s] 35%|███▍      | 1068/3065 [03:33<06:39,  5.00it/s] 35%|███▍      | 1069/3065 [03:33<06:39,  5.00it/s] 35%|███▍      | 1070/3065 [03:34<06:38,  5.00it/s] 35%|███▍      | 1071/3065 [03:34<06:38,  5.00it/s] 35%|███▍      | 1072/3065 [03:34<06:38,  5.00it/s] 35%|███▌      | 1073/3065 [03:34<06:38,  5.00it/s] 35%|███▌      | 1074/3065 [03:34<06:37,  5.00it/s] 35%|███▌      | 1075/3065 [03:35<06:37,  5.00it/s] 35%|███▌      | 1076/3065 [03:35<06:37,  5.00it/s] 35%|███▌      | 1077/3065 [03:35<06:37,  5.00it/s] 35%|███▌      | 1078/3065 [03:35<06:37,  5.00it/s] 35%|███▌      | 1079/3065 [03:35<06:37,  5.00it/s] 35%|███▌      | 1080/3065 [03:36<06:36,  5.00it/s] 35%|███▌      | 1081/3065 [03:36<06:36,  5.00it/s] 35%|███▌      | 1082/3065 [03:36<06:36,  5.00it/s] 35%|███▌      | 1083/3065 [03:36<06:36,  5.00it/s] 35%|███▌      | 1084/3065 [03:36<06:36,  5.00it/s] 35%|███▌      | 1085/3065 [03:37<06:36,  5.00it/s] 35%|███▌      | 1086/3065 [03:37<06:35,  5.00it/s] 35%|███▌      | 1087/3065 [03:37<06:35,  5.00it/s] 35%|███▌      | 1088/3065 [03:37<06:35,  5.00it/s] 36%|███▌      | 1089/3065 [03:37<06:34,  5.00it/s] 36%|███▌      | 1090/3065 [03:38<06:34,  5.01it/s] 36%|███▌      | 1091/3065 [03:38<06:34,  5.00it/s] 36%|███▌      | 1092/3065 [03:38<06:34,  5.00it/s] 36%|███▌      | 1093/3065 [03:38<06:34,  5.00it/s] 36%|███▌      | 1094/3065 [03:38<06:34,  5.00it/s] 36%|███▌      | 1095/3065 [03:39<06:33,  5.00it/s] 36%|███▌      | 1096/3065 [03:39<06:33,  5.00it/s] 36%|███▌      | 1097/3065 [03:39<06:33,  5.00it/s] 36%|███▌      | 1098/3065 [03:39<06:33,  5.00it/s] 36%|███▌      | 1099/3065 [03:39<06:33,  5.00it/s] 36%|███▌      | 1100/3065 [03:40<06:32,  5.00it/s] 36%|███▌      | 1101/3065 [03:40<06:32,  5.00it/s] 36%|███▌      | 1102/3065 [03:40<06:32,  5.00it/s] 36%|███▌      | 1103/3065 [03:40<06:32,  5.00it/s] 36%|███▌      | 1104/3065 [03:40<06:31,  5.00it/s] 36%|███▌      | 1105/3065 [03:41<06:31,  5.00it/s] 36%|███▌      | 1106/3065 [03:41<06:31,  5.00it/s] 36%|███▌      | 1107/3065 [03:41<06:31,  5.00it/s] 36%|███▌      | 1108/3065 [03:41<06:31,  5.00it/s] 36%|███▌      | 1109/3065 [03:41<06:31,  5.00it/s] 36%|███▌      | 1110/3065 [03:42<06:30,  5.00it/s] 36%|███▌      | 1111/3065 [03:42<06:30,  5.00it/s] 36%|███▋      | 1112/3065 [03:42<06:30,  5.00it/s] 36%|███▋      | 1113/3065 [03:42<06:30,  5.00it/s] 36%|███▋      | 1114/3065 [03:42<06:29,  5.00it/s] 36%|███▋      | 1115/3065 [03:43<06:29,  5.00it/s] 36%|███▋      | 1116/3065 [03:43<06:29,  5.00it/s] 36%|███▋      | 1117/3065 [03:43<06:29,  5.00it/s] 36%|███▋      | 1118/3065 [03:43<06:29,  5.00it/s] 37%|███▋      | 1119/3065 [03:43<06:29,  5.00it/s] 37%|███▋      | 1120/3065 [03:44<06:29,  5.00it/s] 37%|███▋      | 1121/3065 [03:44<06:28,  5.00it/s] 37%|███▋      | 1122/3065 [03:44<06:28,  5.00it/s] 37%|███▋      | 1123/3065 [03:44<06:28,  5.00it/s] 37%|███▋      | 1124/3065 [03:44<06:28,  5.00it/s] 37%|███▋      | 1125/3065 [03:45<06:27,  5.00it/s] 37%|███▋      | 1126/3065 [03:45<06:27,  5.00it/s] 37%|███▋      | 1127/3065 [03:45<06:27,  5.00it/s] 37%|███▋      | 1128/3065 [03:45<06:27,  5.00it/s] 37%|███▋      | 1129/3065 [03:45<06:27,  5.00it/s] 37%|███▋      | 1130/3065 [03:46<06:27,  5.00it/s] 37%|███▋      | 1131/3065 [03:46<06:26,  5.00it/s] 37%|███▋      | 1132/3065 [03:46<06:26,  5.00it/s] 37%|███▋      | 1133/3065 [03:46<06:26,  5.00it/s] 37%|███▋      | 1134/3065 [03:46<06:25,  5.01it/s] 37%|███▋      | 1135/3065 [03:47<06:25,  5.00it/s] 37%|███▋      | 1136/3065 [03:47<06:25,  5.00it/s] 37%|███▋      | 1137/3065 [03:47<06:25,  5.00it/s] 37%|███▋      | 1138/3065 [03:47<06:25,  5.00it/s] 37%|███▋      | 1139/3065 [03:47<06:25,  5.00it/s] 37%|███▋      | 1140/3065 [03:48<06:24,  5.00it/s] 37%|███▋      | 1141/3065 [03:48<06:24,  5.00it/s] 37%|███▋      | 1142/3065 [03:48<06:24,  5.00it/s] 37%|███▋      | 1143/3065 [03:48<06:24,  5.00it/s] 37%|███▋      | 1144/3065 [03:48<06:24,  5.00it/s] 37%|███▋      | 1145/3065 [03:49<06:23,  5.00it/s] 37%|███▋      | 1146/3065 [03:49<06:23,  5.00it/s] 37%|███▋      | 1147/3065 [03:49<06:23,  5.00it/s] 37%|███▋      | 1148/3065 [03:49<06:23,  5.00it/s] 37%|███▋      | 1149/3065 [03:49<06:23,  5.00it/s] 38%|███▊      | 1150/3065 [03:50<06:22,  5.00it/s] 38%|███▊      | 1151/3065 [03:50<06:22,  5.00it/s] 38%|███▊      | 1152/3065 [03:50<06:22,  5.00it/s] 38%|███▊      | 1153/3065 [03:50<06:22,  5.00it/s] 38%|███▊      | 1154/3065 [03:50<06:22,  5.00it/s] 38%|███▊      | 1155/3065 [03:51<06:21,  5.00it/s] 38%|███▊      | 1156/3065 [03:51<06:21,  5.00it/s] 38%|███▊      | 1157/3065 [03:51<06:21,  5.00it/s] 38%|███▊      | 1158/3065 [03:51<06:21,  5.00it/s] 38%|███▊      | 1159/3065 [03:51<06:20,  5.00it/s] 38%|███▊      | 1160/3065 [03:52<06:20,  5.00it/s] 38%|███▊      | 1161/3065 [03:52<06:20,  5.00it/s] 38%|███▊      | 1162/3065 [03:52<06:20,  5.00it/s] 38%|███▊      | 1163/3065 [03:52<06:20,  5.00it/s] 38%|███▊      | 1164/3065 [03:52<06:20,  5.00it/s] 38%|███▊      | 1165/3065 [03:53<06:19,  5.00it/s] 38%|███▊      | 1166/3065 [03:53<06:19,  5.00it/s] 38%|███▊      | 1167/3065 [03:53<06:19,  5.00it/s] 38%|███▊      | 1168/3065 [03:53<06:19,  5.00it/s] 38%|███▊      | 1169/3065 [03:53<06:19,  5.00it/s] 38%|███▊      | 1170/3065 [03:54<06:18,  5.00it/s] 38%|███▊      | 1171/3065 [03:54<06:18,  5.00it/s] 38%|███▊      | 1172/3065 [03:54<06:18,  5.00it/s] 38%|███▊      | 1173/3065 [03:54<06:18,  5.00it/s] 38%|███▊      | 1174/3065 [03:54<06:18,  5.00it/s] 38%|███▊      | 1175/3065 [03:55<06:18,  5.00it/s] 38%|███▊      | 1176/3065 [03:55<06:17,  5.00it/s] 38%|███▊      | 1177/3065 [03:55<06:17,  5.00it/s] 38%|███▊      | 1178/3065 [03:55<06:17,  5.00it/s] 38%|███▊      | 1179/3065 [03:55<06:16,  5.00it/s] 38%|███▊      | 1180/3065 [03:56<06:16,  5.00it/s] 39%|███▊      | 1181/3065 [03:56<06:16,  5.00it/s] 39%|███▊      | 1182/3065 [03:56<06:16,  5.00it/s] 39%|███▊      | 1183/3065 [03:56<06:16,  5.00it/s] 39%|███▊      | 1184/3065 [03:56<06:15,  5.00it/s] 39%|███▊      | 1185/3065 [03:57<06:15,  5.01it/s] 39%|███▊      | 1186/3065 [03:57<06:15,  5.00it/s] 39%|███▊      | 1187/3065 [03:57<06:15,  5.00it/s] 39%|███▉      | 1188/3065 [03:57<06:15,  5.00it/s] 39%|███▉      | 1189/3065 [03:57<06:15,  5.00it/s] 39%|███▉      | 1190/3065 [03:58<06:15,  5.00it/s] 39%|███▉      | 1191/3065 [03:58<06:14,  5.00it/s] 39%|███▉      | 1192/3065 [03:58<06:14,  5.00it/s] 39%|███▉      | 1193/3065 [03:58<06:14,  5.00it/s] 39%|███▉      | 1194/3065 [03:58<06:14,  5.00it/s] 39%|███▉      | 1195/3065 [03:59<06:13,  5.00it/s] 39%|███▉      | 1196/3065 [03:59<06:13,  5.00it/s] 39%|███▉      | 1197/3065 [03:59<06:13,  5.00it/s] 39%|███▉      | 1198/3065 [03:59<06:13,  5.00it/s] 39%|███▉      | 1199/3065 [03:59<06:13,  5.00it/s] 39%|███▉      | 1200/3065 [04:00<06:12,  5.00it/s] 39%|███▉      | 1201/3065 [04:00<06:12,  5.01it/s] 39%|███▉      | 1202/3065 [04:00<06:12,  5.00it/s] 39%|███▉      | 1203/3065 [04:00<06:12,  5.00it/s] 39%|███▉      | 1204/3065 [04:00<06:12,  5.00it/s] 39%|███▉      | 1205/3065 [04:01<06:11,  5.00it/s] 39%|███▉      | 1206/3065 [04:01<06:11,  5.00it/s] 39%|███▉      | 1207/3065 [04:01<06:11,  5.00it/s] 39%|███▉      | 1208/3065 [04:01<06:11,  5.00it/s] 39%|███▉      | 1209/3065 [04:01<06:11,  5.00it/s] 39%|███▉      | 1210/3065 [04:02<06:10,  5.00it/s] 40%|███▉      | 1211/3065 [04:02<06:10,  5.00it/s] 40%|███▉      | 1212/3065 [04:02<06:10,  5.00it/s] 40%|███▉      | 1213/3065 [04:02<06:10,  5.00it/s] 40%|███▉      | 1214/3065 [04:02<06:10,  5.00it/s] 40%|███▉      | 1215/3065 [04:03<06:09,  5.00it/s] 40%|███▉      | 1216/3065 [04:03<06:09,  5.00it/s] 40%|███▉      | 1217/3065 [04:03<06:09,  5.00it/s] 40%|███▉      | 1218/3065 [04:03<06:09,  5.00it/s] 40%|███▉      | 1219/3065 [04:03<06:09,  5.00it/s] 40%|███▉      | 1220/3065 [04:04<06:08,  5.00it/s] 40%|███▉      | 1221/3065 [04:04<06:08,  5.00it/s] 40%|███▉      | 1222/3065 [04:04<06:08,  5.00it/s] 40%|███▉      | 1223/3065 [04:04<06:08,  5.00it/s] 40%|███▉      | 1224/3065 [04:04<06:07,  5.00it/s] 40%|███▉      | 1225/3065 [04:05<06:07,  5.00it/s] 40%|████      | 1226/3065 [04:05<06:07,  5.00it/s] 40%|████      | 1227/3065 [04:05<06:07,  5.00it/s] 40%|████      | 1228/3065 [04:05<06:07,  5.00it/s] 40%|████      | 1229/3065 [04:05<06:06,  5.01it/s] 40%|████      | 1230/3065 [04:06<06:06,  5.00it/s] 40%|████      | 1231/3065 [04:06<06:06,  5.00it/s] 40%|████      | 1232/3065 [04:06<06:06,  5.00it/s] 40%|████      | 1233/3065 [04:06<06:06,  5.00it/s] 40%|████      | 1234/3065 [04:06<06:06,  5.00it/s] 40%|████      | 1235/3065 [04:07<06:05,  5.00it/s] 40%|████      | 1236/3065 [04:07<06:05,  5.00it/s] 40%|████      | 1237/3065 [04:07<06:05,  5.00it/s] 40%|████      | 1238/3065 [04:07<06:05,  5.00it/s] 40%|████      | 1239/3065 [04:07<06:05,  5.00it/s] 40%|████      | 1240/3065 [04:08<06:05,  5.00it/s] 40%|████      | 1241/3065 [04:08<06:04,  5.00it/s] 41%|████      | 1242/3065 [04:08<06:04,  5.00it/s] 41%|████      | 1243/3065 [04:08<06:04,  5.00it/s] 41%|████      | 1244/3065 [04:08<06:03,  5.00it/s] 41%|████      | 1245/3065 [04:09<06:03,  5.00it/s] 41%|████      | 1246/3065 [04:09<06:03,  5.00it/s] 41%|████      | 1247/3065 [04:09<06:03,  5.00it/s] 41%|████      | 1248/3065 [04:09<06:03,  5.00it/s] 41%|████      | 1249/3065 [04:09<06:02,  5.00it/s] 41%|████      | 1250/3065 [04:10<06:02,  5.00it/s] 41%|████      | 1251/3065 [04:10<06:02,  5.00it/s] 41%|████      | 1252/3065 [04:10<06:02,  5.00it/s] 41%|████      | 1253/3065 [04:10<06:02,  5.00it/s] 41%|████      | 1254/3065 [04:10<06:02,  5.00it/s] 41%|████      | 1255/3065 [04:11<06:01,  5.00it/s] 41%|████      | 1256/3065 [04:11<06:01,  5.00it/s] 41%|████      | 1257/3065 [04:11<06:01,  5.00it/s] 41%|████      | 1258/3065 [04:11<06:00,  5.01it/s] 41%|████      | 1259/3065 [04:11<06:00,  5.00it/s] 41%|████      | 1260/3065 [04:12<06:00,  5.00it/s] 41%|████      | 1261/3065 [04:12<06:00,  5.00it/s] 41%|████      | 1262/3065 [04:12<06:00,  5.00it/s] 41%|████      | 1263/3065 [04:12<06:00,  5.00it/s] 41%|████      | 1264/3065 [04:12<06:00,  5.00it/s] 41%|████▏     | 1265/3065 [04:13<05:59,  5.00it/s] 41%|████▏     | 1266/3065 [04:13<05:59,  5.00it/s] 41%|████▏     | 1267/3065 [04:13<05:59,  5.00it/s] 41%|████▏     | 1268/3065 [04:13<05:59,  5.00it/s] 41%|████▏     | 1269/3065 [04:13<05:59,  5.00it/s] 41%|████▏     | 1270/3065 [04:14<05:58,  5.00it/s] 41%|████▏     | 1271/3065 [04:14<05:58,  5.01it/s] 42%|████▏     | 1272/3065 [04:14<05:58,  5.01it/s] 42%|████▏     | 1273/3065 [04:14<05:58,  5.00it/s] 42%|████▏     | 1274/3065 [04:14<05:58,  5.00it/s] 42%|████▏     | 1275/3065 [04:15<05:58,  5.00it/s] 42%|████▏     | 1276/3065 [04:15<05:57,  5.00it/s] 42%|████▏     | 1277/3065 [04:15<05:57,  5.00it/s] 42%|████▏     | 1278/3065 [04:15<05:57,  5.00it/s] 42%|████▏     | 1279/3065 [04:15<05:57,  5.00it/s] 42%|████▏     | 1280/3065 [04:16<05:56,  5.00it/s] 42%|████▏     | 1281/3065 [04:16<05:56,  5.00it/s] 42%|████▏     | 1282/3065 [04:16<05:56,  5.00it/s] 42%|████▏     | 1283/3065 [04:16<05:56,  5.00it/s] 42%|████▏     | 1284/3065 [04:16<05:55,  5.01it/s] 42%|████▏     | 1285/3065 [04:17<05:55,  5.00it/s] 42%|████▏     | 1286/3065 [04:17<05:55,  5.00it/s] 42%|████▏     | 1287/3065 [04:17<05:56,  4.99it/s] 42%|████▏     | 1288/3065 [04:17<05:55,  5.00it/s] 42%|████▏     | 1289/3065 [04:17<05:55,  5.00it/s] 42%|████▏     | 1290/3065 [04:18<05:55,  5.00it/s] 42%|████▏     | 1291/3065 [04:18<05:54,  5.00it/s] 42%|████▏     | 1292/3065 [04:18<05:54,  5.00it/s] 42%|████▏     | 1293/3065 [04:18<05:54,  5.00it/s] 42%|████▏     | 1294/3065 [04:18<05:54,  5.00it/s] 42%|████▏     | 1295/3065 [04:19<05:53,  5.00it/s] 42%|████▏     | 1296/3065 [04:19<05:53,  5.00it/s] 42%|████▏     | 1297/3065 [04:19<05:53,  5.00it/s] 42%|████▏     | 1298/3065 [04:19<05:53,  5.00it/s] 42%|████▏     | 1299/3065 [04:19<05:53,  5.00it/s] 42%|████▏     | 1300/3065 [04:20<05:53,  5.00it/s] 42%|████▏     | 1301/3065 [04:20<05:52,  5.00it/s] 42%|████▏     | 1302/3065 [04:20<05:52,  5.00it/s] 43%|████▎     | 1303/3065 [04:20<05:52,  5.00it/s] 43%|████▎     | 1304/3065 [04:20<05:52,  5.00it/s] 43%|████▎     | 1305/3065 [04:21<05:51,  5.00it/s] 43%|████▎     | 1306/3065 [04:21<05:51,  5.00it/s] 43%|████▎     | 1307/3065 [04:21<05:50,  5.01it/s] 43%|████▎     | 1308/3065 [04:21<05:50,  5.01it/s] 43%|████▎     | 1309/3065 [04:21<05:50,  5.01it/s] 43%|████▎     | 1310/3065 [04:22<05:50,  5.01it/s] 43%|████▎     | 1311/3065 [04:22<05:50,  5.00it/s] 43%|████▎     | 1312/3065 [04:22<05:50,  5.00it/s] 43%|████▎     | 1313/3065 [04:22<05:50,  5.00it/s] 43%|████▎     | 1314/3065 [04:22<05:50,  5.00it/s] 43%|████▎     | 1315/3065 [04:23<05:49,  5.00it/s] 43%|████▎     | 1316/3065 [04:23<05:49,  5.01it/s] 43%|████▎     | 1317/3065 [04:23<05:49,  5.00it/s] 43%|████▎     | 1318/3065 [04:23<05:49,  5.00it/s] 43%|████▎     | 1319/3065 [04:23<05:48,  5.00it/s] 43%|████▎     | 1320/3065 [04:23<05:48,  5.01it/s] 43%|████▎     | 1321/3065 [04:24<05:48,  5.01it/s] 43%|████▎     | 1322/3065 [04:24<05:48,  5.01it/s] 43%|████▎     | 1323/3065 [04:24<05:48,  5.00it/s] 43%|████▎     | 1324/3065 [04:24<05:47,  5.00it/s] 43%|████▎     | 1325/3065 [04:24<05:47,  5.00it/s] 43%|████▎     | 1326/3065 [04:25<05:47,  5.01it/s] 43%|████▎     | 1327/3065 [04:25<05:47,  5.01it/s] 43%|████▎     | 1328/3065 [04:25<05:47,  5.00it/s] 43%|████▎     | 1329/3065 [04:25<05:47,  5.00it/s] 43%|████▎     | 1330/3065 [04:25<05:47,  5.00it/s] 43%|████▎     | 1331/3065 [04:26<05:47,  5.00it/s] 43%|████▎     | 1332/3065 [04:26<05:46,  5.00it/s] 43%|████▎     | 1333/3065 [04:26<05:46,  5.00it/s] 44%|████▎     | 1334/3065 [04:26<05:46,  5.00it/s] 44%|████▎     | 1335/3065 [04:26<05:46,  5.00it/s] 44%|████▎     | 1336/3065 [04:27<05:46,  5.00it/s] 44%|████▎     | 1337/3065 [04:27<05:45,  5.00it/s] 44%|████▎     | 1338/3065 [04:27<05:45,  5.00it/s] 44%|████▎     | 1339/3065 [04:27<05:45,  5.00it/s] 44%|████▎     | 1340/3065 [04:27<05:44,  5.00it/s] 44%|████▍     | 1341/3065 [04:28<05:44,  5.00it/s] 44%|████▍     | 1342/3065 [04:28<05:44,  5.00it/s] 44%|████▍     | 1343/3065 [04:28<05:44,  5.00it/s] 44%|████▍     | 1344/3065 [04:28<05:43,  5.00it/s] 44%|████▍     | 1345/3065 [04:28<05:43,  5.00it/s] 44%|████▍     | 1346/3065 [04:29<05:43,  5.00it/s] 44%|████▍     | 1347/3065 [04:29<05:43,  5.00it/s] 44%|████▍     | 1348/3065 [04:29<05:43,  5.00it/s] 44%|████▍     | 1349/3065 [04:29<05:43,  5.00it/s] 44%|████▍     | 1350/3065 [04:29<05:42,  5.00it/s] 44%|████▍     | 1351/3065 [04:30<05:42,  5.00it/s] 44%|████▍     | 1352/3065 [04:30<05:42,  5.00it/s] 44%|████▍     | 1353/3065 [04:30<05:42,  5.00it/s] 44%|████▍     | 1354/3065 [04:30<05:42,  5.00it/s] 44%|████▍     | 1355/3065 [04:30<05:41,  5.00it/s] 44%|████▍     | 1356/3065 [04:31<05:41,  5.00it/s] 44%|████▍     | 1357/3065 [04:31<05:41,  5.00it/s] 44%|████▍     | 1358/3065 [04:31<05:41,  5.00it/s] 44%|████▍     | 1359/3065 [04:31<05:41,  5.00it/s] 44%|████▍     | 1360/3065 [04:31<05:41,  5.00it/s] 44%|████▍     | 1361/3065 [04:32<05:40,  5.00it/s] 44%|████▍     | 1362/3065 [04:32<05:40,  5.00it/s] 44%|████▍     | 1363/3065 [04:32<05:40,  5.00it/s] 45%|████▍     | 1364/3065 [04:32<05:39,  5.00it/s] 45%|████▍     | 1365/3065 [04:32<05:39,  5.00it/s] 45%|████▍     | 1366/3065 [04:33<05:39,  5.00it/s] 45%|████▍     | 1367/3065 [04:33<05:39,  5.00it/s] 45%|████▍     | 1368/3065 [04:33<05:39,  5.00it/s] 45%|████▍     | 1369/3065 [04:33<05:39,  5.00it/s] 45%|████▍     | 1370/3065 [04:33<05:39,  5.00it/s] 45%|████▍     | 1371/3065 [04:34<05:38,  5.00it/s] 45%|████▍     | 1372/3065 [04:34<05:38,  5.00it/s] 45%|████▍     | 1373/3065 [04:34<05:38,  5.00it/s] 45%|████▍     | 1374/3065 [04:34<05:37,  5.01it/s] 45%|████▍     | 1375/3065 [04:34<05:37,  5.01it/s] 45%|████▍     | 1376/3065 [04:35<05:37,  5.00it/s] 45%|████▍     | 1377/3065 [04:35<05:37,  5.00it/s] 45%|████▍     | 1378/3065 [04:35<05:37,  5.00it/s] 45%|████▍     | 1379/3065 [04:35<05:37,  5.00it/s] 45%|████▌     | 1380/3065 [04:35<05:36,  5.00it/s] 45%|████▌     | 1381/3065 [04:36<05:36,  5.00it/s] 45%|████▌     | 1382/3065 [04:36<05:36,  5.00it/s] 45%|████▌     | 1383/3065 [04:36<05:36,  5.00it/s] 45%|████▌     | 1384/3065 [04:36<05:36,  5.00it/s] 45%|████▌     | 1385/3065 [04:36<05:35,  5.00it/s] 45%|████▌     | 1386/3065 [04:37<05:35,  5.00it/s] 45%|████▌     | 1387/3065 [04:37<05:35,  5.00it/s] 45%|████▌     | 1388/3065 [04:37<05:35,  5.00it/s] 45%|████▌     | 1389/3065 [04:37<05:35,  5.00it/s] 45%|████▌     | 1390/3065 [04:37<05:34,  5.00it/s] 45%|████▌     | 1391/3065 [04:38<05:34,  5.00it/s] 45%|████▌     | 1392/3065 [04:38<05:34,  5.00it/s] 45%|████▌     | 1393/3065 [04:38<05:34,  5.00it/s] 45%|████▌     | 1394/3065 [04:38<05:33,  5.00it/s] 46%|████▌     | 1395/3065 [04:38<05:33,  5.01it/s] 46%|████▌     | 1396/3065 [04:39<05:33,  5.00it/s] 46%|████▌     | 1397/3065 [04:39<05:33,  5.00it/s] 46%|████▌     | 1398/3065 [04:39<05:33,  5.00it/s] 46%|████▌     | 1399/3065 [04:39<05:33,  5.00it/s] 46%|████▌     | 1400/3065 [04:39<05:32,  5.00it/s] 46%|████▌     | 1401/3065 [04:40<05:32,  5.00it/s] 46%|████▌     | 1402/3065 [04:40<05:32,  5.00it/s] 46%|████▌     | 1403/3065 [04:40<05:32,  5.00it/s] 46%|████▌     | 1404/3065 [04:40<05:32,  5.00it/s] 46%|████▌     | 1405/3065 [04:40<05:31,  5.01it/s] 46%|████▌     | 1406/3065 [04:41<05:31,  5.01it/s] 46%|████▌     | 1407/3065 [04:41<05:31,  5.00it/s] 46%|████▌     | 1408/3065 [04:41<05:31,  5.00it/s] 46%|████▌     | 1409/3065 [04:41<05:31,  5.00it/s] 46%|████▌     | 1410/3065 [04:41<05:30,  5.00it/s] 46%|████▌     | 1411/3065 [04:42<05:30,  5.00it/s] 46%|████▌     | 1412/3065 [04:42<05:30,  5.00it/s] 46%|████▌     | 1413/3065 [04:42<05:30,  5.00it/s] 46%|████▌     | 1414/3065 [04:42<05:30,  5.00it/s] 46%|████▌     | 1415/3065 [04:42<05:30,  5.00it/s] 46%|████▌     | 1416/3065 [04:43<05:29,  5.00it/s] 46%|████▌     | 1417/3065 [04:43<05:29,  5.00it/s] 46%|████▋     | 1418/3065 [04:43<05:29,  5.00it/s] 46%|████▋     | 1419/3065 [04:43<05:29,  5.00it/s] 46%|████▋     | 1420/3065 [04:43<05:28,  5.00it/s] 46%|████▋     | 1421/3065 [04:44<05:28,  5.00it/s] 46%|████▋     | 1422/3065 [04:44<05:28,  5.00it/s] 46%|████▋     | 1423/3065 [04:44<05:28,  5.00it/s] 46%|████▋     | 1424/3065 [04:44<05:28,  5.00it/s] 46%|████▋     | 1425/3065 [04:44<05:28,  5.00it/s] 47%|████▋     | 1426/3065 [04:45<05:27,  5.00it/s] 47%|████▋     | 1427/3065 [04:45<05:27,  5.00it/s] 47%|████▋     | 1428/3065 [04:45<05:27,  5.00it/s] 47%|████▋     | 1429/3065 [04:45<05:27,  5.00it/s] 47%|████▋     | 1430/3065 [04:45<05:26,  5.00it/s] 47%|████▋     | 1431/3065 [04:46<05:26,  5.00it/s] 47%|████▋     | 1432/3065 [04:46<05:26,  5.00it/s] 47%|████▋     | 1433/3065 [04:46<05:26,  5.00it/s] 47%|████▋     | 1434/3065 [04:46<05:26,  5.00it/s] 47%|████▋     | 1435/3065 [04:46<05:25,  5.00it/s] 47%|████▋     | 1436/3065 [04:47<05:25,  5.00it/s] 47%|████▋     | 1437/3065 [04:47<05:25,  5.00it/s] 47%|████▋     | 1438/3065 [04:47<05:25,  5.00it/s] 47%|████▋     | 1439/3065 [04:47<05:25,  5.00it/s] 47%|████▋     | 1440/3065 [04:47<05:24,  5.00it/s] 47%|████▋     | 1441/3065 [04:48<05:24,  5.00it/s] 47%|████▋     | 1442/3065 [04:48<05:24,  5.00it/s] 47%|████▋     | 1443/3065 [04:48<05:24,  5.00it/s] 47%|████▋     | 1444/3065 [04:48<05:24,  5.00it/s] 47%|████▋     | 1445/3065 [04:48<05:23,  5.00it/s] 47%|████▋     | 1446/3065 [04:49<05:23,  5.00it/s] 47%|████▋     | 1447/3065 [04:49<05:23,  5.00it/s] 47%|████▋     | 1448/3065 [04:49<05:23,  5.00it/s] 47%|████▋     | 1449/3065 [04:49<05:22,  5.00it/s] 47%|████▋     | 1450/3065 [04:49<05:22,  5.01it/s] 47%|████▋     | 1451/3065 [04:50<05:22,  5.01it/s] 47%|████▋     | 1452/3065 [04:50<05:22,  5.01it/s] 47%|████▋     | 1453/3065 [04:50<05:21,  5.01it/s] 47%|████▋     | 1454/3065 [04:50<05:21,  5.01it/s] 47%|████▋     | 1455/3065 [04:50<05:21,  5.01it/s] 48%|████▊     | 1456/3065 [04:51<05:21,  5.00it/s] 48%|████▊     | 1457/3065 [04:51<05:21,  5.00it/s] 48%|████▊     | 1458/3065 [04:51<05:21,  5.00it/s] 48%|████▊     | 1459/3065 [04:51<05:21,  5.00it/s] 48%|████▊     | 1460/3065 [04:51<05:21,  5.00it/s] 48%|████▊     | 1461/3065 [04:52<05:20,  5.00it/s] 48%|████▊     | 1462/3065 [04:52<05:20,  5.00it/s] 48%|████▊     | 1463/3065 [04:52<05:20,  5.00it/s] 48%|████▊     | 1464/3065 [04:52<05:20,  5.00it/s] 48%|████▊     | 1465/3065 [04:52<05:19,  5.00it/s] 48%|████▊     | 1466/3065 [04:53<05:19,  5.00it/s] 48%|████▊     | 1467/3065 [04:53<05:19,  5.00it/s] 48%|████▊     | 1468/3065 [04:53<05:19,  5.00it/s] 48%|████▊     | 1469/3065 [04:53<05:18,  5.00it/s] 48%|████▊     | 1470/3065 [04:53<05:18,  5.01it/s] 48%|████▊     | 1471/3065 [04:54<05:18,  5.01it/s] 48%|████▊     | 1472/3065 [04:54<05:18,  5.00it/s] 48%|████▊     | 1473/3065 [04:54<05:18,  5.00it/s] 48%|████▊     | 1474/3065 [04:54<05:18,  5.00it/s] 48%|████▊     | 1475/3065 [04:54<05:17,  5.00it/s] 48%|████▊     | 1476/3065 [04:55<05:17,  5.00it/s] 48%|████▊     | 1477/3065 [04:55<05:17,  5.00it/s] 48%|████▊     | 1478/3065 [04:55<05:17,  5.00it/s] 48%|████▊     | 1479/3065 [04:55<05:17,  5.00it/s] 48%|████▊     | 1480/3065 [04:55<05:16,  5.00it/s] 48%|████▊     | 1481/3065 [04:56<05:16,  5.01it/s] 48%|████▊     | 1482/3065 [04:56<05:16,  5.00it/s] 48%|████▊     | 1483/3065 [04:56<05:16,  5.01it/s] 48%|████▊     | 1484/3065 [04:56<05:15,  5.01it/s] 48%|████▊     | 1485/3065 [04:56<05:15,  5.00it/s] 48%|████▊     | 1486/3065 [04:57<05:15,  5.00it/s] 49%|████▊     | 1487/3065 [04:57<05:15,  5.00it/s] 49%|████▊     | 1488/3065 [04:57<05:15,  5.00it/s] 49%|████▊     | 1489/3065 [04:57<05:15,  5.00it/s] 49%|████▊     | 1490/3065 [04:57<05:14,  5.00it/s] 49%|████▊     | 1491/3065 [04:58<05:14,  5.00it/s] 49%|████▊     | 1492/3065 [04:58<05:14,  5.00it/s] 49%|████▊     | 1493/3065 [04:58<05:14,  5.00it/s] 49%|████▊     | 1494/3065 [04:58<05:13,  5.01it/s] 49%|████▉     | 1495/3065 [04:58<05:13,  5.00it/s] 49%|████▉     | 1496/3065 [04:59<05:13,  5.01it/s] 49%|████▉     | 1497/3065 [04:59<05:13,  5.00it/s] 49%|████▉     | 1498/3065 [04:59<05:13,  5.00it/s] 49%|████▉     | 1499/3065 [04:59<05:13,  5.00it/s] 49%|████▉     | 1500/3065 [04:59<05:12,  5.00it/s] 49%|████▉     | 1501/3065 [05:00<05:12,  5.01it/s] 49%|████▉     | 1502/3065 [05:00<05:12,  5.01it/s] 49%|████▉     | 1503/3065 [05:00<05:12,  5.00it/s] 49%|████▉     | 1504/3065 [05:00<05:11,  5.00it/s] 49%|████▉     | 1505/3065 [05:00<05:11,  5.00it/s] 49%|████▉     | 1506/3065 [05:01<05:11,  5.00it/s] 49%|████▉     | 1507/3065 [05:01<05:11,  5.00it/s] 49%|████▉     | 1508/3065 [05:01<05:11,  5.00it/s] 49%|████▉     | 1509/3065 [05:01<05:11,  5.00it/s] 49%|████▉     | 1510/3065 [05:01<05:10,  5.00it/s] 49%|████▉     | 1511/3065 [05:02<05:10,  5.00it/s] 49%|████▉     | 1512/3065 [05:02<05:10,  5.00it/s] 49%|████▉     | 1513/3065 [05:02<05:10,  5.00it/s] 49%|████▉     | 1514/3065 [05:02<05:10,  5.00it/s] 49%|████▉     | 1515/3065 [05:02<05:10,  5.00it/s] 49%|████▉     | 1516/3065 [05:03<05:09,  5.00it/s] 49%|████▉     | 1517/3065 [05:03<05:09,  5.00it/s] 50%|████▉     | 1518/3065 [05:03<05:09,  5.00it/s] 50%|████▉     | 1519/3065 [05:03<05:09,  5.00it/s] 50%|████▉     | 1520/3065 [05:03<05:08,  5.00it/s] 50%|████▉     | 1521/3065 [05:04<05:08,  5.00it/s] 50%|████▉     | 1522/3065 [05:04<05:08,  5.00it/s] 50%|████▉     | 1523/3065 [05:04<05:08,  5.00it/s] 50%|████▉     | 1524/3065 [05:04<05:08,  5.00it/s] 50%|████▉     | 1525/3065 [05:04<05:08,  5.00it/s] 50%|████▉     | 1526/3065 [05:05<05:07,  5.00it/s] 50%|████▉     | 1527/3065 [05:05<05:07,  5.00it/s] 50%|████▉     | 1528/3065 [05:05<05:07,  5.00it/s] 50%|████▉     | 1529/3065 [05:05<05:07,  5.00it/s] 50%|████▉     | 1530/3065 [05:05<05:06,  5.00it/s] 50%|████▉     | 1531/3065 [05:06<05:06,  5.00it/s] 50%|████▉     | 1532/3065 [05:06<05:06,  5.00it/s] 50%|█████     | 1533/3065 [05:06<05:06,  5.00it/s] 50%|█████     | 1534/3065 [05:06<05:06,  5.00it/s] 50%|█████     | 1535/3065 [05:06<05:05,  5.00it/s] 50%|█████     | 1536/3065 [05:07<05:05,  5.00it/s] 50%|█████     | 1537/3065 [05:07<05:05,  5.01it/s] 50%|█████     | 1538/3065 [05:07<05:04,  5.01it/s] 50%|█████     | 1539/3065 [05:07<05:04,  5.01it/s] 50%|█████     | 1540/3065 [05:07<05:04,  5.01it/s] 50%|█████     | 1541/3065 [05:08<05:04,  5.01it/s] 50%|█████     | 1542/3065 [05:08<05:04,  5.00it/s] 50%|█████     | 1543/3065 [05:08<05:04,  5.00it/s] 50%|█████     | 1544/3065 [05:08<05:04,  5.00it/s] 50%|█████     | 1545/3065 [05:08<05:03,  5.00it/s] 50%|█████     | 1546/3065 [05:09<05:03,  5.00it/s] 50%|█████     | 1547/3065 [05:09<05:03,  5.00it/s] 51%|█████     | 1548/3065 [05:09<05:03,  5.00it/s] 51%|█████     | 1549/3065 [05:09<05:03,  5.00it/s] 51%|█████     | 1550/3065 [05:09<05:03,  5.00it/s] 51%|█████     | 1551/3065 [05:10<05:03,  4.99it/s] 51%|█████     | 1552/3065 [05:10<05:02,  5.00it/s] 51%|█████     | 1553/3065 [05:10<05:02,  5.00it/s] 51%|█████     | 1554/3065 [05:10<05:02,  5.00it/s] 51%|█████     | 1555/3065 [05:10<05:01,  5.00it/s] 51%|█████     | 1556/3065 [05:11<05:02,  5.00it/s] 51%|█████     | 1557/3065 [05:11<05:01,  5.00it/s] 51%|█████     | 1558/3065 [05:11<05:01,  5.00it/s] 51%|█████     | 1559/3065 [05:11<05:01,  5.00it/s] 51%|█████     | 1560/3065 [05:11<05:00,  5.00it/s] 51%|█████     | 1561/3065 [05:12<05:00,  5.01it/s] 51%|█████     | 1562/3065 [05:12<05:00,  5.01it/s] 51%|█████     | 1563/3065 [05:12<05:00,  5.00it/s] 51%|█████     | 1564/3065 [05:12<04:59,  5.01it/s] 51%|█████     | 1565/3065 [05:12<04:59,  5.01it/s] 51%|█████     | 1566/3065 [05:13<04:59,  5.01it/s] 51%|█████     | 1567/3065 [05:13<04:59,  5.01it/s] 51%|█████     | 1568/3065 [05:13<04:58,  5.01it/s] 51%|█████     | 1569/3065 [05:13<04:58,  5.01it/s] 51%|█████     | 1570/3065 [05:13<04:58,  5.01it/s] 51%|█████▏    | 1571/3065 [05:14<04:57,  5.01it/s] 51%|█████▏    | 1572/3065 [05:14<04:57,  5.02it/s] 51%|█████▏    | 1573/3065 [05:14<04:56,  5.03it/s] 51%|█████▏    | 1574/3065 [05:14<04:55,  5.05it/s] 51%|█████▏    | 1575/3065 [05:14<04:53,  5.08it/s] 51%|█████▏    | 1576/3065 [05:15<04:53,  5.07it/s] 51%|█████▏    | 1577/3065 [05:15<04:54,  5.05it/s] 51%|█████▏    | 1578/3065 [05:15<04:55,  5.04it/s] 52%|█████▏    | 1579/3065 [05:15<04:55,  5.03it/s] 52%|█████▏    | 1580/3065 [05:15<04:55,  5.02it/s] 52%|█████▏    | 1581/3065 [05:16<04:55,  5.02it/s] 52%|█████▏    | 1582/3065 [05:16<04:55,  5.02it/s] 52%|█████▏    | 1583/3065 [05:16<04:55,  5.01it/s] 52%|█████▏    | 1584/3065 [05:16<04:55,  5.01it/s] 52%|█████▏    | 1585/3065 [05:16<04:55,  5.01it/s] 52%|█████▏    | 1586/3065 [05:17<04:55,  5.00it/s] 52%|█████▏    | 1587/3065 [05:17<04:55,  5.00it/s] 52%|█████▏    | 1588/3065 [05:17<04:55,  5.00it/s] 52%|█████▏    | 1589/3065 [05:17<04:55,  5.00it/s] 52%|█████▏    | 1590/3065 [05:17<04:54,  5.00it/s] 52%|█████▏    | 1591/3065 [05:18<04:54,  5.01it/s] 52%|█████▏    | 1592/3065 [05:18<04:54,  5.00it/s] 52%|█████▏    | 1593/3065 [05:18<04:54,  5.00it/s] 52%|█████▏    | 1594/3065 [05:18<04:54,  5.00it/s] 52%|█████▏    | 1595/3065 [05:18<04:54,  5.00it/s] 52%|█████▏    | 1596/3065 [05:19<04:53,  5.00it/s] 52%|█████▏    | 1597/3065 [05:19<04:53,  5.01it/s] 52%|█████▏    | 1598/3065 [05:19<04:53,  5.01it/s] 52%|█████▏    | 1599/3065 [05:19<04:52,  5.01it/s] 52%|█████▏    | 1600/3065 [05:19<04:52,  5.01it/s] 52%|█████▏    | 1601/3065 [05:20<04:52,  5.01it/s] 52%|█████▏    | 1602/3065 [05:20<04:51,  5.01it/s] 52%|█████▏    | 1603/3065 [05:20<04:51,  5.02it/s] 52%|█████▏    | 1604/3065 [05:20<04:50,  5.04it/s] 52%|█████▏    | 1605/3065 [05:20<04:48,  5.06it/s] 52%|█████▏    | 1606/3065 [05:21<04:47,  5.08it/s] 52%|█████▏    | 1607/3065 [05:21<04:47,  5.06it/s] 52%|█████▏    | 1608/3065 [05:21<04:48,  5.05it/s] 52%|█████▏    | 1609/3065 [05:21<04:48,  5.04it/s] 53%|█████▎    | 1610/3065 [05:21<04:49,  5.03it/s] 53%|█████▎    | 1611/3065 [05:22<04:49,  5.02it/s] 53%|█████▎    | 1612/3065 [05:22<04:49,  5.02it/s] 53%|█████▎    | 1613/3065 [05:22<04:49,  5.01it/s] 53%|█████▎    | 1614/3065 [05:22<04:49,  5.02it/s] 53%|█████▎    | 1615/3065 [05:22<04:49,  5.01it/s] 53%|█████▎    | 1616/3065 [05:23<04:49,  5.01it/s] 53%|█████▎    | 1617/3065 [05:23<04:48,  5.02it/s] 53%|█████▎    | 1618/3065 [05:23<04:48,  5.01it/s] 53%|█████▎    | 1619/3065 [05:23<04:48,  5.02it/s] 53%|█████▎    | 1620/3065 [05:23<04:47,  5.02it/s] 53%|█████▎    | 1621/3065 [05:24<04:46,  5.04it/s] 53%|█████▎    | 1622/3065 [05:24<04:45,  5.06it/s] 53%|█████▎    | 1623/3065 [05:24<04:43,  5.08it/s] 53%|█████▎    | 1624/3065 [05:24<04:43,  5.07it/s] 53%|█████▎    | 1625/3065 [05:24<04:44,  5.06it/s] 53%|█████▎    | 1626/3065 [05:25<04:45,  5.04it/s] 53%|█████▎    | 1627/3065 [05:25<04:45,  5.03it/s] 53%|█████▎    | 1628/3065 [05:25<04:46,  5.02it/s] 53%|█████▎    | 1629/3065 [05:25<04:46,  5.02it/s] 53%|█████▎    | 1630/3065 [05:25<04:46,  5.01it/s] 53%|█████▎    | 1631/3065 [05:26<04:46,  5.01it/s] 53%|█████▎    | 1632/3065 [05:26<04:46,  5.01it/s] 53%|█████▎    | 1633/3065 [05:26<04:46,  5.00it/s] 53%|█████▎    | 1634/3065 [05:26<04:46,  5.00it/s] 53%|█████▎    | 1635/3065 [05:26<04:46,  5.00it/s] 53%|█████▎    | 1636/3065 [05:27<04:45,  5.00it/s] 53%|█████▎    | 1637/3065 [05:27<04:45,  5.00it/s] 53%|█████▎    | 1638/3065 [05:27<04:45,  5.00it/s] 53%|█████▎    | 1639/3065 [05:27<04:45,  5.00it/s] 54%|█████▎    | 1640/3065 [05:27<04:44,  5.00it/s] 54%|█████▎    | 1641/3065 [05:28<04:44,  5.00it/s] 54%|█████▎    | 1642/3065 [05:28<04:44,  5.00it/s] 54%|█████▎    | 1643/3065 [05:28<04:44,  5.00it/s] 54%|█████▎    | 1644/3065 [05:28<04:44,  5.00it/s] 54%|█████▎    | 1645/3065 [05:28<04:43,  5.00it/s] 54%|█████▎    | 1646/3065 [05:29<04:43,  5.00it/s] 54%|█████▎    | 1647/3065 [05:29<04:43,  5.00it/s] 54%|█████▍    | 1648/3065 [05:29<04:43,  5.00it/s] 54%|█████▍    | 1649/3065 [05:29<04:43,  5.00it/s] 54%|█████▍    | 1650/3065 [05:29<04:43,  5.00it/s] 54%|█████▍    | 1651/3065 [05:30<04:42,  5.00it/s] 54%|█████▍    | 1652/3065 [05:30<04:42,  5.00it/s] 54%|█████▍    | 1653/3065 [05:30<04:42,  5.00it/s] 54%|█████▍    | 1654/3065 [05:30<04:42,  5.00it/s] 54%|█████▍    | 1655/3065 [05:30<04:41,  5.00it/s] 54%|█████▍    | 1656/3065 [05:31<04:41,  5.00it/s] 54%|█████▍    | 1657/3065 [05:31<04:41,  5.00it/s] 54%|█████▍    | 1658/3065 [05:31<04:41,  5.00it/s] 54%|█████▍    | 1659/3065 [05:31<04:41,  5.00it/s] 54%|█████▍    | 1660/3065 [05:31<04:40,  5.00it/s] 54%|█████▍    | 1661/3065 [05:32<04:40,  5.00it/s] 54%|█████▍    | 1662/3065 [05:32<04:40,  5.00it/s] 54%|█████▍    | 1663/3065 [05:32<04:40,  5.00it/s] 54%|█████▍    | 1664/3065 [05:32<04:40,  5.00it/s] 54%|█████▍    | 1665/3065 [05:32<04:39,  5.00it/s] 54%|█████▍    | 1666/3065 [05:33<04:39,  5.00it/s] 54%|█████▍    | 1667/3065 [05:33<04:39,  5.00it/s] 54%|█████▍    | 1668/3065 [05:33<04:39,  5.00it/s] 54%|█████▍    | 1669/3065 [05:33<04:39,  5.00it/s] 54%|█████▍    | 1670/3065 [05:33<04:38,  5.00it/s] 55%|█████▍    | 1671/3065 [05:34<04:38,  5.00it/s] 55%|█████▍    | 1672/3065 [05:34<04:38,  5.00it/s] 55%|█████▍    | 1673/3065 [05:34<04:38,  5.00it/s] 55%|█████▍    | 1674/3065 [05:34<04:38,  5.00it/s] 55%|█████▍    | 1675/3065 [05:34<04:37,  5.00it/s] 55%|█████▍    | 1676/3065 [05:35<04:37,  5.00it/s] 55%|█████▍    | 1677/3065 [05:35<04:37,  5.00it/s] 55%|█████▍    | 1678/3065 [05:35<04:37,  5.00it/s] 55%|█████▍    | 1679/3065 [05:35<04:36,  5.01it/s] 55%|█████▍    | 1680/3065 [05:35<04:36,  5.01it/s] 55%|█████▍    | 1681/3065 [05:36<04:36,  5.01it/s] 55%|█████▍    | 1682/3065 [05:36<04:36,  5.01it/s] 55%|█████▍    | 1683/3065 [05:36<04:36,  5.01it/s] 55%|█████▍    | 1684/3065 [05:36<04:35,  5.01it/s] 55%|█████▍    | 1685/3065 [05:36<04:35,  5.00it/s] 55%|█████▌    | 1686/3065 [05:37<04:35,  5.01it/s] 55%|█████▌    | 1687/3065 [05:37<04:35,  5.01it/s] 55%|█████▌    | 1688/3065 [05:37<04:34,  5.01it/s] 55%|█████▌    | 1689/3065 [05:37<04:34,  5.01it/s] 55%|█████▌    | 1690/3065 [05:37<04:34,  5.01it/s] 55%|█████▌    | 1691/3065 [05:38<04:34,  5.01it/s] 55%|█████▌    | 1692/3065 [05:38<04:34,  5.01it/s] 55%|█████▌    | 1693/3065 [05:38<04:34,  5.01it/s] 55%|█████▌    | 1694/3065 [05:38<04:33,  5.01it/s] 55%|█████▌    | 1695/3065 [05:38<04:33,  5.01it/s] 55%|█████▌    | 1696/3065 [05:39<04:32,  5.02it/s] 55%|█████▌    | 1697/3065 [05:39<04:31,  5.04it/s] 55%|█████▌    | 1698/3065 [05:39<04:30,  5.06it/s] 55%|█████▌    | 1699/3065 [05:39<04:28,  5.08it/s] 55%|█████▌    | 1700/3065 [05:39<04:29,  5.06it/s] 55%|█████▌    | 1701/3065 [05:40<04:30,  5.05it/s] 56%|█████▌    | 1702/3065 [05:40<04:30,  5.04it/s] 56%|█████▌    | 1703/3065 [05:40<04:30,  5.03it/s] 56%|█████▌    | 1704/3065 [05:40<04:30,  5.03it/s] 56%|█████▌    | 1705/3065 [05:40<04:30,  5.02it/s] 56%|█████▌    | 1706/3065 [05:41<04:30,  5.02it/s] 56%|█████▌    | 1707/3065 [05:41<04:30,  5.02it/s] 56%|█████▌    | 1708/3065 [05:41<04:30,  5.02it/s] 56%|█████▌    | 1709/3065 [05:41<04:30,  5.02it/s] 56%|█████▌    | 1710/3065 [05:41<04:29,  5.03it/s] 56%|█████▌    | 1711/3065 [05:42<04:28,  5.05it/s] 56%|█████▌    | 1712/3065 [05:42<04:26,  5.07it/s] 56%|█████▌    | 1713/3065 [05:42<04:26,  5.08it/s] 56%|█████▌    | 1714/3065 [05:42<04:27,  5.06it/s] 56%|█████▌    | 1715/3065 [05:42<04:27,  5.04it/s] 56%|█████▌    | 1716/3065 [05:43<04:27,  5.03it/s] 56%|█████▌    | 1717/3065 [05:43<04:28,  5.03it/s] 56%|█████▌    | 1718/3065 [05:43<04:28,  5.02it/s] 56%|█████▌    | 1719/3065 [05:43<04:28,  5.02it/s] 56%|█████▌    | 1720/3065 [05:43<04:28,  5.01it/s] 56%|█████▌    | 1721/3065 [05:44<04:28,  5.01it/s] 56%|█████▌    | 1722/3065 [05:44<04:28,  5.01it/s] 56%|█████▌    | 1723/3065 [05:44<04:27,  5.01it/s] 56%|█████▌    | 1724/3065 [05:44<04:27,  5.01it/s] 56%|█████▋    | 1725/3065 [05:44<04:27,  5.01it/s] 56%|█████▋    | 1726/3065 [05:45<04:27,  5.01it/s] 56%|█████▋    | 1727/3065 [05:45<04:27,  5.01it/s] 56%|█████▋    | 1728/3065 [05:45<04:27,  5.01it/s] 56%|█████▋    | 1729/3065 [05:45<04:26,  5.01it/s] 56%|█████▋    | 1730/3065 [05:45<04:26,  5.01it/s] 56%|█████▋    | 1731/3065 [05:46<04:26,  5.01it/s] 57%|█████▋    | 1732/3065 [05:46<04:26,  5.01it/s] 57%|█████▋    | 1733/3065 [05:46<04:25,  5.01it/s] 57%|█████▋    | 1734/3065 [05:46<04:25,  5.01it/s] 57%|█████▋    | 1735/3065 [05:46<04:25,  5.01it/s] 57%|█████▋    | 1736/3065 [05:47<04:25,  5.01it/s] 57%|█████▋    | 1737/3065 [05:47<04:24,  5.02it/s] 57%|█████▋    | 1738/3065 [05:47<04:23,  5.03it/s] 57%|█████▋    | 1739/3065 [05:47<04:22,  5.06it/s] 57%|█████▋    | 1740/3065 [05:47<04:20,  5.08it/s] 57%|█████▋    | 1741/3065 [05:48<04:21,  5.06it/s] 57%|█████▋    | 1742/3065 [05:48<04:21,  5.05it/s] 57%|█████▋    | 1743/3065 [05:48<04:22,  5.04it/s] 57%|█████▋    | 1744/3065 [05:48<04:22,  5.03it/s] 57%|█████▋    | 1745/3065 [05:48<04:23,  5.02it/s] 57%|█████▋    | 1746/3065 [05:49<04:23,  5.01it/s] 57%|█████▋    | 1747/3065 [05:49<04:23,  5.01it/s] 57%|█████▋    | 1748/3065 [05:49<04:22,  5.01it/s] 57%|█████▋    | 1749/3065 [05:49<04:22,  5.00it/s] 57%|█████▋    | 1750/3065 [05:49<04:22,  5.01it/s] 57%|█████▋    | 1751/3065 [05:50<04:22,  5.01it/s] 57%|█████▋    | 1752/3065 [05:50<04:22,  5.00it/s] 57%|█████▋    | 1753/3065 [05:50<04:22,  5.00it/s] 57%|█████▋    | 1754/3065 [05:50<04:21,  5.00it/s] 57%|█████▋    | 1755/3065 [05:50<04:21,  5.00it/s] 57%|█████▋    | 1756/3065 [05:51<04:21,  5.00it/s] 57%|█████▋    | 1757/3065 [05:51<04:21,  5.00it/s] 57%|█████▋    | 1758/3065 [05:51<04:21,  5.00it/s] 57%|█████▋    | 1759/3065 [05:51<04:21,  5.00it/s] 57%|█████▋    | 1760/3065 [05:51<04:20,  5.00it/s] 57%|█████▋    | 1761/3065 [05:52<04:20,  5.00it/s] 57%|█████▋    | 1762/3065 [05:52<04:20,  5.00it/s] 58%|█████▊    | 1763/3065 [05:52<04:20,  5.00it/s] 58%|█████▊    | 1764/3065 [05:52<04:20,  5.00it/s] 58%|█████▊    | 1765/3065 [05:52<04:19,  5.00it/s] 58%|█████▊    | 1766/3065 [05:53<04:19,  5.01it/s] 58%|█████▊    | 1767/3065 [05:53<04:19,  5.00it/s] 58%|█████▊    | 1768/3065 [05:53<04:19,  5.00it/s] 58%|█████▊    | 1769/3065 [05:53<04:19,  5.00it/s] 58%|█████▊    | 1770/3065 [05:53<04:18,  5.00it/s] 58%|█████▊    | 1771/3065 [05:54<04:18,  5.00it/s] 58%|█████▊    | 1772/3065 [05:54<04:18,  5.00it/s] 58%|█████▊    | 1773/3065 [05:54<04:18,  5.00it/s] 58%|█████▊    | 1774/3065 [05:54<04:17,  5.00it/s] 58%|█████▊    | 1775/3065 [05:54<04:17,  5.00it/s] 58%|█████▊    | 1776/3065 [05:55<04:17,  5.00it/s] 58%|█████▊    | 1777/3065 [05:55<04:17,  5.00it/s] 58%|█████▊    | 1778/3065 [05:55<04:17,  5.00it/s] 58%|█████▊    | 1779/3065 [05:55<04:17,  5.00it/s] 58%|█████▊    | 1780/3065 [05:55<04:17,  5.00it/s] 58%|█████▊    | 1781/3065 [05:56<04:16,  5.00it/s] 58%|█████▊    | 1782/3065 [05:56<04:16,  5.00it/s] 58%|█████▊    | 1783/3065 [05:56<04:16,  5.00it/s] 58%|█████▊    | 1784/3065 [05:56<04:16,  5.00it/s] 58%|█████▊    | 1785/3065 [05:56<04:15,  5.00it/s] 58%|█████▊    | 1786/3065 [05:57<04:15,  5.00it/s] 58%|█████▊    | 1787/3065 [05:57<04:15,  5.00it/s] 58%|█████▊    | 1788/3065 [05:57<04:15,  5.00it/s] 58%|█████▊    | 1789/3065 [05:57<04:15,  5.00it/s] 58%|█████▊    | 1790/3065 [05:57<04:15,  5.00it/s] 58%|█████▊    | 1791/3065 [05:58<04:14,  5.00it/s] 58%|█████▊    | 1792/3065 [05:58<04:14,  5.00it/s] 58%|█████▊    | 1793/3065 [05:58<04:14,  5.00it/s] 59%|█████▊    | 1794/3065 [05:58<04:14,  5.00it/s] 59%|█████▊    | 1795/3065 [05:58<04:13,  5.00it/s] 59%|█████▊    | 1796/3065 [05:59<04:13,  5.00it/s] 59%|█████▊    | 1797/3065 [05:59<04:13,  5.00it/s] 59%|█████▊    | 1798/3065 [05:59<04:13,  5.00it/s] 59%|█████▊    | 1799/3065 [05:59<04:12,  5.01it/s] 59%|█████▊    | 1800/3065 [05:59<04:12,  5.01it/s] 59%|█████▉    | 1801/3065 [06:00<04:12,  5.01it/s] 59%|█████▉    | 1802/3065 [06:00<04:12,  5.01it/s] 59%|█████▉    | 1803/3065 [06:00<04:11,  5.01it/s] 59%|█████▉    | 1804/3065 [06:00<04:11,  5.01it/s] 59%|█████▉    | 1805/3065 [06:00<04:11,  5.01it/s] 59%|█████▉    | 1806/3065 [06:01<04:11,  5.01it/s] 59%|█████▉    | 1807/3065 [06:01<04:11,  5.01it/s] 59%|█████▉    | 1808/3065 [06:01<04:10,  5.01it/s] 59%|█████▉    | 1809/3065 [06:01<04:10,  5.01it/s] 59%|█████▉    | 1810/3065 [06:01<04:09,  5.02it/s] 59%|█████▉    | 1811/3065 [06:02<04:08,  5.04it/s] 59%|█████▉    | 1812/3065 [06:02<04:07,  5.07it/s] 59%|█████▉    | 1813/3065 [06:02<04:06,  5.07it/s] 59%|█████▉    | 1814/3065 [06:02<04:07,  5.06it/s] 59%|█████▉    | 1815/3065 [06:02<04:07,  5.05it/s] 59%|█████▉    | 1816/3065 [06:03<04:08,  5.03it/s] 59%|█████▉    | 1817/3065 [06:03<04:08,  5.03it/s] 59%|█████▉    | 1818/3065 [06:03<04:08,  5.02it/s] 59%|█████▉    | 1819/3065 [06:03<04:08,  5.02it/s] 59%|█████▉    | 1820/3065 [06:03<04:08,  5.02it/s] 59%|█████▉    | 1821/3065 [06:04<04:08,  5.01it/s] 59%|█████▉    | 1822/3065 [06:04<04:08,  5.01it/s] 59%|█████▉    | 1823/3065 [06:04<04:07,  5.01it/s] 60%|█████▉    | 1824/3065 [06:04<04:07,  5.01it/s] 60%|█████▉    | 1825/3065 [06:04<04:07,  5.00it/s] 60%|█████▉    | 1826/3065 [06:05<04:07,  5.01it/s] 60%|█████▉    | 1827/3065 [06:05<04:07,  5.00it/s] 60%|█████▉    | 1828/3065 [06:05<04:07,  5.00it/s] 60%|█████▉    | 1829/3065 [06:05<04:07,  5.00it/s] 60%|█████▉    | 1830/3065 [06:05<04:07,  5.00it/s] 60%|█████▉    | 1831/3065 [06:06<04:06,  5.00it/s] 60%|█████▉    | 1832/3065 [06:06<04:06,  5.00it/s] 60%|█████▉    | 1833/3065 [06:06<04:06,  5.00it/s] 60%|█████▉    | 1834/3065 [06:06<04:06,  5.00it/s] 60%|█████▉    | 1835/3065 [06:06<04:05,  5.00it/s] 60%|█████▉    | 1836/3065 [06:07<04:05,  5.00it/s] 60%|█████▉    | 1837/3065 [06:07<04:05,  5.00it/s] 60%|█████▉    | 1838/3065 [06:07<04:05,  5.00it/s] 60%|██████    | 1839/3065 [06:07<04:05,  5.00it/s] 60%|██████    | 1840/3065 [06:07<04:04,  5.01it/s] 60%|██████    | 1841/3065 [06:08<04:04,  5.01it/s] 60%|██████    | 1842/3065 [06:08<04:04,  5.01it/s] 60%|██████    | 1843/3065 [06:08<04:03,  5.01it/s] 60%|██████    | 1844/3065 [06:08<04:03,  5.01it/s] 60%|██████    | 1845/3065 [06:08<04:03,  5.01it/s] 60%|██████    | 1846/3065 [06:09<04:03,  5.01it/s] 60%|██████    | 1847/3065 [06:09<04:03,  5.01it/s] 60%|██████    | 1848/3065 [06:09<04:02,  5.02it/s] 60%|██████    | 1849/3065 [06:09<04:01,  5.03it/s] 60%|██████    | 1850/3065 [06:09<04:00,  5.05it/s] 60%|██████    | 1851/3065 [06:10<03:59,  5.07it/s] 60%|██████    | 1852/3065 [06:10<03:59,  5.07it/s] 60%|██████    | 1853/3065 [06:10<03:59,  5.06it/s] 60%|██████    | 1854/3065 [06:10<04:00,  5.04it/s] 61%|██████    | 1855/3065 [06:10<04:00,  5.03it/s] 61%|██████    | 1856/3065 [06:11<04:00,  5.02it/s] 61%|██████    | 1857/3065 [06:11<04:00,  5.02it/s] 61%|██████    | 1858/3065 [06:11<04:00,  5.01it/s] 61%|██████    | 1859/3065 [06:11<04:00,  5.01it/s] 61%|██████    | 1860/3065 [06:11<04:00,  5.01it/s] 61%|██████    | 1861/3065 [06:12<04:00,  5.01it/s] 61%|██████    | 1862/3065 [06:12<04:00,  5.01it/s] 61%|██████    | 1863/3065 [06:12<04:00,  5.01it/s] 61%|██████    | 1864/3065 [06:12<04:00,  5.00it/s] 61%|██████    | 1865/3065 [06:12<03:59,  5.00it/s] 61%|██████    | 1866/3065 [06:13<03:59,  5.00it/s] 61%|██████    | 1867/3065 [06:13<03:59,  5.00it/s] 61%|██████    | 1868/3065 [06:13<03:59,  5.00it/s] 61%|██████    | 1869/3065 [06:13<03:59,  5.00it/s] 61%|██████    | 1870/3065 [06:13<03:58,  5.00it/s] 61%|██████    | 1871/3065 [06:14<03:58,  5.00it/s] 61%|██████    | 1872/3065 [06:14<03:58,  5.00it/s] 61%|██████    | 1873/3065 [06:14<03:58,  5.00it/s] 61%|██████    | 1874/3065 [06:14<03:57,  5.00it/s] 61%|██████    | 1875/3065 [06:14<03:57,  5.00it/s] 61%|██████    | 1876/3065 [06:15<03:57,  5.00it/s] 61%|██████    | 1877/3065 [06:15<03:57,  5.00it/s] 61%|██████▏   | 1878/3065 [06:15<03:57,  5.00it/s] 61%|██████▏   | 1879/3065 [06:15<03:57,  5.00it/s] 61%|██████▏   | 1880/3065 [06:15<03:56,  5.00it/s] 61%|██████▏   | 1881/3065 [06:16<03:56,  5.00it/s] 61%|██████▏   | 1882/3065 [06:16<03:56,  5.00it/s] 61%|██████▏   | 1883/3065 [06:16<03:56,  5.00it/s] 61%|██████▏   | 1884/3065 [06:16<03:56,  5.00it/s] 62%|██████▏   | 1885/3065 [06:16<03:55,  5.00it/s] 62%|██████▏   | 1886/3065 [06:17<03:55,  5.00it/s] 62%|██████▏   | 1887/3065 [06:17<03:55,  5.00it/s] 62%|██████▏   | 1888/3065 [06:17<03:55,  5.01it/s] 62%|██████▏   | 1889/3065 [06:17<03:55,  5.00it/s] 62%|██████▏   | 1890/3065 [06:17<03:55,  5.00it/s] 62%|██████▏   | 1891/3065 [06:18<03:54,  5.00it/s] 62%|██████▏   | 1892/3065 [06:18<03:54,  5.00it/s] 62%|██████▏   | 1893/3065 [06:18<03:54,  5.00it/s] 62%|██████▏   | 1894/3065 [06:18<03:54,  5.00it/s] 62%|██████▏   | 1895/3065 [06:18<03:53,  5.00it/s] 62%|██████▏   | 1896/3065 [06:19<03:53,  5.00it/s] 62%|██████▏   | 1897/3065 [06:19<03:53,  5.00it/s] 62%|██████▏   | 1898/3065 [06:19<03:53,  5.00it/s] 62%|██████▏   | 1899/3065 [06:19<03:53,  5.00it/s] 62%|██████▏   | 1900/3065 [06:19<03:53,  5.00it/s] 62%|██████▏   | 1901/3065 [06:20<03:52,  5.00it/s] 62%|██████▏   | 1902/3065 [06:20<03:52,  5.00it/s] 62%|██████▏   | 1903/3065 [06:20<03:52,  5.00it/s] 62%|██████▏   | 1904/3065 [06:20<03:52,  5.00it/s] 62%|██████▏   | 1905/3065 [06:20<03:52,  5.00it/s] 62%|██████▏   | 1906/3065 [06:21<03:51,  5.00it/s] 62%|██████▏   | 1907/3065 [06:21<03:51,  5.00it/s] 62%|██████▏   | 1908/3065 [06:21<03:51,  5.00it/s] 62%|██████▏   | 1909/3065 [06:21<03:51,  5.00it/s] 62%|██████▏   | 1910/3065 [06:21<03:51,  5.00it/s] 62%|██████▏   | 1911/3065 [06:22<03:50,  5.00it/s] 62%|██████▏   | 1912/3065 [06:22<03:50,  5.00it/s] 62%|██████▏   | 1913/3065 [06:22<03:50,  5.00it/s] 62%|██████▏   | 1914/3065 [06:22<03:50,  5.00it/s] 62%|██████▏   | 1915/3065 [06:22<03:50,  5.00it/s] 63%|██████▎   | 1916/3065 [06:23<03:49,  5.00it/s] 63%|██████▎   | 1917/3065 [06:23<03:49,  5.00it/s] 63%|██████▎   | 1918/3065 [06:23<03:49,  5.00it/s] 63%|██████▎   | 1919/3065 [06:23<03:49,  5.00it/s] 63%|██████▎   | 1920/3065 [06:23<03:48,  5.00it/s] 63%|██████▎   | 1921/3065 [06:24<03:48,  5.00it/s] 63%|██████▎   | 1922/3065 [06:24<03:48,  5.00it/s] 63%|██████▎   | 1923/3065 [06:24<03:48,  5.00it/s] 63%|██████▎   | 1924/3065 [06:24<03:48,  5.00it/s] 63%|██████▎   | 1925/3065 [06:24<03:47,  5.00it/s] 63%|██████▎   | 1926/3065 [06:25<03:47,  5.00it/s] 63%|██████▎   | 1927/3065 [06:25<03:47,  5.00it/s] 63%|██████▎   | 1928/3065 [06:25<03:47,  5.00it/s] 63%|██████▎   | 1929/3065 [06:25<03:46,  5.01it/s] 63%|██████▎   | 1930/3065 [06:25<03:46,  5.00it/s] 63%|██████▎   | 1931/3065 [06:26<03:46,  5.00it/s] 63%|██████▎   | 1932/3065 [06:26<03:46,  5.00it/s] 63%|██████▎   | 1933/3065 [06:26<03:46,  5.00it/s] 63%|██████▎   | 1934/3065 [06:26<03:46,  5.00it/s] 63%|██████▎   | 1935/3065 [06:26<03:45,  5.00it/s] 63%|██████▎   | 1936/3065 [06:27<03:45,  5.00it/s] 63%|██████▎   | 1937/3065 [06:27<03:45,  5.00it/s] 63%|██████▎   | 1938/3065 [06:27<03:45,  5.00it/s] 63%|██████▎   | 1939/3065 [06:27<03:45,  5.00it/s] 63%|██████▎   | 1940/3065 [06:27<03:44,  5.00it/s] 63%|██████▎   | 1941/3065 [06:28<03:44,  5.00it/s] 63%|██████▎   | 1942/3065 [06:28<03:44,  5.00it/s] 63%|██████▎   | 1943/3065 [06:28<03:44,  5.00it/s] 63%|██████▎   | 1944/3065 [06:28<03:44,  5.00it/s] 63%|██████▎   | 1945/3065 [06:28<03:43,  5.00it/s] 63%|██████▎   | 1946/3065 [06:29<03:43,  5.00it/s] 64%|██████▎   | 1947/3065 [06:29<03:43,  4.99it/s] 64%|██████▎   | 1948/3065 [06:29<03:43,  4.99it/s] 64%|██████▎   | 1949/3065 [06:29<03:43,  5.00it/s] 64%|██████▎   | 1950/3065 [06:29<03:43,  5.00it/s] 64%|██████▎   | 1951/3065 [06:30<03:42,  5.00it/s] 64%|██████▎   | 1952/3065 [06:30<03:42,  5.00it/s] 64%|██████▎   | 1953/3065 [06:30<03:42,  5.00it/s] 64%|██████▍   | 1954/3065 [06:30<03:41,  5.01it/s] 64%|██████▍   | 1955/3065 [06:30<03:41,  5.01it/s] 64%|██████▍   | 1956/3065 [06:31<03:41,  5.01it/s] 64%|██████▍   | 1957/3065 [06:31<03:41,  5.01it/s] 64%|██████▍   | 1958/3065 [06:31<03:41,  5.01it/s] 64%|██████▍   | 1959/3065 [06:31<03:41,  5.00it/s] 64%|██████▍   | 1960/3065 [06:31<03:40,  5.00it/s] 64%|██████▍   | 1961/3065 [06:31<03:40,  5.00it/s] 64%|██████▍   | 1962/3065 [06:32<03:40,  5.00it/s] 64%|██████▍   | 1963/3065 [06:32<03:40,  5.00it/s] 64%|██████▍   | 1964/3065 [06:32<03:40,  5.00it/s] 64%|██████▍   | 1965/3065 [06:32<03:39,  5.00it/s] 64%|██████▍   | 1966/3065 [06:32<03:39,  5.00it/s] 64%|██████▍   | 1967/3065 [06:33<03:39,  5.00it/s] 64%|██████▍   | 1968/3065 [06:33<03:39,  5.00it/s] 64%|██████▍   | 1969/3065 [06:33<03:39,  5.00it/s] 64%|██████▍   | 1970/3065 [06:33<03:38,  5.00it/s] 64%|██████▍   | 1971/3065 [06:33<03:38,  5.00it/s] 64%|██████▍   | 1972/3065 [06:34<03:38,  5.00it/s] 64%|██████▍   | 1973/3065 [06:34<03:38,  5.00it/s] 64%|██████▍   | 1974/3065 [06:34<03:38,  5.00it/s] 64%|██████▍   | 1975/3065 [06:34<03:37,  5.00it/s] 64%|██████▍   | 1976/3065 [06:34<03:37,  5.00it/s] 65%|██████▍   | 1977/3065 [06:35<03:37,  5.00it/s] 65%|██████▍   | 1978/3065 [06:35<03:37,  5.00it/s] 65%|██████▍   | 1979/3065 [06:35<03:37,  5.00it/s] 65%|██████▍   | 1980/3065 [06:35<03:36,  5.00it/s] 65%|██████▍   | 1981/3065 [06:35<03:36,  5.00it/s] 65%|██████▍   | 1982/3065 [06:36<03:36,  5.00it/s] 65%|██████▍   | 1983/3065 [06:36<03:36,  5.00it/s] 65%|██████▍   | 1984/3065 [06:36<03:36,  5.00it/s] 65%|██████▍   | 1985/3065 [06:36<03:35,  5.00it/s] 65%|██████▍   | 1986/3065 [06:36<03:35,  5.01it/s] 65%|██████▍   | 1987/3065 [06:37<03:35,  5.00it/s] 65%|██████▍   | 1988/3065 [06:37<03:35,  5.00it/s] 65%|██████▍   | 1989/3065 [06:37<03:34,  5.01it/s] 65%|██████▍   | 1990/3065 [06:37<03:34,  5.01it/s] 65%|██████▍   | 1991/3065 [06:37<03:34,  5.01it/s] 65%|██████▍   | 1992/3065 [06:38<03:34,  5.01it/s] 65%|██████▌   | 1993/3065 [06:38<03:34,  5.00it/s] 65%|██████▌   | 1994/3065 [06:38<03:33,  5.00it/s] 65%|██████▌   | 1995/3065 [06:38<03:33,  5.00it/s] 65%|██████▌   | 1996/3065 [06:38<03:33,  5.01it/s] 65%|██████▌   | 1997/3065 [06:39<03:33,  5.00it/s] 65%|██████▌   | 1998/3065 [06:39<03:33,  5.00it/s] 65%|██████▌   | 1999/3065 [06:39<03:32,  5.00it/s] 65%|██████▌   | 2000/3065 [06:39<03:32,  5.00it/s] 65%|██████▌   | 2001/3065 [06:39<03:32,  5.00it/s] 65%|██████▌   | 2002/3065 [06:40<03:32,  5.01it/s] 65%|██████▌   | 2003/3065 [06:40<03:32,  5.01it/s] 65%|██████▌   | 2004/3065 [06:40<03:31,  5.01it/s] 65%|██████▌   | 2005/3065 [06:40<03:31,  5.01it/s] 65%|██████▌   | 2006/3065 [06:40<03:31,  5.01it/s] 65%|██████▌   | 2007/3065 [06:41<03:31,  5.01it/s] 66%|██████▌   | 2008/3065 [06:41<03:30,  5.01it/s] 66%|██████▌   | 2009/3065 [06:41<03:30,  5.02it/s] 66%|██████▌   | 2010/3065 [06:41<03:29,  5.03it/s] 66%|██████▌   | 2011/3065 [06:41<03:28,  5.05it/s] 66%|██████▌   | 2012/3065 [06:42<03:27,  5.07it/s] 66%|██████▌   | 2013/3065 [06:42<03:27,  5.07it/s] 66%|██████▌   | 2014/3065 [06:42<03:27,  5.06it/s] 66%|██████▌   | 2015/3065 [06:42<03:28,  5.05it/s] 66%|██████▌   | 2016/3065 [06:42<03:28,  5.03it/s] 66%|██████▌   | 2017/3065 [06:43<03:28,  5.02it/s] 66%|██████▌   | 2018/3065 [06:43<03:28,  5.02it/s] 66%|██████▌   | 2019/3065 [06:43<03:28,  5.02it/s] 66%|██████▌   | 2020/3065 [06:43<03:28,  5.01it/s] 66%|██████▌   | 2021/3065 [06:43<03:28,  5.01it/s] 66%|██████▌   | 2022/3065 [06:44<03:28,  5.01it/s] 66%|██████▌   | 2023/3065 [06:44<03:27,  5.01it/s] 66%|██████▌   | 2024/3065 [06:44<03:27,  5.01it/s] 66%|██████▌   | 2025/3065 [06:44<03:27,  5.01it/s] 66%|██████▌   | 2026/3065 [06:44<03:27,  5.01it/s] 66%|██████▌   | 2027/3065 [06:45<03:26,  5.02it/s] 66%|██████▌   | 2028/3065 [06:45<03:26,  5.03it/s] 66%|██████▌   | 2029/3065 [06:45<03:25,  5.05it/s] 66%|██████▌   | 2030/3065 [06:45<03:24,  5.07it/s] 66%|██████▋   | 2031/3065 [06:45<03:23,  5.07it/s] 66%|██████▋   | 2032/3065 [06:46<03:24,  5.06it/s] 66%|██████▋   | 2033/3065 [06:46<03:24,  5.04it/s] 66%|██████▋   | 2034/3065 [06:46<03:24,  5.03it/s] 66%|██████▋   | 2035/3065 [06:46<03:25,  5.02it/s] 66%|██████▋   | 2036/3065 [06:46<03:25,  5.02it/s] 66%|██████▋   | 2037/3065 [06:47<03:25,  5.01it/s] 66%|██████▋   | 2038/3065 [06:47<03:25,  5.01it/s] 67%|██████▋   | 2039/3065 [06:47<03:25,  5.00it/s] 67%|██████▋   | 2040/3065 [06:47<03:24,  5.00it/s] 67%|██████▋   | 2041/3065 [06:47<03:24,  5.00it/s] 67%|██████▋   | 2042/3065 [06:48<03:24,  5.00it/s] 67%|██████▋   | 2043/3065 [06:48<03:24,  5.00it/s] 67%|██████▋   | 2044/3065 [06:48<03:23,  5.01it/s] 67%|██████▋   | 2045/3065 [06:48<03:23,  5.01it/s] 67%|██████▋   | 2046/3065 [06:48<03:23,  5.00it/s] 67%|██████▋   | 2047/3065 [06:49<03:23,  5.01it/s] 67%|██████▋   | 2048/3065 [06:49<03:23,  5.00it/s] 67%|██████▋   | 2049/3065 [06:49<03:23,  5.00it/s] 67%|██████▋   | 2050/3065 [06:49<03:23,  5.00it/s] 67%|██████▋   | 2051/3065 [06:49<03:22,  5.00it/s] 67%|██████▋   | 2052/3065 [06:50<03:22,  5.00it/s] 67%|██████▋   | 2053/3065 [06:50<03:22,  5.00it/s] 67%|██████▋   | 2054/3065 [06:50<03:22,  5.00it/s] 67%|██████▋   | 2055/3065 [06:50<03:21,  5.00it/s] 67%|██████▋   | 2056/3065 [06:50<03:21,  5.00it/s] 67%|██████▋   | 2057/3065 [06:51<03:21,  5.00it/s] 67%|██████▋   | 2058/3065 [06:51<03:21,  5.00it/s] 67%|██████▋   | 2059/3065 [06:51<03:21,  5.00it/s] 67%|██████▋   | 2060/3065 [06:51<03:20,  5.00it/s] 67%|██████▋   | 2061/3065 [06:51<03:20,  5.00it/s] 67%|██████▋   | 2062/3065 [06:52<03:20,  5.01it/s] 67%|██████▋   | 2063/3065 [06:52<03:20,  5.01it/s] 67%|██████▋   | 2064/3065 [06:52<03:20,  5.00it/s] 67%|██████▋   | 2065/3065 [06:52<03:19,  5.00it/s] 67%|██████▋   | 2066/3065 [06:52<03:19,  5.00it/s] 67%|██████▋   | 2067/3065 [06:53<03:19,  5.00it/s] 67%|██████▋   | 2068/3065 [06:53<03:19,  5.00it/s] 68%|██████▊   | 2069/3065 [06:53<03:19,  5.00it/s] 68%|██████▊   | 2070/3065 [06:53<03:18,  5.00it/s] 68%|██████▊   | 2071/3065 [06:53<03:18,  5.00it/s] 68%|██████▊   | 2072/3065 [06:54<03:18,  5.00it/s] 68%|██████▊   | 2073/3065 [06:54<03:18,  5.00it/s] 68%|██████▊   | 2074/3065 [06:54<03:18,  5.00it/s] 68%|██████▊   | 2075/3065 [06:54<03:18,  5.00it/s] 68%|██████▊   | 2076/3065 [06:54<03:17,  5.00it/s] 68%|██████▊   | 2077/3065 [06:55<03:17,  5.00it/s] 68%|██████▊   | 2078/3065 [06:55<03:17,  5.00it/s] 68%|██████▊   | 2079/3065 [06:55<03:17,  5.00it/s] 68%|██████▊   | 2080/3065 [06:55<03:16,  5.00it/s] 68%|██████▊   | 2081/3065 [06:55<03:16,  5.01it/s] 68%|██████▊   | 2082/3065 [06:56<03:16,  5.01it/s] 68%|██████▊   | 2083/3065 [06:56<03:16,  5.01it/s] 68%|██████▊   | 2084/3065 [06:56<03:15,  5.01it/s] 68%|██████▊   | 2085/3065 [06:56<03:15,  5.01it/s] 68%|██████▊   | 2086/3065 [06:56<03:15,  5.01it/s] 68%|██████▊   | 2087/3065 [06:57<03:15,  5.01it/s] 68%|██████▊   | 2088/3065 [06:57<03:15,  5.00it/s] 68%|██████▊   | 2089/3065 [06:57<03:15,  5.00it/s] 68%|██████▊   | 2090/3065 [06:57<03:14,  5.00it/s] 68%|██████▊   | 2091/3065 [06:57<03:14,  5.00it/s] 68%|██████▊   | 2092/3065 [06:58<03:14,  5.00it/s] 68%|██████▊   | 2093/3065 [06:58<03:14,  5.00it/s] 68%|██████▊   | 2094/3065 [06:58<03:14,  5.00it/s] 68%|██████▊   | 2095/3065 [06:58<03:13,  5.00it/s] 68%|██████▊   | 2096/3065 [06:58<03:13,  5.00it/s] 68%|██████▊   | 2097/3065 [06:59<03:13,  5.01it/s] 68%|██████▊   | 2098/3065 [06:59<03:13,  5.00it/s] 68%|██████▊   | 2099/3065 [06:59<03:13,  5.00it/s] 69%|██████▊   | 2100/3065 [06:59<03:13,  5.00it/s] 69%|██████▊   | 2101/3065 [06:59<03:12,  5.00it/s] 69%|██████▊   | 2102/3065 [07:00<03:12,  5.00it/s] 69%|██████▊   | 2103/3065 [07:00<03:12,  5.00it/s] 69%|██████▊   | 2104/3065 [07:00<03:12,  5.00it/s] 69%|██████▊   | 2105/3065 [07:00<03:12,  5.00it/s] 69%|██████▊   | 2106/3065 [07:00<03:11,  5.00it/s] 69%|██████▊   | 2107/3065 [07:01<03:11,  5.00it/s] 69%|██████▉   | 2108/3065 [07:01<03:11,  5.00it/s] 69%|██████▉   | 2109/3065 [07:01<03:11,  5.00it/s] 69%|██████▉   | 2110/3065 [07:01<03:11,  4.99it/s] 69%|██████▉   | 2111/3065 [07:01<03:10,  5.00it/s] 69%|██████▉   | 2112/3065 [07:02<03:10,  5.00it/s] 69%|██████▉   | 2113/3065 [07:02<03:10,  5.00it/s] 69%|██████▉   | 2114/3065 [07:02<03:10,  5.00it/s] 69%|██████▉   | 2115/3065 [07:02<03:09,  5.00it/s] 69%|██████▉   | 2116/3065 [07:02<03:09,  5.00it/s] 69%|██████▉   | 2117/3065 [07:03<03:09,  5.00it/s] 69%|██████▉   | 2118/3065 [07:03<03:09,  5.00it/s] 69%|██████▉   | 2119/3065 [07:03<03:09,  5.00it/s] 69%|██████▉   | 2120/3065 [07:03<03:09,  5.00it/s] 69%|██████▉   | 2121/3065 [07:03<03:08,  5.00it/s] 69%|██████▉   | 2122/3065 [07:04<03:08,  5.00it/s] 69%|██████▉   | 2123/3065 [07:04<03:08,  5.00it/s] 69%|██████▉   | 2124/3065 [07:04<03:08,  5.00it/s] 69%|██████▉   | 2125/3065 [07:04<03:07,  5.00it/s] 69%|██████▉   | 2126/3065 [07:04<03:07,  5.00it/s] 69%|██████▉   | 2127/3065 [07:05<03:07,  5.00it/s] 69%|██████▉   | 2128/3065 [07:05<03:07,  5.00it/s] 69%|██████▉   | 2129/3065 [07:05<03:07,  5.00it/s] 69%|██████▉   | 2130/3065 [07:05<03:06,  5.00it/s] 70%|██████▉   | 2131/3065 [07:05<03:06,  5.00it/s] 70%|██████▉   | 2132/3065 [07:06<03:06,  5.00it/s] 70%|██████▉   | 2133/3065 [07:06<03:06,  5.00it/s] 70%|██████▉   | 2134/3065 [07:06<03:06,  5.00it/s] 70%|██████▉   | 2135/3065 [07:06<03:05,  5.00it/s] 70%|██████▉   | 2136/3065 [07:06<03:05,  5.00it/s] 70%|██████▉   | 2137/3065 [07:07<03:05,  5.00it/s] 70%|██████▉   | 2138/3065 [07:07<03:05,  5.00it/s] 70%|██████▉   | 2139/3065 [07:07<03:05,  5.00it/s] 70%|██████▉   | 2140/3065 [07:07<03:04,  5.00it/s] 70%|██████▉   | 2141/3065 [07:07<03:04,  5.00it/s] 70%|██████▉   | 2142/3065 [07:08<03:04,  5.00it/s] 70%|██████▉   | 2143/3065 [07:08<03:04,  5.00it/s] 70%|██████▉   | 2144/3065 [07:08<03:04,  5.00it/s] 70%|██████▉   | 2145/3065 [07:08<03:36,  4.24it/s] 70%|███████   | 2146/3065 [07:09<03:26,  4.45it/s] 70%|███████   | 2147/3065 [07:09<03:19,  4.61it/s] 70%|███████   | 2148/3065 [07:09<03:14,  4.72it/s] 70%|███████   | 2149/3065 [07:09<03:10,  4.80it/s] 70%|███████   | 2150/3065 [07:09<03:08,  4.86it/s] 70%|███████   | 2151/3065 [07:10<03:06,  4.90it/s] 70%|███████   | 2152/3065 [07:10<03:05,  4.93it/s] 70%|███████   | 2153/3065 [07:10<03:03,  4.96it/s] 70%|███████   | 2154/3065 [07:10<03:03,  4.97it/s] 70%|███████   | 2155/3065 [07:10<03:02,  4.98it/s] 70%|███████   | 2156/3065 [07:11<03:02,  4.99it/s] 70%|███████   | 2157/3065 [07:11<03:01,  5.00it/s] 70%|███████   | 2158/3065 [07:11<03:01,  5.01it/s] 70%|███████   | 2159/3065 [07:11<03:00,  5.03it/s] 70%|███████   | 2160/3065 [07:11<02:58,  5.06it/s] 71%|███████   | 2161/3065 [07:12<02:58,  5.07it/s] 71%|███████   | 2162/3065 [07:12<02:58,  5.06it/s] 71%|███████   | 2163/3065 [07:12<02:58,  5.04it/s] 71%|███████   | 2164/3065 [07:12<02:59,  5.03it/s] 71%|███████   | 2165/3065 [07:12<02:59,  5.02it/s] 71%|███████   | 2166/3065 [07:13<02:59,  5.02it/s] 71%|███████   | 2167/3065 [07:13<02:59,  5.02it/s] 71%|███████   | 2168/3065 [07:13<02:59,  5.01it/s] 71%|███████   | 2169/3065 [07:13<02:58,  5.01it/s] 71%|███████   | 2170/3065 [07:13<02:58,  5.00it/s] 71%|███████   | 2171/3065 [07:14<02:58,  5.00it/s] 71%|███████   | 2172/3065 [07:14<02:58,  5.00it/s] 71%|███████   | 2173/3065 [07:14<02:58,  5.00it/s] 71%|███████   | 2174/3065 [07:14<02:58,  5.00it/s] 71%|███████   | 2175/3065 [07:14<02:57,  5.00it/s] 71%|███████   | 2176/3065 [07:15<02:57,  5.00it/s] 71%|███████   | 2177/3065 [07:15<02:57,  5.01it/s] 71%|███████   | 2178/3065 [07:15<02:57,  5.00it/s] 71%|███████   | 2179/3065 [07:15<02:57,  4.99it/s] 71%|███████   | 2180/3065 [07:15<02:57,  4.99it/s] 71%|███████   | 2181/3065 [07:16<02:56,  5.00it/s] 71%|███████   | 2182/3065 [07:16<02:56,  5.00it/s] 71%|███████   | 2183/3065 [07:16<02:56,  5.00it/s] 71%|███████▏  | 2184/3065 [07:16<02:56,  5.00it/s] 71%|███████▏  | 2185/3065 [07:16<02:56,  5.00it/s] 71%|███████▏  | 2186/3065 [07:17<02:55,  5.00it/s] 71%|███████▏  | 2187/3065 [07:17<02:55,  5.00it/s] 71%|███████▏  | 2188/3065 [07:17<02:55,  5.00it/s] 71%|███████▏  | 2189/3065 [07:17<02:55,  5.00it/s] 71%|███████▏  | 2190/3065 [07:17<02:54,  5.00it/s] 71%|███████▏  | 2191/3065 [07:18<02:54,  5.00it/s] 72%|███████▏  | 2192/3065 [07:18<02:54,  5.00it/s] 72%|███████▏  | 2193/3065 [07:18<02:54,  5.00it/s] 72%|███████▏  | 2194/3065 [07:18<02:54,  5.00it/s] 72%|███████▏  | 2195/3065 [07:18<02:53,  5.00it/s] 72%|███████▏  | 2196/3065 [07:19<02:53,  5.01it/s] 72%|███████▏  | 2197/3065 [07:19<02:53,  5.01it/s] 72%|███████▏  | 2198/3065 [07:19<02:53,  5.01it/s] 72%|███████▏  | 2199/3065 [07:19<02:52,  5.01it/s] 72%|███████▏  | 2200/3065 [07:19<02:52,  5.01it/s] 72%|███████▏  | 2201/3065 [07:20<02:52,  5.00it/s] 72%|███████▏  | 2202/3065 [07:20<02:52,  5.00it/s] 72%|███████▏  | 2203/3065 [07:20<02:52,  5.00it/s] 72%|███████▏  | 2204/3065 [07:20<02:52,  5.00it/s] 72%|███████▏  | 2205/3065 [07:20<02:52,  5.00it/s] 72%|███████▏  | 2206/3065 [07:21<02:51,  5.00it/s] 72%|███████▏  | 2207/3065 [07:21<02:51,  5.00it/s] 72%|███████▏  | 2208/3065 [07:21<02:51,  5.00it/s] 72%|███████▏  | 2209/3065 [07:21<02:51,  5.00it/s] 72%|███████▏  | 2210/3065 [07:21<02:50,  5.01it/s] 72%|███████▏  | 2211/3065 [07:22<02:50,  5.00it/s] 72%|███████▏  | 2212/3065 [07:22<02:50,  5.00it/s] 72%|███████▏  | 2213/3065 [07:22<02:50,  5.00it/s] 72%|███████▏  | 2214/3065 [07:22<02:50,  5.00it/s] 72%|███████▏  | 2215/3065 [07:22<02:49,  5.00it/s] 72%|███████▏  | 2216/3065 [07:23<02:49,  5.00it/s] 72%|███████▏  | 2217/3065 [07:23<02:49,  5.00it/s] 72%|███████▏  | 2218/3065 [07:23<02:49,  5.00it/s] 72%|███████▏  | 2219/3065 [07:23<02:49,  5.00it/s] 72%|███████▏  | 2220/3065 [07:23<02:49,  5.00it/s] 72%|███████▏  | 2221/3065 [07:24<02:48,  5.00it/s] 72%|███████▏  | 2222/3065 [07:24<02:48,  5.00it/s] 73%|███████▎  | 2223/3065 [07:24<02:48,  5.00it/s] 73%|███████▎  | 2224/3065 [07:24<02:48,  5.00it/s] 73%|███████▎  | 2225/3065 [07:24<02:47,  5.00it/s] 73%|███████▎  | 2226/3065 [07:25<02:47,  5.00it/s] 73%|███████▎  | 2227/3065 [07:25<02:47,  5.00it/s] 73%|███████▎  | 2228/3065 [07:25<02:47,  5.00it/s] 73%|███████▎  | 2229/3065 [07:25<02:47,  5.00it/s] 73%|███████▎  | 2230/3065 [07:25<02:46,  5.00it/s] 73%|███████▎  | 2231/3065 [07:26<02:46,  5.00it/s] 73%|███████▎  | 2232/3065 [07:26<02:46,  5.00it/s] 73%|███████▎  | 2233/3065 [07:26<02:46,  5.00it/s] 73%|███████▎  | 2234/3065 [07:26<02:46,  5.00it/s] 73%|███████▎  | 2235/3065 [07:26<02:45,  5.00it/s] 73%|███████▎  | 2236/3065 [07:27<02:45,  5.00it/s] 73%|███████▎  | 2237/3065 [07:27<02:45,  5.00it/s] 73%|███████▎  | 2238/3065 [07:27<02:45,  5.00it/s] 73%|███████▎  | 2239/3065 [07:27<02:45,  5.00it/s] 73%|███████▎  | 2240/3065 [07:27<02:44,  5.00it/s] 73%|███████▎  | 2241/3065 [07:28<02:44,  5.01it/s] 73%|███████▎  | 2242/3065 [07:28<02:44,  5.00it/s] 73%|███████▎  | 2243/3065 [07:28<02:44,  5.00it/s] 73%|███████▎  | 2244/3065 [07:28<02:44,  5.00it/s] 73%|███████▎  | 2245/3065 [07:28<02:43,  5.00it/s] 73%|███████▎  | 2246/3065 [07:29<02:43,  5.00it/s] 73%|███████▎  | 2247/3065 [07:29<02:43,  5.00it/s] 73%|███████▎  | 2248/3065 [07:29<02:43,  5.00it/s] 73%|███████▎  | 2249/3065 [07:29<02:43,  5.00it/s] 73%|███████▎  | 2250/3065 [07:29<02:43,  5.00it/s] 73%|███████▎  | 2251/3065 [07:30<02:42,  5.00it/s] 73%|███████▎  | 2252/3065 [07:30<02:42,  5.00it/s] 74%|███████▎  | 2253/3065 [07:30<02:42,  5.00it/s] 74%|███████▎  | 2254/3065 [07:30<02:41,  5.01it/s] 74%|███████▎  | 2255/3065 [07:30<02:41,  5.01it/s] 74%|███████▎  | 2256/3065 [07:31<02:41,  5.01it/s] 74%|███████▎  | 2257/3065 [07:31<02:41,  5.01it/s] 74%|███████▎  | 2258/3065 [07:31<02:41,  5.00it/s] 74%|███████▎  | 2259/3065 [07:31<02:41,  5.00it/s] 74%|███████▎  | 2260/3065 [07:31<02:40,  5.01it/s] 74%|███████▍  | 2261/3065 [07:32<02:40,  5.01it/s] 74%|███████▍  | 2262/3065 [07:32<02:40,  5.01it/s] 74%|███████▍  | 2263/3065 [07:32<02:39,  5.02it/s] 74%|███████▍  | 2264/3065 [07:32<02:39,  5.02it/s] 74%|███████▍  | 2265/3065 [07:32<02:39,  5.03it/s] 74%|███████▍  | 2266/3065 [07:33<02:38,  5.05it/s] 74%|███████▍  | 2267/3065 [07:33<02:37,  5.07it/s] 74%|███████▍  | 2268/3065 [07:33<02:37,  5.08it/s] 74%|███████▍  | 2269/3065 [07:33<02:37,  5.06it/s] 74%|███████▍  | 2270/3065 [07:33<02:37,  5.05it/s] 74%|███████▍  | 2271/3065 [07:34<02:37,  5.03it/s] 74%|███████▍  | 2272/3065 [07:34<02:37,  5.02it/s] 74%|███████▍  | 2273/3065 [07:34<02:37,  5.02it/s] 74%|███████▍  | 2274/3065 [07:34<02:37,  5.01it/s] 74%|███████▍  | 2275/3065 [07:34<02:37,  5.01it/s] 74%|███████▍  | 2276/3065 [07:35<02:37,  5.01it/s] 74%|███████▍  | 2277/3065 [07:35<02:37,  5.01it/s] 74%|███████▍  | 2278/3065 [07:35<02:37,  5.01it/s] 74%|███████▍  | 2279/3065 [07:35<02:37,  5.00it/s] 74%|███████▍  | 2280/3065 [07:35<02:36,  5.00it/s] 74%|███████▍  | 2281/3065 [07:36<02:36,  5.00it/s] 74%|███████▍  | 2282/3065 [07:36<02:36,  5.00it/s] 74%|███████▍  | 2283/3065 [07:36<02:36,  5.00it/s] 75%|███████▍  | 2284/3065 [07:36<02:36,  5.00it/s] 75%|███████▍  | 2285/3065 [07:36<02:35,  5.00it/s] 75%|███████▍  | 2286/3065 [07:37<02:35,  5.00it/s] 75%|███████▍  | 2287/3065 [07:37<02:35,  5.00it/s] 75%|███████▍  | 2288/3065 [07:37<02:35,  5.00it/s] 75%|███████▍  | 2289/3065 [07:37<02:35,  5.00it/s] 75%|███████▍  | 2290/3065 [07:37<02:34,  5.00it/s] 75%|███████▍  | 2291/3065 [07:38<02:34,  5.00it/s] 75%|███████▍  | 2292/3065 [07:38<02:34,  5.00it/s] 75%|███████▍  | 2293/3065 [07:38<02:34,  5.00it/s] 75%|███████▍  | 2294/3065 [07:38<02:34,  5.00it/s] 75%|███████▍  | 2295/3065 [07:38<02:33,  5.00it/s] 75%|███████▍  | 2296/3065 [07:39<02:33,  5.00it/s] 75%|███████▍  | 2297/3065 [07:39<02:33,  5.00it/s] 75%|███████▍  | 2298/3065 [07:39<02:33,  5.00it/s] 75%|███████▌  | 2299/3065 [07:39<02:33,  5.00it/s] 75%|███████▌  | 2300/3065 [07:39<02:32,  5.00it/s] 75%|███████▌  | 2301/3065 [07:40<02:32,  5.00it/s] 75%|███████▌  | 2302/3065 [07:40<02:32,  5.00it/s] 75%|███████▌  | 2303/3065 [07:40<02:32,  5.00it/s] 75%|███████▌  | 2304/3065 [07:40<02:32,  5.00it/s] 75%|███████▌  | 2305/3065 [07:40<02:32,  5.00it/s] 75%|███████▌  | 2306/3065 [07:41<02:31,  5.00it/s] 75%|███████▌  | 2307/3065 [07:41<02:31,  5.00it/s] 75%|███████▌  | 2308/3065 [07:41<02:31,  5.00it/s] 75%|███████▌  | 2309/3065 [07:41<02:31,  5.00it/s] 75%|███████▌  | 2310/3065 [07:41<02:30,  5.00it/s] 75%|███████▌  | 2311/3065 [07:42<02:30,  5.01it/s] 75%|███████▌  | 2312/3065 [07:42<02:30,  5.00it/s] 75%|███████▌  | 2313/3065 [07:42<02:30,  5.00it/s] 75%|███████▌  | 2314/3065 [07:42<02:30,  5.00it/s] 76%|███████▌  | 2315/3065 [07:42<02:29,  5.00it/s] 76%|███████▌  | 2316/3065 [07:43<02:29,  5.00it/s] 76%|███████▌  | 2317/3065 [07:43<02:29,  5.00it/s] 76%|███████▌  | 2318/3065 [07:43<02:29,  5.00it/s] 76%|███████▌  | 2319/3065 [07:43<02:29,  5.00it/s] 76%|███████▌  | 2320/3065 [07:43<02:28,  5.01it/s] 76%|███████▌  | 2321/3065 [07:44<02:28,  5.00it/s] 76%|███████▌  | 2322/3065 [07:44<02:28,  5.01it/s] 76%|███████▌  | 2323/3065 [07:44<02:28,  5.01it/s] 76%|███████▌  | 2324/3065 [07:44<02:27,  5.01it/s] 76%|███████▌  | 2325/3065 [07:44<02:27,  5.01it/s] 76%|███████▌  | 2326/3065 [07:45<02:27,  5.01it/s] 76%|███████▌  | 2327/3065 [07:45<02:27,  5.01it/s] 76%|███████▌  | 2328/3065 [07:45<02:27,  5.01it/s] 76%|███████▌  | 2329/3065 [07:45<02:26,  5.01it/s] 76%|███████▌  | 2330/3065 [07:45<02:26,  5.01it/s] 76%|███████▌  | 2331/3065 [07:46<02:26,  5.01it/s] 76%|███████▌  | 2332/3065 [07:46<02:25,  5.02it/s] 76%|███████▌  | 2333/3065 [07:46<02:25,  5.04it/s] 76%|███████▌  | 2334/3065 [07:46<02:24,  5.06it/s] 76%|███████▌  | 2335/3065 [07:46<02:23,  5.08it/s] 76%|███████▌  | 2336/3065 [07:46<02:23,  5.06it/s] 76%|███████▌  | 2337/3065 [07:47<02:24,  5.05it/s] 76%|███████▋  | 2338/3065 [07:47<02:24,  5.04it/s] 76%|███████▋  | 2339/3065 [07:47<02:24,  5.03it/s] 76%|███████▋  | 2340/3065 [07:47<02:24,  5.02it/s] 76%|███████▋  | 2341/3065 [07:47<02:24,  5.02it/s] 76%|███████▋  | 2342/3065 [07:48<02:24,  5.02it/s] 76%|███████▋  | 2343/3065 [07:48<02:24,  5.01it/s] 76%|███████▋  | 2344/3065 [07:48<02:23,  5.01it/s] 77%|███████▋  | 2345/3065 [07:48<02:23,  5.01it/s] 77%|███████▋  | 2346/3065 [07:48<02:23,  5.01it/s] 77%|███████▋  | 2347/3065 [07:49<02:23,  5.00it/s] 77%|███████▋  | 2348/3065 [07:49<02:23,  5.00it/s] 77%|███████▋  | 2349/3065 [07:49<02:23,  5.00it/s] 77%|███████▋  | 2350/3065 [07:49<02:23,  5.00it/s] 77%|███████▋  | 2351/3065 [07:49<02:22,  5.00it/s] 77%|███████▋  | 2352/3065 [07:50<02:22,  5.00it/s] 77%|███████▋  | 2353/3065 [07:50<02:22,  5.00it/s] 77%|███████▋  | 2354/3065 [07:50<02:22,  5.00it/s] 77%|███████▋  | 2355/3065 [07:50<02:21,  5.00it/s] 77%|███████▋  | 2356/3065 [07:50<02:21,  5.01it/s] 77%|███████▋  | 2357/3065 [07:51<02:21,  5.00it/s] 77%|███████▋  | 2358/3065 [07:51<02:21,  5.01it/s] 77%|███████▋  | 2359/3065 [07:51<02:21,  5.01it/s] 77%|███████▋  | 2360/3065 [07:51<02:20,  5.00it/s] 77%|███████▋  | 2361/3065 [07:51<02:20,  5.00it/s] 77%|███████▋  | 2362/3065 [07:52<02:20,  5.00it/s] 77%|███████▋  | 2363/3065 [07:52<02:20,  5.00it/s] 77%|███████▋  | 2364/3065 [07:52<02:20,  5.00it/s] 77%|███████▋  | 2365/3065 [07:52<02:19,  5.00it/s] 77%|███████▋  | 2366/3065 [07:52<02:19,  5.00it/s] 77%|███████▋  | 2367/3065 [07:53<02:19,  5.00it/s] 77%|███████▋  | 2368/3065 [07:53<02:19,  4.99it/s] 77%|███████▋  | 2369/3065 [07:53<02:19,  4.99it/s] 77%|███████▋  | 2370/3065 [07:53<02:19,  5.00it/s] 77%|███████▋  | 2371/3065 [07:53<02:18,  5.00it/s] 77%|███████▋  | 2372/3065 [07:54<02:18,  5.00it/s] 77%|███████▋  | 2373/3065 [07:54<02:18,  5.00it/s] 77%|███████▋  | 2374/3065 [07:54<02:18,  5.00it/s] 77%|███████▋  | 2375/3065 [07:54<02:18,  5.00it/s] 78%|███████▊  | 2376/3065 [07:54<02:17,  5.00it/s] 78%|███████▊  | 2377/3065 [07:55<02:17,  5.00it/s] 78%|███████▊  | 2378/3065 [07:55<02:17,  5.00it/s] 78%|███████▊  | 2379/3065 [07:55<02:17,  5.00it/s] 78%|███████▊  | 2380/3065 [07:55<02:16,  5.00it/s] 78%|███████▊  | 2381/3065 [07:55<02:16,  5.00it/s] 78%|███████▊  | 2382/3065 [07:56<02:16,  5.00it/s] 78%|███████▊  | 2383/3065 [07:56<02:16,  5.00it/s] 78%|███████▊  | 2384/3065 [07:56<02:16,  5.00it/s] 78%|███████▊  | 2385/3065 [07:56<02:16,  5.00it/s] 78%|███████▊  | 2386/3065 [07:56<02:15,  5.00it/s] 78%|███████▊  | 2387/3065 [07:57<02:15,  5.00it/s] 78%|███████▊  | 2388/3065 [07:57<02:15,  5.01it/s] 78%|███████▊  | 2389/3065 [07:57<02:15,  5.00it/s] 78%|███████▊  | 2390/3065 [07:57<02:14,  5.00it/s] 78%|███████▊  | 2391/3065 [07:57<02:14,  5.01it/s] 78%|███████▊  | 2392/3065 [07:58<02:14,  5.01it/s] 78%|███████▊  | 2393/3065 [07:58<02:14,  5.00it/s] 78%|███████▊  | 2394/3065 [07:58<02:14,  5.00it/s] 78%|███████▊  | 2395/3065 [07:58<02:13,  5.00it/s] 78%|███████▊  | 2396/3065 [07:58<02:13,  5.00it/s] 78%|███████▊  | 2397/3065 [07:59<02:13,  5.00it/s] 78%|███████▊  | 2398/3065 [07:59<02:13,  5.00it/s] 78%|███████▊  | 2399/3065 [07:59<02:13,  5.00it/s] 78%|███████▊  | 2400/3065 [07:59<02:12,  5.00it/s] 78%|███████▊  | 2401/3065 [07:59<02:12,  5.00it/s] 78%|███████▊  | 2402/3065 [08:00<02:12,  5.00it/s] 78%|███████▊  | 2403/3065 [08:00<02:12,  5.00it/s] 78%|███████▊  | 2404/3065 [08:00<02:12,  5.00it/s] 78%|███████▊  | 2405/3065 [08:00<02:12,  5.00it/s] 78%|███████▊  | 2406/3065 [08:00<02:11,  5.00it/s] 79%|███████▊  | 2407/3065 [08:01<02:11,  5.00it/s] 79%|███████▊  | 2408/3065 [08:01<02:11,  5.00it/s] 79%|███████▊  | 2409/3065 [08:01<02:11,  5.00it/s] 79%|███████▊  | 2410/3065 [08:01<02:10,  5.00it/s] 79%|███████▊  | 2411/3065 [08:01<02:10,  5.00it/s] 79%|███████▊  | 2412/3065 [08:02<02:10,  5.00it/s] 79%|███████▊  | 2413/3065 [08:02<02:10,  5.00it/s] 79%|███████▉  | 2414/3065 [08:02<02:10,  5.00it/s] 79%|███████▉  | 2415/3065 [08:02<02:09,  5.00it/s] 79%|███████▉  | 2416/3065 [08:02<02:09,  5.00it/s] 79%|███████▉  | 2417/3065 [08:03<02:09,  5.00it/s] 79%|███████▉  | 2418/3065 [08:03<02:09,  5.00it/s] 79%|███████▉  | 2419/3065 [08:03<02:09,  5.00it/s] 79%|███████▉  | 2420/3065 [08:03<02:08,  5.00it/s] 79%|███████▉  | 2421/3065 [08:03<02:08,  5.00it/s] 79%|███████▉  | 2422/3065 [08:04<02:08,  5.00it/s] 79%|███████▉  | 2423/3065 [08:04<02:08,  5.00it/s] 79%|███████▉  | 2424/3065 [08:04<02:08,  5.00it/s] 79%|███████▉  | 2425/3065 [08:04<02:07,  5.00it/s] 79%|███████▉  | 2426/3065 [08:04<02:07,  5.00it/s] 79%|███████▉  | 2427/3065 [08:05<02:07,  5.00it/s] 79%|███████▉  | 2428/3065 [08:05<02:07,  5.00it/s] 79%|███████▉  | 2429/3065 [08:05<02:07,  5.00it/s] 79%|███████▉  | 2430/3065 [08:05<02:06,  5.00it/s] 79%|███████▉  | 2431/3065 [08:05<02:06,  5.00it/s] 79%|███████▉  | 2432/3065 [08:06<02:06,  5.00it/s] 79%|███████▉  | 2433/3065 [08:06<02:06,  5.00it/s] 79%|███████▉  | 2434/3065 [08:06<02:06,  5.00it/s] 79%|███████▉  | 2435/3065 [08:06<02:05,  5.00it/s] 79%|███████▉  | 2436/3065 [08:06<02:05,  5.00it/s] 80%|███████▉  | 2437/3065 [08:07<02:05,  5.00it/s] 80%|███████▉  | 2438/3065 [08:07<02:05,  5.00it/s] 80%|███████▉  | 2439/3065 [08:07<02:05,  5.00it/s] 80%|███████▉  | 2440/3065 [08:07<02:04,  5.00it/s] 80%|███████▉  | 2441/3065 [08:07<02:04,  5.00it/s] 80%|███████▉  | 2442/3065 [08:08<02:04,  5.00it/s] 80%|███████▉  | 2443/3065 [08:08<02:04,  5.00it/s] 80%|███████▉  | 2444/3065 [08:08<02:04,  5.00it/s] 80%|███████▉  | 2445/3065 [08:08<02:03,  5.00it/s] 80%|███████▉  | 2446/3065 [08:08<02:03,  5.00it/s] 80%|███████▉  | 2447/3065 [08:09<02:03,  5.00it/s] 80%|███████▉  | 2448/3065 [08:09<02:03,  5.00it/s] 80%|███████▉  | 2449/3065 [08:09<02:03,  5.00it/s] 80%|███████▉  | 2450/3065 [08:09<02:02,  5.00it/s] 80%|███████▉  | 2451/3065 [08:09<02:02,  5.00it/s] 80%|████████  | 2452/3065 [08:10<02:02,  5.00it/s] 80%|████████  | 2453/3065 [08:10<02:02,  5.00it/s] 80%|████████  | 2454/3065 [08:10<02:02,  5.00it/s] 80%|████████  | 2455/3065 [08:10<02:01,  5.00it/s] 80%|████████  | 2456/3065 [08:10<02:01,  5.00it/s] 80%|████████  | 2457/3065 [08:11<02:01,  5.00it/s] 80%|████████  | 2458/3065 [08:11<02:01,  5.00it/s] 80%|████████  | 2459/3065 [08:11<02:01,  5.00it/s] 80%|████████  | 2460/3065 [08:11<02:01,  5.00it/s] 80%|████████  | 2461/3065 [08:11<02:00,  5.00it/s] 80%|████████  | 2462/3065 [08:12<02:00,  5.00it/s] 80%|████████  | 2463/3065 [08:12<02:00,  5.00it/s] 80%|████████  | 2464/3065 [08:12<02:00,  5.00it/s] 80%|████████  | 2465/3065 [08:12<01:59,  5.00it/s] 80%|████████  | 2466/3065 [08:12<01:59,  5.00it/s] 80%|████████  | 2467/3065 [08:13<01:59,  5.00it/s] 81%|████████  | 2468/3065 [08:13<01:59,  5.00it/s] 81%|████████  | 2469/3065 [08:13<01:59,  5.00it/s] 81%|████████  | 2470/3065 [08:13<01:58,  5.00it/s] 81%|████████  | 2471/3065 [08:13<01:58,  5.00it/s] 81%|████████  | 2472/3065 [08:14<01:58,  5.00it/s] 81%|████████  | 2473/3065 [08:14<01:58,  5.00it/s] 81%|████████  | 2474/3065 [08:14<01:58,  5.00it/s] 81%|████████  | 2475/3065 [08:14<01:57,  5.00it/s] 81%|████████  | 2476/3065 [08:14<01:57,  5.00it/s] 81%|████████  | 2477/3065 [08:15<01:57,  5.00it/s] 81%|████████  | 2478/3065 [08:15<01:57,  5.00it/s] 81%|████████  | 2479/3065 [08:15<01:57,  5.00it/s] 81%|████████  | 2480/3065 [08:15<01:56,  5.00it/s] 81%|████████  | 2481/3065 [08:15<01:56,  5.00it/s] 81%|████████  | 2482/3065 [08:16<01:56,  5.00it/s] 81%|████████  | 2483/3065 [08:16<01:56,  5.00it/s] 81%|████████  | 2484/3065 [08:16<01:56,  5.01it/s] 81%|████████  | 2485/3065 [08:16<01:55,  5.01it/s] 81%|████████  | 2486/3065 [08:16<01:55,  5.01it/s] 81%|████████  | 2487/3065 [08:17<01:55,  5.00it/s] 81%|████████  | 2488/3065 [08:17<01:55,  5.00it/s] 81%|████████  | 2489/3065 [08:17<01:55,  5.00it/s] 81%|████████  | 2490/3065 [08:17<01:54,  5.00it/s] 81%|████████▏ | 2491/3065 [08:17<01:54,  5.01it/s] 81%|████████▏ | 2492/3065 [08:18<01:54,  5.00it/s] 81%|████████▏ | 2493/3065 [08:18<01:54,  5.00it/s] 81%|████████▏ | 2494/3065 [08:18<01:54,  5.00it/s] 81%|████████▏ | 2495/3065 [08:18<01:53,  5.00it/s] 81%|████████▏ | 2496/3065 [08:18<01:53,  5.00it/s] 81%|████████▏ | 2497/3065 [08:19<01:53,  5.00it/s] 82%|████████▏ | 2498/3065 [08:19<01:53,  5.00it/s] 82%|████████▏ | 2499/3065 [08:19<01:53,  5.00it/s] 82%|████████▏ | 2500/3065 [08:19<01:53,  5.00it/s] 82%|████████▏ | 2501/3065 [08:19<01:52,  5.00it/s] 82%|████████▏ | 2502/3065 [08:20<01:52,  5.00it/s] 82%|████████▏ | 2503/3065 [08:20<01:52,  5.00it/s] 82%|████████▏ | 2504/3065 [08:20<01:52,  5.00it/s] 82%|████████▏ | 2505/3065 [08:20<01:51,  5.01it/s] 82%|████████▏ | 2506/3065 [08:20<01:51,  5.01it/s] 82%|████████▏ | 2507/3065 [08:21<01:51,  5.00it/s] 82%|████████▏ | 2508/3065 [08:21<01:51,  5.00it/s] 82%|████████▏ | 2509/3065 [08:21<01:51,  5.00it/s] 82%|████████▏ | 2510/3065 [08:21<01:50,  5.00it/s] 82%|████████▏ | 2511/3065 [08:21<01:50,  5.00it/s] 82%|████████▏ | 2512/3065 [08:22<01:50,  5.01it/s] 82%|████████▏ | 2513/3065 [08:22<01:50,  5.01it/s] 82%|████████▏ | 2514/3065 [08:22<01:50,  5.01it/s] 82%|████████▏ | 2515/3065 [08:22<01:49,  5.01it/s] 82%|████████▏ | 2516/3065 [08:22<01:49,  5.01it/s] 82%|████████▏ | 2517/3065 [08:23<01:49,  5.01it/s] 82%|████████▏ | 2518/3065 [08:23<01:49,  5.01it/s] 82%|████████▏ | 2519/3065 [08:23<01:48,  5.01it/s] 82%|████████▏ | 2520/3065 [08:23<01:48,  5.01it/s] 82%|████████▏ | 2521/3065 [08:23<01:48,  5.02it/s] 82%|████████▏ | 2522/3065 [08:24<01:48,  5.02it/s] 82%|████████▏ | 2523/3065 [08:24<01:47,  5.04it/s] 82%|████████▏ | 2524/3065 [08:24<01:46,  5.06it/s] 82%|████████▏ | 2525/3065 [08:24<01:46,  5.08it/s] 82%|████████▏ | 2526/3065 [08:24<01:46,  5.06it/s] 82%|████████▏ | 2527/3065 [08:25<01:46,  5.05it/s] 82%|████████▏ | 2528/3065 [08:25<01:46,  5.03it/s] 83%|████████▎ | 2529/3065 [08:25<01:46,  5.03it/s] 83%|████████▎ | 2530/3065 [08:25<01:46,  5.02it/s] 83%|████████▎ | 2531/3065 [08:25<01:46,  5.01it/s] 83%|████████▎ | 2532/3065 [08:26<01:46,  5.01it/s] 83%|████████▎ | 2533/3065 [08:26<01:46,  5.01it/s] 83%|████████▎ | 2534/3065 [08:26<01:46,  5.00it/s] 83%|████████▎ | 2535/3065 [08:26<01:45,  5.01it/s] 83%|████████▎ | 2536/3065 [08:26<01:45,  5.00it/s] 83%|████████▎ | 2537/3065 [08:27<01:45,  5.00it/s] 83%|████████▎ | 2538/3065 [08:27<01:45,  5.00it/s] 83%|████████▎ | 2539/3065 [08:27<01:45,  5.00it/s] 83%|████████▎ | 2540/3065 [08:27<01:44,  5.00it/s] 83%|████████▎ | 2541/3065 [08:27<01:44,  5.00it/s] 83%|████████▎ | 2542/3065 [08:28<01:44,  5.00it/s] 83%|████████▎ | 2543/3065 [08:28<01:44,  5.00it/s] 83%|████████▎ | 2544/3065 [08:28<01:44,  5.00it/s] 83%|████████▎ | 2545/3065 [08:28<01:43,  5.00it/s] 83%|████████▎ | 2546/3065 [08:28<01:43,  5.00it/s] 83%|████████▎ | 2547/3065 [08:29<01:43,  5.00it/s] 83%|████████▎ | 2548/3065 [08:29<01:43,  5.00it/s] 83%|████████▎ | 2549/3065 [08:29<01:43,  5.00it/s] 83%|████████▎ | 2550/3065 [08:29<01:42,  5.00it/s] 83%|████████▎ | 2551/3065 [08:29<01:42,  5.00it/s] 83%|████████▎ | 2552/3065 [08:30<01:42,  5.00it/s] 83%|████████▎ | 2553/3065 [08:30<01:42,  5.00it/s] 83%|████████▎ | 2554/3065 [08:30<01:42,  5.00it/s] 83%|████████▎ | 2555/3065 [08:30<01:41,  5.00it/s] 83%|████████▎ | 2556/3065 [08:30<01:41,  5.00it/s] 83%|████████▎ | 2557/3065 [08:31<01:41,  5.00it/s] 83%|████████▎ | 2558/3065 [08:31<01:41,  5.00it/s] 83%|████████▎ | 2559/3065 [08:31<01:41,  5.00it/s] 84%|████████▎ | 2560/3065 [08:31<01:40,  5.00it/s] 84%|████████▎ | 2561/3065 [08:31<01:40,  5.00it/s] 84%|████████▎ | 2562/3065 [08:32<01:40,  5.00it/s] 84%|████████▎ | 2563/3065 [08:32<01:40,  5.00it/s] 84%|████████▎ | 2564/3065 [08:32<01:40,  5.00it/s] 84%|████████▎ | 2565/3065 [08:32<01:39,  5.00it/s] 84%|████████▎ | 2566/3065 [08:32<01:39,  5.00it/s] 84%|████████▍ | 2567/3065 [08:33<01:39,  5.00it/s] 84%|████████▍ | 2568/3065 [08:33<01:39,  5.01it/s] 84%|████████▍ | 2569/3065 [08:33<01:39,  5.01it/s] 84%|████████▍ | 2570/3065 [08:33<01:38,  5.01it/s] 84%|████████▍ | 2571/3065 [08:33<01:38,  5.00it/s] 84%|████████▍ | 2572/3065 [08:34<01:38,  5.00it/s] 84%|████████▍ | 2573/3065 [08:34<01:38,  5.00it/s] 84%|████████▍ | 2574/3065 [08:34<01:38,  5.00it/s] 84%|████████▍ | 2575/3065 [08:34<01:38,  5.00it/s] 84%|████████▍ | 2576/3065 [08:34<01:37,  5.00it/s] 84%|████████▍ | 2577/3065 [08:35<01:37,  5.00it/s] 84%|████████▍ | 2578/3065 [08:35<01:37,  5.01it/s] 84%|████████▍ | 2579/3065 [08:35<01:37,  5.01it/s] 84%|████████▍ | 2580/3065 [08:35<01:36,  5.01it/s] 84%|████████▍ | 2581/3065 [08:35<01:36,  5.00it/s] 84%|████████▍ | 2582/3065 [08:36<01:36,  5.00it/s] 84%|████████▍ | 2583/3065 [08:36<01:36,  5.00it/s] 84%|████████▍ | 2584/3065 [08:36<01:36,  5.01it/s] 84%|████████▍ | 2585/3065 [08:36<01:35,  5.00it/s] 84%|████████▍ | 2586/3065 [08:36<01:35,  5.00it/s] 84%|████████▍ | 2587/3065 [08:37<01:35,  5.00it/s] 84%|████████▍ | 2588/3065 [08:37<01:35,  5.00it/s] 84%|████████▍ | 2589/3065 [08:37<01:35,  5.00it/s] 85%|████████▍ | 2590/3065 [08:37<01:35,  5.00it/s] 85%|████████▍ | 2591/3065 [08:37<01:34,  5.00it/s] 85%|████████▍ | 2592/3065 [08:38<01:34,  5.00it/s] 85%|████████▍ | 2593/3065 [08:38<01:34,  5.00it/s] 85%|████████▍ | 2594/3065 [08:38<01:34,  5.00it/s] 85%|████████▍ | 2595/3065 [08:38<01:33,  5.00it/s] 85%|████████▍ | 2596/3065 [08:38<01:33,  5.00it/s] 85%|████████▍ | 2597/3065 [08:39<01:33,  5.00it/s] 85%|████████▍ | 2598/3065 [08:39<01:33,  5.00it/s] 85%|████████▍ | 2599/3065 [08:39<01:33,  5.00it/s] 85%|████████▍ | 2600/3065 [08:39<01:32,  5.00it/s] 85%|████████▍ | 2601/3065 [08:39<01:32,  5.00it/s] 85%|████████▍ | 2602/3065 [08:40<01:32,  5.00it/s] 85%|████████▍ | 2603/3065 [08:40<01:32,  5.00it/s] 85%|████████▍ | 2604/3065 [08:40<01:32,  5.00it/s] 85%|████████▍ | 2605/3065 [08:40<01:32,  5.00it/s] 85%|████████▌ | 2606/3065 [08:40<01:31,  5.00it/s] 85%|████████▌ | 2607/3065 [08:41<01:31,  5.00it/s] 85%|████████▌ | 2608/3065 [08:41<01:31,  5.00it/s] 85%|████████▌ | 2609/3065 [08:41<01:31,  5.00it/s] 85%|████████▌ | 2610/3065 [08:41<01:30,  5.00it/s] 85%|████████▌ | 2611/3065 [08:41<01:30,  5.00it/s] 85%|████████▌ | 2612/3065 [08:42<01:30,  5.00it/s] 85%|████████▌ | 2613/3065 [08:42<01:30,  5.00it/s] 85%|████████▌ | 2614/3065 [08:42<01:30,  5.00it/s] 85%|████████▌ | 2615/3065 [08:42<01:29,  5.00it/s] 85%|████████▌ | 2616/3065 [08:42<01:29,  5.00it/s] 85%|████████▌ | 2617/3065 [08:43<01:29,  5.00it/s] 85%|████████▌ | 2618/3065 [08:43<01:29,  5.00it/s] 85%|████████▌ | 2619/3065 [08:43<01:29,  5.00it/s] 85%|████████▌ | 2620/3065 [08:43<01:28,  5.00it/s] 86%|████████▌ | 2621/3065 [08:43<01:28,  5.00it/s] 86%|████████▌ | 2622/3065 [08:44<01:28,  5.00it/s] 86%|████████▌ | 2623/3065 [08:44<01:28,  5.00it/s] 86%|████████▌ | 2624/3065 [08:44<01:28,  5.00it/s] 86%|████████▌ | 2625/3065 [08:44<01:28,  4.99it/s] 86%|████████▌ | 2626/3065 [08:44<01:27,  5.00it/s] 86%|████████▌ | 2627/3065 [08:45<01:27,  5.00it/s] 86%|████████▌ | 2628/3065 [08:45<01:27,  5.00it/s] 86%|████████▌ | 2629/3065 [08:45<01:27,  5.00it/s] 86%|████████▌ | 2630/3065 [08:45<01:26,  5.00it/s] 86%|████████▌ | 2631/3065 [08:45<01:26,  5.00it/s] 86%|████████▌ | 2632/3065 [08:46<01:26,  5.00it/s] 86%|████████▌ | 2633/3065 [08:46<01:26,  5.00it/s] 86%|████████▌ | 2634/3065 [08:46<01:26,  5.00it/s] 86%|████████▌ | 2635/3065 [08:46<01:26,  5.00it/s] 86%|████████▌ | 2636/3065 [08:46<01:25,  5.00it/s] 86%|████████▌ | 2637/3065 [08:47<01:25,  5.00it/s] 86%|████████▌ | 2638/3065 [08:47<01:25,  5.00it/s] 86%|████████▌ | 2639/3065 [08:47<01:25,  5.00it/s] 86%|████████▌ | 2640/3065 [08:47<01:24,  5.00it/s] 86%|████████▌ | 2641/3065 [08:47<01:24,  5.00it/s] 86%|████████▌ | 2642/3065 [08:48<01:24,  5.00it/s] 86%|████████▌ | 2643/3065 [08:48<01:24,  5.00it/s] 86%|████████▋ | 2644/3065 [08:48<01:24,  5.00it/s] 86%|████████▋ | 2645/3065 [08:48<01:23,  5.00it/s] 86%|████████▋ | 2646/3065 [08:48<01:23,  5.00it/s] 86%|████████▋ | 2647/3065 [08:49<01:23,  5.00it/s] 86%|████████▋ | 2648/3065 [08:49<01:23,  5.00it/s] 86%|████████▋ | 2649/3065 [08:49<01:23,  5.00it/s] 86%|████████▋ | 2650/3065 [08:49<01:22,  5.00it/s] 86%|████████▋ | 2651/3065 [08:49<01:22,  5.00it/s] 87%|████████▋ | 2652/3065 [08:50<01:22,  5.00it/s] 87%|████████▋ | 2653/3065 [08:50<01:22,  5.00it/s] 87%|████████▋ | 2654/3065 [08:50<01:22,  5.00it/s] 87%|████████▋ | 2655/3065 [08:50<01:21,  5.00it/s] 87%|████████▋ | 2656/3065 [08:50<01:21,  5.00it/s] 87%|████████▋ | 2657/3065 [08:51<01:21,  5.00it/s] 87%|████████▋ | 2658/3065 [08:51<01:21,  5.00it/s] 87%|████████▋ | 2659/3065 [08:51<01:21,  5.00it/s] 87%|████████▋ | 2660/3065 [08:51<01:21,  5.00it/s] 87%|████████▋ | 2661/3065 [08:51<01:20,  5.00it/s] 87%|████████▋ | 2662/3065 [08:52<01:20,  5.00it/s] 87%|████████▋ | 2663/3065 [08:52<01:20,  5.00it/s] 87%|████████▋ | 2664/3065 [08:52<01:20,  5.00it/s] 87%|████████▋ | 2665/3065 [08:52<01:19,  5.00it/s] 87%|████████▋ | 2666/3065 [08:52<01:19,  5.00it/s] 87%|████████▋ | 2667/3065 [08:53<01:19,  5.00it/s] 87%|████████▋ | 2668/3065 [08:53<01:19,  5.00it/s] 87%|████████▋ | 2669/3065 [08:53<01:19,  5.00it/s] 87%|████████▋ | 2670/3065 [08:53<01:19,  5.00it/s] 87%|████████▋ | 2671/3065 [08:53<01:18,  5.01it/s] 87%|████████▋ | 2672/3065 [08:54<01:18,  5.01it/s] 87%|████████▋ | 2673/3065 [08:54<01:18,  5.00it/s] 87%|████████▋ | 2674/3065 [08:54<01:18,  5.00it/s] 87%|████████▋ | 2675/3065 [08:54<01:17,  5.00it/s] 87%|████████▋ | 2676/3065 [08:54<01:17,  5.01it/s] 87%|████████▋ | 2677/3065 [08:55<01:17,  5.01it/s] 87%|████████▋ | 2678/3065 [08:55<01:17,  5.01it/s] 87%|████████▋ | 2679/3065 [08:55<01:17,  5.00it/s] 87%|████████▋ | 2680/3065 [08:55<01:17,  5.00it/s] 87%|████████▋ | 2681/3065 [08:55<01:16,  4.99it/s] 88%|████████▊ | 2682/3065 [08:56<01:16,  5.00it/s] 88%|████████▊ | 2683/3065 [08:56<01:16,  5.00it/s] 88%|████████▊ | 2684/3065 [08:56<01:16,  5.00it/s] 88%|████████▊ | 2685/3065 [08:56<01:15,  5.00it/s] 88%|████████▊ | 2686/3065 [08:56<01:15,  5.00it/s] 88%|████████▊ | 2687/3065 [08:57<01:15,  5.00it/s] 88%|████████▊ | 2688/3065 [08:57<01:15,  5.00it/s] 88%|████████▊ | 2689/3065 [08:57<01:15,  5.00it/s] 88%|████████▊ | 2690/3065 [08:57<01:14,  5.00it/s] 88%|████████▊ | 2691/3065 [08:57<01:14,  5.00it/s] 88%|████████▊ | 2692/3065 [08:58<01:14,  5.00it/s] 88%|████████▊ | 2693/3065 [08:58<01:14,  5.00it/s] 88%|████████▊ | 2694/3065 [08:58<01:14,  5.00it/s] 88%|████████▊ | 2695/3065 [08:58<01:13,  5.00it/s] 88%|████████▊ | 2696/3065 [08:58<01:13,  5.00it/s] 88%|████████▊ | 2697/3065 [08:59<01:13,  5.00it/s] 88%|████████▊ | 2698/3065 [08:59<01:13,  5.00it/s] 88%|████████▊ | 2699/3065 [08:59<01:13,  5.00it/s] 88%|████████▊ | 2700/3065 [08:59<01:12,  5.00it/s] 88%|████████▊ | 2701/3065 [08:59<01:12,  5.00it/s] 88%|████████▊ | 2702/3065 [09:00<01:12,  5.00it/s] 88%|████████▊ | 2703/3065 [09:00<01:12,  5.00it/s] 88%|████████▊ | 2704/3065 [09:00<01:12,  5.00it/s] 88%|████████▊ | 2705/3065 [09:00<01:11,  5.00it/s] 88%|████████▊ | 2706/3065 [09:00<01:11,  5.00it/s] 88%|████████▊ | 2707/3065 [09:01<01:11,  5.00it/s] 88%|████████▊ | 2708/3065 [09:01<01:11,  5.00it/s] 88%|████████▊ | 2709/3065 [09:01<01:11,  5.00it/s] 88%|████████▊ | 2710/3065 [09:01<01:10,  5.00it/s] 88%|████████▊ | 2711/3065 [09:01<01:10,  5.00it/s] 88%|████████▊ | 2712/3065 [09:02<01:10,  5.00it/s] 89%|████████▊ | 2713/3065 [09:02<01:10,  5.00it/s] 89%|████████▊ | 2714/3065 [09:02<01:10,  5.00it/s] 89%|████████▊ | 2715/3065 [09:02<01:09,  5.00it/s] 89%|████████▊ | 2716/3065 [09:02<01:09,  5.00it/s] 89%|████████▊ | 2717/3065 [09:03<01:09,  5.00it/s] 89%|████████▊ | 2718/3065 [09:03<01:09,  5.00it/s] 89%|████████▊ | 2719/3065 [09:03<01:09,  5.00it/s] 89%|████████▊ | 2720/3065 [09:03<01:08,  5.00it/s] 89%|████████▉ | 2721/3065 [09:03<01:08,  5.00it/s] 89%|████████▉ | 2722/3065 [09:04<01:08,  5.00it/s] 89%|████████▉ | 2723/3065 [09:04<01:08,  5.00it/s] 89%|████████▉ | 2724/3065 [09:04<01:08,  5.00it/s] 89%|████████▉ | 2725/3065 [09:04<01:07,  5.00it/s] 89%|████████▉ | 2726/3065 [09:04<01:07,  5.00it/s] 89%|████████▉ | 2727/3065 [09:05<01:07,  5.00it/s] 89%|████████▉ | 2728/3065 [09:05<01:07,  5.00it/s] 89%|████████▉ | 2729/3065 [09:05<01:07,  5.00it/s] 89%|████████▉ | 2730/3065 [09:05<01:06,  5.00it/s] 89%|████████▉ | 2731/3065 [09:05<01:06,  5.00it/s] 89%|████████▉ | 2732/3065 [09:06<01:06,  5.00it/s] 89%|████████▉ | 2733/3065 [09:06<01:06,  5.00it/s] 89%|████████▉ | 2734/3065 [09:06<01:06,  5.00it/s] 89%|████████▉ | 2735/3065 [09:06<01:06,  5.00it/s] 89%|████████▉ | 2736/3065 [09:06<01:05,  5.00it/s] 89%|████████▉ | 2737/3065 [09:07<01:05,  5.00it/s] 89%|████████▉ | 2738/3065 [09:07<01:05,  5.00it/s] 89%|████████▉ | 2739/3065 [09:07<01:05,  5.00it/s] 89%|████████▉ | 2740/3065 [09:07<01:04,  5.00it/s] 89%|████████▉ | 2741/3065 [09:07<01:04,  5.00it/s] 89%|████████▉ | 2742/3065 [09:08<01:04,  5.00it/s] 89%|████████▉ | 2743/3065 [09:08<01:04,  5.00it/s] 90%|████████▉ | 2744/3065 [09:08<01:04,  5.00it/s] 90%|████████▉ | 2745/3065 [09:08<01:03,  5.00it/s] 90%|████████▉ | 2746/3065 [09:08<01:03,  5.00it/s] 90%|████████▉ | 2747/3065 [09:09<01:03,  5.00it/s] 90%|████████▉ | 2748/3065 [09:09<01:03,  5.00it/s] 90%|████████▉ | 2749/3065 [09:09<01:03,  5.00it/s] 90%|████████▉ | 2750/3065 [09:09<01:03,  5.00it/s] 90%|████████▉ | 2751/3065 [09:09<01:02,  5.00it/s] 90%|████████▉ | 2752/3065 [09:10<01:02,  5.00it/s] 90%|████████▉ | 2753/3065 [09:10<01:02,  5.00it/s] 90%|████████▉ | 2754/3065 [09:10<01:02,  5.00it/s] 90%|████████▉ | 2755/3065 [09:10<01:01,  5.00it/s] 90%|████████▉ | 2756/3065 [09:10<01:01,  5.00it/s] 90%|████████▉ | 2757/3065 [09:11<01:01,  5.00it/s] 90%|████████▉ | 2758/3065 [09:11<01:01,  5.00it/s] 90%|█████████ | 2759/3065 [09:11<01:01,  5.00it/s] 90%|█████████ | 2760/3065 [09:11<01:00,  5.00it/s] 90%|█████████ | 2761/3065 [09:11<01:00,  5.00it/s] 90%|█████████ | 2762/3065 [09:12<01:00,  5.00it/s] 90%|█████████ | 2763/3065 [09:12<01:00,  5.00it/s] 90%|█████████ | 2764/3065 [09:12<01:00,  5.00it/s] 90%|█████████ | 2765/3065 [09:12<00:59,  5.00it/s] 90%|█████████ | 2766/3065 [09:12<00:59,  5.00it/s] 90%|█████████ | 2767/3065 [09:13<00:59,  5.00it/s] 90%|█████████ | 2768/3065 [09:13<00:59,  5.00it/s] 90%|█████████ | 2769/3065 [09:13<00:59,  5.00it/s] 90%|█████████ | 2770/3065 [09:13<00:58,  5.00it/s] 90%|█████████ | 2771/3065 [09:13<00:58,  5.00it/s] 90%|█████████ | 2772/3065 [09:14<00:58,  5.00it/s] 90%|█████████ | 2773/3065 [09:14<00:58,  4.99it/s] 91%|█████████ | 2774/3065 [09:14<00:58,  4.99it/s] 91%|█████████ | 2775/3065 [09:14<00:58,  5.00it/s] 91%|█████████ | 2776/3065 [09:14<00:57,  5.00it/s] 91%|█████████ | 2777/3065 [09:15<00:57,  5.00it/s] 91%|█████████ | 2778/3065 [09:15<00:57,  5.00it/s] 91%|█████████ | 2779/3065 [09:15<00:57,  5.00it/s] 91%|█████████ | 2780/3065 [09:15<00:56,  5.00it/s] 91%|█████████ | 2781/3065 [09:15<00:56,  5.00it/s] 91%|█████████ | 2782/3065 [09:16<00:56,  5.00it/s] 91%|█████████ | 2783/3065 [09:16<00:56,  5.00it/s] 91%|█████████ | 2784/3065 [09:16<00:56,  5.00it/s] 91%|█████████ | 2785/3065 [09:16<00:55,  5.00it/s] 91%|█████████ | 2786/3065 [09:16<00:55,  5.00it/s] 91%|█████████ | 2787/3065 [09:17<00:55,  5.01it/s] 91%|█████████ | 2788/3065 [09:17<00:55,  5.01it/s] 91%|█████████ | 2789/3065 [09:17<00:55,  5.01it/s] 91%|█████████ | 2790/3065 [09:17<00:54,  5.01it/s] 91%|█████████ | 2791/3065 [09:17<00:54,  5.00it/s] 91%|█████████ | 2792/3065 [09:18<00:54,  5.00it/s] 91%|█████████ | 2793/3065 [09:18<00:54,  5.00it/s] 91%|█████████ | 2794/3065 [09:18<00:54,  5.01it/s] 91%|█████████ | 2795/3065 [09:18<00:53,  5.00it/s] 91%|█████████ | 2796/3065 [09:18<00:53,  5.00it/s] 91%|█████████▏| 2797/3065 [09:19<00:53,  5.00it/s] 91%|█████████▏| 2798/3065 [09:19<00:53,  5.00it/s] 91%|█████████▏| 2799/3065 [09:19<00:53,  5.00it/s] 91%|█████████▏| 2800/3065 [09:19<00:52,  5.00it/s] 91%|█████████▏| 2801/3065 [09:19<00:52,  5.00it/s] 91%|█████████▏| 2802/3065 [09:20<00:52,  5.00it/s] 91%|█████████▏| 2803/3065 [09:20<00:52,  5.00it/s] 91%|█████████▏| 2804/3065 [09:20<00:52,  5.00it/s] 92%|█████████▏| 2805/3065 [09:20<00:51,  5.00it/s] 92%|█████████▏| 2806/3065 [09:20<00:51,  5.00it/s] 92%|█████████▏| 2807/3065 [09:21<00:51,  5.00it/s] 92%|█████████▏| 2808/3065 [09:21<00:51,  5.00it/s] 92%|█████████▏| 2809/3065 [09:21<00:51,  5.00it/s] 92%|█████████▏| 2810/3065 [09:21<00:50,  5.00it/s] 92%|█████████▏| 2811/3065 [09:21<00:50,  5.00it/s] 92%|█████████▏| 2812/3065 [09:22<00:50,  5.00it/s] 92%|█████████▏| 2813/3065 [09:22<00:50,  5.00it/s] 92%|█████████▏| 2814/3065 [09:22<00:50,  5.00it/s] 92%|█████████▏| 2815/3065 [09:22<00:49,  5.00it/s] 92%|█████████▏| 2816/3065 [09:22<00:49,  5.00it/s] 92%|█████████▏| 2817/3065 [09:23<00:49,  5.00it/s] 92%|█████████▏| 2818/3065 [09:23<00:49,  5.00it/s] 92%|█████████▏| 2819/3065 [09:23<00:49,  5.00it/s] 92%|█████████▏| 2820/3065 [09:23<00:48,  5.00it/s] 92%|█████████▏| 2821/3065 [09:23<00:48,  5.00it/s] 92%|█████████▏| 2822/3065 [09:24<00:48,  5.00it/s] 92%|█████████▏| 2823/3065 [09:24<00:48,  5.00it/s] 92%|█████████▏| 2824/3065 [09:24<00:48,  5.00it/s] 92%|█████████▏| 2825/3065 [09:24<00:47,  5.00it/s] 92%|█████████▏| 2826/3065 [09:24<00:47,  5.00it/s] 92%|█████████▏| 2827/3065 [09:25<00:47,  5.00it/s] 92%|█████████▏| 2828/3065 [09:25<00:47,  5.00it/s] 92%|█████████▏| 2829/3065 [09:25<00:47,  5.00it/s] 92%|█████████▏| 2830/3065 [09:25<00:46,  5.00it/s] 92%|█████████▏| 2831/3065 [09:25<00:46,  5.00it/s] 92%|█████████▏| 2832/3065 [09:26<00:46,  5.00it/s] 92%|█████████▏| 2833/3065 [09:26<00:46,  5.00it/s] 92%|█████████▏| 2834/3065 [09:26<00:46,  5.00it/s] 92%|█████████▏| 2835/3065 [09:26<00:45,  5.00it/s] 93%|█████████▎| 2836/3065 [09:26<00:45,  5.00it/s] 93%|█████████▎| 2837/3065 [09:27<00:45,  5.00it/s] 93%|█████████▎| 2838/3065 [09:27<00:45,  5.00it/s] 93%|█████████▎| 2839/3065 [09:27<00:45,  5.00it/s] 93%|█████████▎| 2840/3065 [09:27<00:45,  5.00it/s] 93%|█████████▎| 2841/3065 [09:27<00:44,  5.00it/s] 93%|█████████▎| 2842/3065 [09:28<00:44,  5.00it/s] 93%|█████████▎| 2843/3065 [09:28<00:44,  5.00it/s] 93%|█████████▎| 2844/3065 [09:28<00:44,  5.00it/s] 93%|█████████▎| 2845/3065 [09:28<00:44,  5.00it/s] 93%|█████████▎| 2846/3065 [09:28<00:43,  5.00it/s] 93%|█████████▎| 2847/3065 [09:29<00:43,  5.01it/s] 93%|█████████▎| 2848/3065 [09:29<00:43,  5.01it/s] 93%|█████████▎| 2849/3065 [09:29<00:43,  5.01it/s] 93%|█████████▎| 2850/3065 [09:29<00:42,  5.01it/s] 93%|█████████▎| 2851/3065 [09:29<00:42,  5.00it/s] 93%|█████████▎| 2852/3065 [09:30<00:42,  5.01it/s] 93%|█████████▎| 2853/3065 [09:30<00:42,  5.00it/s] 93%|█████████▎| 2854/3065 [09:30<00:42,  5.00it/s] 93%|█████████▎| 2855/3065 [09:30<00:42,  5.00it/s] 93%|█████████▎| 2856/3065 [09:30<00:41,  5.00it/s] 93%|█████████▎| 2857/3065 [09:31<00:41,  5.00it/s] 93%|█████████▎| 2858/3065 [09:31<00:41,  5.00it/s] 93%|█████████▎| 2859/3065 [09:31<00:41,  5.00it/s] 93%|█████████▎| 2860/3065 [09:31<00:41,  5.00it/s] 93%|█████████▎| 2861/3065 [09:31<00:40,  5.00it/s] 93%|█████████▎| 2862/3065 [09:32<00:40,  5.00it/s] 93%|█████████▎| 2863/3065 [09:32<00:40,  5.00it/s] 93%|█████████▎| 2864/3065 [09:32<00:40,  5.00it/s] 93%|█████████▎| 2865/3065 [09:32<00:39,  5.00it/s] 94%|█████████▎| 2866/3065 [09:32<00:39,  5.00it/s] 94%|█████████▎| 2867/3065 [09:33<00:39,  5.00it/s] 94%|█████████▎| 2868/3065 [09:33<00:39,  5.00it/s] 94%|█████████▎| 2869/3065 [09:33<00:39,  5.00it/s] 94%|█████████▎| 2870/3065 [09:33<00:38,  5.00it/s] 94%|█████████▎| 2871/3065 [09:33<00:38,  5.00it/s] 94%|█████████▎| 2872/3065 [09:34<00:38,  5.00it/s] 94%|█████████▎| 2873/3065 [09:34<00:38,  5.00it/s] 94%|█████████▍| 2874/3065 [09:34<00:38,  5.00it/s] 94%|█████████▍| 2875/3065 [09:34<00:37,  5.00it/s] 94%|█████████▍| 2876/3065 [09:34<00:37,  5.00it/s] 94%|█████████▍| 2877/3065 [09:35<00:37,  5.00it/s] 94%|█████████▍| 2878/3065 [09:35<00:37,  5.00it/s] 94%|█████████▍| 2879/3065 [09:35<00:37,  5.00it/s] 94%|█████████▍| 2880/3065 [09:35<00:36,  5.00it/s] 94%|█████████▍| 2881/3065 [09:35<00:36,  5.00it/s] 94%|█████████▍| 2882/3065 [09:36<00:36,  5.00it/s] 94%|█████████▍| 2883/3065 [09:36<00:36,  5.00it/s] 94%|█████████▍| 2884/3065 [09:36<00:36,  5.00it/s] 94%|█████████▍| 2885/3065 [09:36<00:35,  5.00it/s] 94%|█████████▍| 2886/3065 [09:36<00:35,  5.00it/s] 94%|█████████▍| 2887/3065 [09:37<00:35,  5.00it/s] 94%|█████████▍| 2888/3065 [09:37<00:35,  5.00it/s] 94%|█████████▍| 2889/3065 [09:37<00:35,  5.00it/s] 94%|█████████▍| 2890/3065 [09:37<00:34,  5.00it/s] 94%|█████████▍| 2891/3065 [09:37<00:34,  5.00it/s] 94%|█████████▍| 2892/3065 [09:38<00:34,  5.00it/s] 94%|█████████▍| 2893/3065 [09:38<00:34,  5.00it/s] 94%|█████████▍| 2894/3065 [09:38<00:34,  5.00it/s] 94%|█████████▍| 2895/3065 [09:38<00:34,  5.00it/s] 94%|█████████▍| 2896/3065 [09:38<00:33,  5.00it/s] 95%|█████████▍| 2897/3065 [09:39<00:33,  5.00it/s] 95%|█████████▍| 2898/3065 [09:39<00:33,  5.00it/s] 95%|█████████▍| 2899/3065 [09:39<00:33,  5.00it/s] 95%|█████████▍| 2900/3065 [09:39<00:32,  5.00it/s] 95%|█████████▍| 2901/3065 [09:39<00:32,  5.00it/s] 95%|█████████▍| 2902/3065 [09:40<00:32,  5.00it/s] 95%|█████████▍| 2903/3065 [09:40<00:32,  5.00it/s] 95%|█████████▍| 2904/3065 [09:40<00:32,  5.00it/s] 95%|█████████▍| 2905/3065 [09:40<00:31,  5.00it/s] 95%|█████████▍| 2906/3065 [09:40<00:31,  5.00it/s] 95%|█████████▍| 2907/3065 [09:41<00:31,  5.00it/s] 95%|█████████▍| 2908/3065 [09:41<00:31,  5.00it/s] 95%|█████████▍| 2909/3065 [09:41<00:31,  5.01it/s] 95%|█████████▍| 2910/3065 [09:41<00:30,  5.00it/s] 95%|█████████▍| 2911/3065 [09:41<00:30,  5.00it/s] 95%|█████████▌| 2912/3065 [09:42<00:30,  5.00it/s] 95%|█████████▌| 2913/3065 [09:42<00:30,  5.00it/s] 95%|█████████▌| 2914/3065 [09:42<00:30,  5.00it/s] 95%|█████████▌| 2915/3065 [09:42<00:29,  5.00it/s] 95%|█████████▌| 2916/3065 [09:42<00:29,  5.00it/s] 95%|█████████▌| 2917/3065 [09:43<00:29,  5.00it/s] 95%|█████████▌| 2918/3065 [09:43<00:29,  5.00it/s] 95%|█████████▌| 2919/3065 [09:43<00:29,  5.00it/s] 95%|█████████▌| 2920/3065 [09:43<00:28,  5.00it/s] 95%|█████████▌| 2921/3065 [09:43<00:28,  5.00it/s] 95%|█████████▌| 2922/3065 [09:44<00:28,  5.00it/s] 95%|█████████▌| 2923/3065 [09:44<00:28,  5.00it/s] 95%|█████████▌| 2924/3065 [09:44<00:28,  5.00it/s] 95%|█████████▌| 2925/3065 [09:44<00:27,  5.00it/s] 95%|█████████▌| 2926/3065 [09:44<00:27,  5.00it/s] 95%|█████████▌| 2927/3065 [09:45<00:27,  5.00it/s] 96%|█████████▌| 2928/3065 [09:45<00:27,  5.00it/s] 96%|█████████▌| 2929/3065 [09:45<00:27,  5.00it/s] 96%|█████████▌| 2930/3065 [09:45<00:26,  5.00it/s] 96%|█████████▌| 2931/3065 [09:45<00:26,  5.00it/s] 96%|█████████▌| 2932/3065 [09:46<00:26,  5.00it/s] 96%|█████████▌| 2933/3065 [09:46<00:26,  5.00it/s] 96%|█████████▌| 2934/3065 [09:46<00:26,  5.00it/s] 96%|█████████▌| 2935/3065 [09:46<00:25,  5.00it/s] 96%|█████████▌| 2936/3065 [09:46<00:25,  5.00it/s] 96%|█████████▌| 2937/3065 [09:47<00:25,  5.00it/s] 96%|█████████▌| 2938/3065 [09:47<00:25,  5.00it/s] 96%|█████████▌| 2939/3065 [09:47<00:25,  5.00it/s] 96%|█████████▌| 2940/3065 [09:47<00:24,  5.00it/s] 96%|█████████▌| 2941/3065 [09:47<00:24,  5.00it/s] 96%|█████████▌| 2942/3065 [09:48<00:24,  5.00it/s] 96%|█████████▌| 2943/3065 [09:48<00:24,  5.00it/s] 96%|█████████▌| 2944/3065 [09:48<00:24,  5.00it/s] 96%|█████████▌| 2945/3065 [09:48<00:23,  5.00it/s] 96%|█████████▌| 2946/3065 [09:48<00:23,  5.00it/s] 96%|█████████▌| 2947/3065 [09:49<00:23,  5.00it/s] 96%|█████████▌| 2948/3065 [09:49<00:23,  5.00it/s] 96%|█████████▌| 2949/3065 [09:49<00:23,  5.00it/s] 96%|█████████▌| 2950/3065 [09:49<00:22,  5.00it/s] 96%|█████████▋| 2951/3065 [09:49<00:22,  5.00it/s] 96%|█████████▋| 2952/3065 [09:50<00:22,  5.00it/s] 96%|█████████▋| 2953/3065 [09:50<00:22,  5.00it/s] 96%|█████████▋| 2954/3065 [09:50<00:22,  5.00it/s] 96%|█████████▋| 2955/3065 [09:50<00:21,  5.01it/s] 96%|█████████▋| 2956/3065 [09:50<00:21,  5.01it/s] 96%|█████████▋| 2957/3065 [09:51<00:21,  5.01it/s] 97%|█████████▋| 2958/3065 [09:51<00:21,  5.01it/s] 97%|█████████▋| 2959/3065 [09:51<00:21,  5.01it/s] 97%|█████████▋| 2960/3065 [09:51<00:20,  5.00it/s] 97%|█████████▋| 2961/3065 [09:51<00:20,  5.00it/s] 97%|█████████▋| 2962/3065 [09:52<00:20,  5.00it/s] 97%|█████████▋| 2963/3065 [09:52<00:20,  5.00it/s] 97%|█████████▋| 2964/3065 [09:52<00:20,  5.00it/s] 97%|█████████▋| 2965/3065 [09:52<00:19,  5.01it/s] 97%|█████████▋| 2966/3065 [09:52<00:19,  5.01it/s] 97%|█████████▋| 2967/3065 [09:53<00:19,  5.01it/s] 97%|█████████▋| 2968/3065 [09:53<00:19,  5.01it/s] 97%|█████████▋| 2969/3065 [09:53<00:19,  5.01it/s] 97%|█████████▋| 2970/3065 [09:53<00:18,  5.01it/s] 97%|█████████▋| 2971/3065 [09:53<00:18,  5.02it/s] 97%|█████████▋| 2972/3065 [09:54<00:18,  5.03it/s] 97%|█████████▋| 2973/3065 [09:54<00:18,  5.06it/s] 97%|█████████▋| 2974/3065 [09:54<00:17,  5.08it/s] 97%|█████████▋| 2975/3065 [09:54<00:17,  5.07it/s] 97%|█████████▋| 2976/3065 [09:54<00:17,  5.05it/s] 97%|█████████▋| 2977/3065 [09:55<00:17,  5.04it/s] 97%|█████████▋| 2978/3065 [09:55<00:17,  5.03it/s] 97%|█████████▋| 2979/3065 [09:55<00:17,  5.03it/s] 97%|█████████▋| 2980/3065 [09:55<00:16,  5.02it/s] 97%|█████████▋| 2981/3065 [09:55<00:16,  5.02it/s] 97%|█████████▋| 2982/3065 [09:56<00:16,  5.02it/s] 97%|█████████▋| 2983/3065 [09:56<00:16,  5.03it/s] 97%|█████████▋| 2984/3065 [09:56<00:16,  5.05it/s] 97%|█████████▋| 2985/3065 [09:56<00:15,  5.07it/s] 97%|█████████▋| 2986/3065 [09:56<00:15,  5.09it/s] 97%|█████████▋| 2987/3065 [09:57<00:15,  5.07it/s] 97%|█████████▋| 2988/3065 [09:57<00:15,  5.05it/s] 98%|█████████▊| 2989/3065 [09:57<00:15,  5.04it/s] 98%|█████████▊| 2990/3065 [09:57<00:14,  5.03it/s] 98%|█████████▊| 2991/3065 [09:57<00:14,  5.02it/s] 98%|█████████▊| 2992/3065 [09:58<00:14,  5.01it/s] 98%|█████████▊| 2993/3065 [09:58<00:14,  5.01it/s] 98%|█████████▊| 2994/3065 [09:58<00:14,  5.01it/s] 98%|█████████▊| 2995/3065 [09:58<00:13,  5.00it/s] 98%|█████████▊| 2996/3065 [09:58<00:13,  5.00it/s] 98%|█████████▊| 2997/3065 [09:59<00:13,  5.00it/s] 98%|█████████▊| 2998/3065 [09:59<00:13,  5.00it/s] 98%|█████████▊| 2999/3065 [09:59<00:13,  5.00it/s] 98%|█████████▊| 3000/3065 [09:59<00:12,  5.00it/s] 98%|█████████▊| 3001/3065 [09:59<00:12,  5.00it/s] 98%|█████████▊| 3002/3065 [10:00<00:12,  5.00it/s] 98%|█████████▊| 3003/3065 [10:00<00:12,  5.00it/s] 98%|█████████▊| 3004/3065 [10:00<00:12,  5.00it/s] 98%|█████████▊| 3005/3065 [10:00<00:11,  5.00it/s] 98%|█████████▊| 3006/3065 [10:00<00:11,  5.00it/s] 98%|█████████▊| 3007/3065 [10:01<00:11,  5.00it/s] 98%|█████████▊| 3008/3065 [10:01<00:11,  5.00it/s] 98%|█████████▊| 3009/3065 [10:01<00:11,  5.00it/s] 98%|█████████▊| 3010/3065 [10:01<00:11,  5.00it/s] 98%|█████████▊| 3011/3065 [10:01<00:10,  5.00it/s] 98%|█████████▊| 3012/3065 [10:02<00:10,  5.00it/s] 98%|█████████▊| 3013/3065 [10:02<00:10,  5.00it/s] 98%|█████████▊| 3014/3065 [10:02<00:10,  5.00it/s] 98%|█████████▊| 3015/3065 [10:02<00:09,  5.00it/s] 98%|█████████▊| 3016/3065 [10:02<00:09,  5.00it/s] 98%|█████████▊| 3017/3065 [10:03<00:09,  5.01it/s] 98%|█████████▊| 3018/3065 [10:03<00:09,  5.00it/s] 98%|█████████▊| 3019/3065 [10:03<00:09,  5.00it/s] 99%|█████████▊| 3020/3065 [10:03<00:08,  5.00it/s] 99%|█████████▊| 3021/3065 [10:03<00:08,  5.00it/s] 99%|█████████▊| 3022/3065 [10:04<00:08,  5.00it/s] 99%|█████████▊| 3023/3065 [10:04<00:08,  5.00it/s] 99%|█████████▊| 3024/3065 [10:04<00:08,  5.01it/s] 99%|█████████▊| 3025/3065 [10:04<00:07,  5.01it/s] 99%|█████████▊| 3026/3065 [10:04<00:07,  5.01it/s] 99%|█████████▉| 3027/3065 [10:05<00:07,  5.01it/s] 99%|█████████▉| 3028/3065 [10:05<00:07,  5.01it/s] 99%|█████████▉| 3029/3065 [10:05<00:07,  5.01it/s] 99%|█████████▉| 3030/3065 [10:05<00:06,  5.01it/s] 99%|█████████▉| 3031/3065 [10:05<00:06,  5.01it/s] 99%|█████████▉| 3032/3065 [10:06<00:06,  5.01it/s] 99%|█████████▉| 3033/3065 [10:06<00:06,  5.01it/s] 99%|█████████▉| 3034/3065 [10:06<00:06,  5.00it/s] 99%|█████████▉| 3035/3065 [10:06<00:05,  5.00it/s] 99%|█████████▉| 3036/3065 [10:06<00:05,  5.00it/s] 99%|█████████▉| 3037/3065 [10:07<00:05,  5.00it/s] 99%|█████████▉| 3038/3065 [10:07<00:05,  5.00it/s] 99%|█████████▉| 3039/3065 [10:07<00:05,  5.00it/s] 99%|█████████▉| 3040/3065 [10:07<00:05,  5.00it/s] 99%|█████████▉| 3041/3065 [10:07<00:04,  5.00it/s] 99%|█████████▉| 3042/3065 [10:08<00:04,  5.00it/s] 99%|█████████▉| 3043/3065 [10:08<00:04,  5.00it/s] 99%|█████████▉| 3044/3065 [10:08<00:04,  5.00it/s] 99%|█████████▉| 3045/3065 [10:08<00:03,  5.01it/s] 99%|█████████▉| 3046/3065 [10:08<00:03,  5.01it/s] 99%|█████████▉| 3047/3065 [10:09<00:03,  5.00it/s] 99%|█████████▉| 3048/3065 [10:09<00:03,  5.00it/s] 99%|█████████▉| 3049/3065 [10:09<00:03,  5.01it/s]100%|█████████▉| 3050/3065 [10:09<00:02,  5.00it/s]100%|█████████▉| 3051/3065 [10:09<00:02,  5.00it/s]100%|█████████▉| 3052/3065 [10:10<00:02,  5.00it/s]100%|█████████▉| 3053/3065 [10:10<00:02,  5.00it/s]100%|█████████▉| 3054/3065 [10:10<00:02,  5.00it/s]100%|█████████▉| 3055/3065 [10:10<00:02,  5.00it/s]100%|█████████▉| 3056/3065 [10:10<00:01,  5.00it/s]100%|█████████▉| 3057/3065 [10:11<00:01,  5.00it/s]100%|█████████▉| 3058/3065 [10:11<00:01,  5.00it/s]100%|█████████▉| 3059/3065 [10:11<00:01,  5.00it/s]100%|█████████▉| 3060/3065 [10:11<00:01,  5.00it/s]100%|█████████▉| 3061/3065 [10:11<00:00,  5.00it/s]100%|█████████▉| 3062/3065 [10:12<00:00,  5.00it/s]100%|█████████▉| 3063/3065 [10:12<00:00,  5.00it/s]100%|█████████▉| 3064/3065 [10:12<00:00,  5.00it/s]100%|██████████| 3065/3065 [10:12<00:00,  5.00it/s]
Predicting and calculating anomaly scores..
  0%|          | 0/675 [00:00<?, ?it/s]  0%|          | 1/675 [00:00<02:09,  5.19it/s]  0%|          | 2/675 [00:00<02:10,  5.16it/s]  0%|          | 3/675 [00:00<02:11,  5.11it/s]  1%|          | 4/675 [00:00<02:12,  5.08it/s]  1%|          | 5/675 [00:00<02:12,  5.06it/s]  1%|          | 6/675 [00:01<02:12,  5.06it/s]  1%|          | 7/675 [00:01<02:11,  5.07it/s]  1%|          | 8/675 [00:01<02:10,  5.10it/s]  1%|▏         | 9/675 [00:01<02:10,  5.10it/s]  1%|▏         | 10/675 [00:01<02:11,  5.07it/s]  2%|▏         | 11/675 [00:02<02:11,  5.05it/s]  2%|▏         | 12/675 [00:02<02:11,  5.03it/s]  2%|▏         | 13/675 [00:02<02:11,  5.02it/s]  2%|▏         | 14/675 [00:02<02:11,  5.02it/s]  2%|▏         | 15/675 [00:02<02:11,  5.01it/s]  2%|▏         | 16/675 [00:03<02:11,  5.01it/s]  3%|▎         | 17/675 [00:03<02:11,  5.01it/s]  3%|▎         | 18/675 [00:03<02:11,  5.01it/s]  3%|▎         | 19/675 [00:03<02:11,  5.00it/s]  3%|▎         | 20/675 [00:03<02:10,  5.00it/s]  3%|▎         | 21/675 [00:04<02:10,  5.00it/s]  3%|▎         | 22/675 [00:04<02:10,  5.00it/s]  3%|▎         | 23/675 [00:04<02:10,  5.00it/s]  4%|▎         | 24/675 [00:04<02:10,  5.00it/s]  4%|▎         | 25/675 [00:04<02:09,  5.00it/s]  4%|▍         | 26/675 [00:05<02:09,  5.00it/s]  4%|▍         | 27/675 [00:05<02:09,  5.00it/s]  4%|▍         | 28/675 [00:05<02:09,  5.00it/s]  4%|▍         | 29/675 [00:05<02:09,  5.00it/s]  4%|▍         | 30/675 [00:05<02:08,  5.00it/s]  5%|▍         | 31/675 [00:06<02:08,  5.00it/s]  5%|▍         | 32/675 [00:06<02:08,  5.00it/s]  5%|▍         | 33/675 [00:06<02:08,  5.00it/s]  5%|▌         | 34/675 [00:06<02:08,  5.00it/s]  5%|▌         | 35/675 [00:06<02:07,  5.00it/s]  5%|▌         | 36/675 [00:07<02:07,  5.00it/s]  5%|▌         | 37/675 [00:07<02:07,  5.00it/s]  6%|▌         | 38/675 [00:07<02:07,  5.00it/s]  6%|▌         | 39/675 [00:07<02:07,  5.00it/s]  6%|▌         | 40/675 [00:07<02:06,  5.00it/s]  6%|▌         | 41/675 [00:08<02:06,  5.00it/s]  6%|▌         | 42/675 [00:08<02:06,  5.00it/s]  6%|▋         | 43/675 [00:08<02:06,  5.00it/s]  7%|▋         | 44/675 [00:08<02:06,  5.00it/s]  7%|▋         | 45/675 [00:08<02:05,  5.00it/s]  7%|▋         | 46/675 [00:09<02:05,  5.00it/s]  7%|▋         | 47/675 [00:09<02:05,  5.00it/s]  7%|▋         | 48/675 [00:09<02:05,  5.00it/s]  7%|▋         | 49/675 [00:09<02:05,  5.00it/s]  7%|▋         | 50/675 [00:09<02:04,  5.00it/s]  8%|▊         | 51/675 [00:10<02:04,  5.00it/s]  8%|▊         | 52/675 [00:10<02:04,  5.00it/s]  8%|▊         | 53/675 [00:10<02:04,  5.00it/s]  8%|▊         | 54/675 [00:10<02:04,  5.00it/s]  8%|▊         | 55/675 [00:10<02:03,  5.00it/s]  8%|▊         | 56/675 [00:11<02:03,  5.00it/s]  8%|▊         | 57/675 [00:11<02:03,  5.00it/s]  9%|▊         | 58/675 [00:11<02:03,  5.00it/s]  9%|▊         | 59/675 [00:11<02:03,  5.00it/s]  9%|▉         | 60/675 [00:11<02:02,  5.01it/s]  9%|▉         | 61/675 [00:12<02:02,  5.00it/s]  9%|▉         | 62/675 [00:12<02:02,  5.00it/s]  9%|▉         | 63/675 [00:12<02:02,  5.00it/s]  9%|▉         | 64/675 [00:12<02:02,  5.00it/s] 10%|▉         | 65/675 [00:12<02:01,  5.01it/s] 10%|▉         | 66/675 [00:13<02:01,  5.01it/s] 10%|▉         | 67/675 [00:13<02:01,  5.01it/s] 10%|█         | 68/675 [00:13<02:01,  5.00it/s] 10%|█         | 69/675 [00:13<02:01,  5.00it/s] 10%|█         | 70/675 [00:13<02:00,  5.00it/s] 11%|█         | 71/675 [00:14<02:00,  5.00it/s] 11%|█         | 72/675 [00:14<02:00,  5.00it/s] 11%|█         | 73/675 [00:14<02:00,  5.00it/s] 11%|█         | 74/675 [00:14<02:00,  5.00it/s] 11%|█         | 75/675 [00:14<01:59,  5.00it/s] 11%|█▏        | 76/675 [00:15<01:59,  5.00it/s] 11%|█▏        | 77/675 [00:15<01:59,  5.00it/s] 12%|█▏        | 78/675 [00:15<01:59,  5.00it/s] 12%|█▏        | 79/675 [00:15<01:59,  5.00it/s] 12%|█▏        | 80/675 [00:15<01:59,  5.00it/s] 12%|█▏        | 81/675 [00:16<01:58,  5.00it/s] 12%|█▏        | 82/675 [00:16<01:58,  5.00it/s] 12%|█▏        | 83/675 [00:16<01:58,  5.00it/s] 12%|█▏        | 84/675 [00:16<01:58,  5.00it/s] 13%|█▎        | 85/675 [00:16<01:57,  5.00it/s] 13%|█▎        | 86/675 [00:17<01:57,  5.00it/s] 13%|█▎        | 87/675 [00:17<01:57,  5.00it/s] 13%|█▎        | 88/675 [00:17<01:57,  5.00it/s] 13%|█▎        | 89/675 [00:17<01:57,  5.00it/s] 13%|█▎        | 90/675 [00:17<01:57,  5.00it/s] 13%|█▎        | 91/675 [00:18<01:56,  5.00it/s] 14%|█▎        | 92/675 [00:18<01:56,  5.00it/s] 14%|█▍        | 93/675 [00:18<01:56,  5.00it/s] 14%|█▍        | 94/675 [00:18<01:56,  5.00it/s] 14%|█▍        | 95/675 [00:18<01:56,  5.00it/s] 14%|█▍        | 96/675 [00:19<01:55,  5.00it/s] 14%|█▍        | 97/675 [00:19<01:55,  5.00it/s] 15%|█▍        | 98/675 [00:19<01:55,  5.00it/s] 15%|█▍        | 99/675 [00:19<01:55,  5.00it/s] 15%|█▍        | 100/675 [00:19<01:55,  5.00it/s] 15%|█▍        | 101/675 [00:20<01:54,  5.00it/s] 15%|█▌        | 102/675 [00:20<01:54,  5.00it/s] 15%|█▌        | 103/675 [00:20<01:54,  5.00it/s] 15%|█▌        | 104/675 [00:20<01:54,  5.00it/s] 16%|█▌        | 105/675 [00:20<01:53,  5.00it/s] 16%|█▌        | 106/675 [00:21<01:53,  5.01it/s] 16%|█▌        | 107/675 [00:21<01:53,  5.00it/s] 16%|█▌        | 108/675 [00:21<01:53,  5.00it/s] 16%|█▌        | 109/675 [00:21<01:53,  5.00it/s] 16%|█▋        | 110/675 [00:21<01:53,  5.00it/s] 16%|█▋        | 111/675 [00:22<01:52,  5.00it/s] 17%|█▋        | 112/675 [00:22<01:52,  5.00it/s] 17%|█▋        | 113/675 [00:22<01:52,  5.00it/s] 17%|█▋        | 114/675 [00:22<01:52,  5.00it/s] 17%|█▋        | 115/675 [00:22<01:51,  5.00it/s] 17%|█▋        | 116/675 [00:23<01:51,  5.00it/s] 17%|█▋        | 117/675 [00:23<01:51,  5.00it/s] 17%|█▋        | 118/675 [00:23<01:51,  5.00it/s] 18%|█▊        | 119/675 [00:23<01:51,  5.00it/s] 18%|█▊        | 120/675 [00:23<01:50,  5.00it/s] 18%|█▊        | 121/675 [00:24<01:50,  5.00it/s] 18%|█▊        | 122/675 [00:24<01:50,  5.00it/s] 18%|█▊        | 123/675 [00:24<01:50,  5.00it/s] 18%|█▊        | 124/675 [00:24<01:50,  5.00it/s] 19%|█▊        | 125/675 [00:24<01:49,  5.00it/s] 19%|█▊        | 126/675 [00:25<01:49,  5.00it/s] 19%|█▉        | 127/675 [00:25<01:49,  5.00it/s] 19%|█▉        | 128/675 [00:25<01:49,  5.00it/s] 19%|█▉        | 129/675 [00:25<01:49,  5.00it/s] 19%|█▉        | 130/675 [00:25<01:48,  5.00it/s] 19%|█▉        | 131/675 [00:26<01:48,  5.00it/s] 20%|█▉        | 132/675 [00:26<01:48,  5.00it/s] 20%|█▉        | 133/675 [00:26<01:48,  5.00it/s] 20%|█▉        | 134/675 [00:26<01:48,  5.00it/s] 20%|██        | 135/675 [00:26<01:47,  5.00it/s] 20%|██        | 136/675 [00:27<01:47,  5.00it/s] 20%|██        | 137/675 [00:27<01:47,  5.00it/s] 20%|██        | 138/675 [00:27<01:47,  5.00it/s] 21%|██        | 139/675 [00:27<01:47,  5.00it/s] 21%|██        | 140/675 [00:27<01:46,  5.00it/s] 21%|██        | 141/675 [00:28<01:46,  5.00it/s] 21%|██        | 142/675 [00:28<01:46,  5.03it/s] 21%|██        | 143/675 [00:28<01:45,  5.03it/s] 21%|██▏       | 144/675 [00:28<01:45,  5.04it/s] 21%|██▏       | 145/675 [00:28<01:44,  5.06it/s] 22%|██▏       | 146/675 [00:29<01:43,  5.09it/s] 22%|██▏       | 147/675 [00:29<01:44,  5.07it/s] 22%|██▏       | 148/675 [00:29<01:44,  5.05it/s] 22%|██▏       | 149/675 [00:29<01:44,  5.04it/s] 22%|██▏       | 150/675 [00:29<01:44,  5.02it/s] 22%|██▏       | 151/675 [00:30<01:44,  5.02it/s] 23%|██▎       | 152/675 [00:30<01:44,  5.02it/s] 23%|██▎       | 153/675 [00:30<01:43,  5.02it/s] 23%|██▎       | 154/675 [00:30<01:43,  5.02it/s] 23%|██▎       | 155/675 [00:30<01:43,  5.02it/s] 23%|██▎       | 156/675 [00:31<01:43,  5.02it/s] 23%|██▎       | 157/675 [00:31<01:43,  5.02it/s] 23%|██▎       | 158/675 [00:31<01:42,  5.03it/s] 24%|██▎       | 159/675 [00:31<01:42,  5.04it/s] 24%|██▎       | 160/675 [00:31<01:41,  5.07it/s] 24%|██▍       | 161/675 [00:32<01:40,  5.09it/s] 24%|██▍       | 162/675 [00:32<01:41,  5.08it/s] 24%|██▍       | 163/675 [00:32<01:41,  5.06it/s] 24%|██▍       | 164/675 [00:32<01:41,  5.05it/s] 24%|██▍       | 165/675 [00:32<01:41,  5.04it/s] 25%|██▍       | 166/675 [00:33<01:41,  5.03it/s] 25%|██▍       | 167/675 [00:33<01:41,  5.03it/s] 25%|██▍       | 168/675 [00:33<01:40,  5.03it/s] 25%|██▌       | 169/675 [00:33<01:40,  5.04it/s] 25%|██▌       | 170/675 [00:33<01:39,  5.06it/s] 25%|██▌       | 171/675 [00:34<01:39,  5.08it/s] 25%|██▌       | 172/675 [00:34<01:39,  5.08it/s] 26%|██▌       | 173/675 [00:34<01:39,  5.06it/s] 26%|██▌       | 174/675 [00:34<01:39,  5.05it/s] 26%|██▌       | 175/675 [00:34<01:39,  5.04it/s] 26%|██▌       | 176/675 [00:35<01:39,  5.03it/s] 26%|██▌       | 177/675 [00:35<01:39,  5.03it/s] 26%|██▋       | 178/675 [00:35<01:38,  5.03it/s] 27%|██▋       | 179/675 [00:35<01:38,  5.03it/s] 27%|██▋       | 180/675 [00:35<01:38,  5.04it/s] 27%|██▋       | 181/675 [00:36<01:37,  5.06it/s] 27%|██▋       | 182/675 [00:36<01:36,  5.09it/s] 27%|██▋       | 183/675 [00:36<01:36,  5.08it/s] 27%|██▋       | 184/675 [00:36<01:37,  5.06it/s] 27%|██▋       | 185/675 [00:36<01:37,  5.05it/s] 28%|██▊       | 186/675 [00:37<01:37,  5.04it/s] 28%|██▊       | 187/675 [00:37<01:36,  5.04it/s] 28%|██▊       | 188/675 [00:37<01:36,  5.03it/s] 28%|██▊       | 189/675 [00:37<01:36,  5.03it/s] 28%|██▊       | 190/675 [00:37<01:36,  5.05it/s] 28%|██▊       | 191/675 [00:38<01:35,  5.08it/s] 28%|██▊       | 192/675 [00:38<01:34,  5.09it/s] 29%|██▊       | 193/675 [00:38<01:35,  5.07it/s] 29%|██▊       | 194/675 [00:38<01:35,  5.06it/s] 29%|██▉       | 195/675 [00:38<01:35,  5.04it/s] 29%|██▉       | 196/675 [00:39<01:35,  5.04it/s] 29%|██▉       | 197/675 [00:39<01:34,  5.04it/s] 29%|██▉       | 198/675 [00:39<01:34,  5.04it/s] 29%|██▉       | 199/675 [00:39<01:34,  5.06it/s] 30%|██▉       | 200/675 [00:39<01:33,  5.09it/s] 30%|██▉       | 201/675 [00:40<01:33,  5.09it/s] 30%|██▉       | 202/675 [00:40<01:33,  5.07it/s] 30%|███       | 203/675 [00:40<01:33,  5.06it/s] 30%|███       | 204/675 [00:40<01:33,  5.04it/s] 30%|███       | 205/675 [00:40<01:33,  5.03it/s] 31%|███       | 206/675 [00:41<01:33,  5.03it/s] 31%|███       | 207/675 [00:41<01:33,  5.02it/s] 31%|███       | 208/675 [00:41<01:32,  5.03it/s] 31%|███       | 209/675 [00:41<01:32,  5.03it/s] 31%|███       | 210/675 [00:41<01:32,  5.05it/s] 31%|███▏      | 211/675 [00:42<01:31,  5.08it/s] 31%|███▏      | 212/675 [00:42<01:31,  5.09it/s] 32%|███▏      | 213/675 [00:42<01:31,  5.07it/s] 32%|███▏      | 214/675 [00:42<01:31,  5.05it/s] 32%|███▏      | 215/675 [00:42<01:31,  5.04it/s] 32%|███▏      | 216/675 [00:43<01:31,  5.03it/s] 32%|███▏      | 217/675 [00:43<01:31,  5.03it/s] 32%|███▏      | 218/675 [00:43<01:30,  5.02it/s] 32%|███▏      | 219/675 [00:43<01:30,  5.02it/s] 33%|███▎      | 220/675 [00:43<01:30,  5.02it/s] 33%|███▎      | 221/675 [00:44<01:30,  5.03it/s] 33%|███▎      | 222/675 [00:44<01:29,  5.04it/s] 33%|███▎      | 223/675 [00:44<01:29,  5.07it/s] 33%|███▎      | 224/675 [00:44<01:28,  5.09it/s] 33%|███▎      | 225/675 [00:44<01:28,  5.07it/s] 33%|███▎      | 226/675 [00:44<01:28,  5.05it/s] 34%|███▎      | 227/675 [00:45<01:28,  5.04it/s] 34%|███▍      | 228/675 [00:45<01:28,  5.03it/s] 34%|███▍      | 229/675 [00:45<01:28,  5.02it/s] 34%|███▍      | 230/675 [00:45<01:28,  5.02it/s] 34%|███▍      | 231/675 [00:45<01:28,  5.01it/s] 34%|███▍      | 232/675 [00:46<01:28,  5.01it/s] 35%|███▍      | 233/675 [00:46<01:28,  5.01it/s] 35%|███▍      | 234/675 [00:46<01:28,  5.01it/s] 35%|███▍      | 235/675 [00:46<01:27,  5.01it/s] 35%|███▍      | 236/675 [00:46<01:27,  5.01it/s] 35%|███▌      | 237/675 [00:47<01:27,  5.01it/s] 35%|███▌      | 238/675 [00:47<01:27,  5.01it/s] 35%|███▌      | 239/675 [00:47<01:26,  5.01it/s] 36%|███▌      | 240/675 [00:47<01:26,  5.01it/s] 36%|███▌      | 241/675 [00:47<01:26,  5.01it/s] 36%|███▌      | 242/675 [00:48<01:26,  5.01it/s] 36%|███▌      | 243/675 [00:48<01:26,  5.02it/s] 36%|███▌      | 244/675 [00:48<01:25,  5.03it/s] 36%|███▋      | 245/675 [00:48<01:25,  5.06it/s] 36%|███▋      | 246/675 [00:48<01:24,  5.09it/s] 37%|███▋      | 247/675 [00:49<01:24,  5.08it/s] 37%|███▋      | 248/675 [00:49<01:24,  5.07it/s] 37%|███▋      | 249/675 [00:49<01:24,  5.06it/s] 37%|███▋      | 250/675 [00:49<01:23,  5.06it/s] 37%|███▋      | 251/675 [00:49<01:23,  5.08it/s] 37%|███▋      | 252/675 [00:50<01:22,  5.11it/s] 37%|███▋      | 253/675 [00:50<01:22,  5.09it/s] 38%|███▊      | 254/675 [00:50<01:22,  5.07it/s] 38%|███▊      | 255/675 [00:50<01:23,  5.06it/s] 38%|███▊      | 256/675 [00:50<01:23,  5.04it/s] 38%|███▊      | 257/675 [00:51<01:23,  5.03it/s] 38%|███▊      | 258/675 [00:51<01:22,  5.03it/s] 38%|███▊      | 259/675 [00:51<01:22,  5.03it/s] 39%|███▊      | 260/675 [00:51<01:22,  5.04it/s] 39%|███▊      | 261/675 [00:51<01:21,  5.06it/s] 39%|███▉      | 262/675 [00:52<01:21,  5.09it/s] 39%|███▉      | 263/675 [00:52<01:21,  5.08it/s] 39%|███▉      | 264/675 [00:52<01:21,  5.06it/s] 39%|███▉      | 265/675 [00:52<01:21,  5.05it/s] 39%|███▉      | 266/675 [00:52<01:21,  5.04it/s] 40%|███▉      | 267/675 [00:53<01:21,  5.03it/s] 40%|███▉      | 268/675 [00:53<01:20,  5.03it/s] 40%|███▉      | 269/675 [00:53<01:20,  5.03it/s] 40%|████      | 270/675 [00:53<01:20,  5.03it/s] 40%|████      | 271/675 [00:53<01:20,  5.03it/s] 40%|████      | 272/675 [00:54<01:19,  5.05it/s] 40%|████      | 273/675 [00:54<01:19,  5.07it/s] 41%|████      | 274/675 [00:54<01:18,  5.08it/s] 41%|████      | 275/675 [00:54<01:18,  5.06it/s] 41%|████      | 276/675 [00:54<01:18,  5.05it/s] 41%|████      | 277/675 [00:55<01:18,  5.04it/s] 41%|████      | 278/675 [00:55<01:18,  5.03it/s] 41%|████▏     | 279/675 [00:55<01:18,  5.03it/s] 41%|████▏     | 280/675 [00:55<01:18,  5.02it/s] 42%|████▏     | 281/675 [00:55<01:18,  5.02it/s] 42%|████▏     | 282/675 [00:56<01:18,  5.02it/s] 42%|████▏     | 283/675 [00:56<01:18,  5.02it/s] 42%|████▏     | 284/675 [00:56<01:17,  5.03it/s] 42%|████▏     | 285/675 [00:56<01:17,  5.04it/s] 42%|████▏     | 286/675 [00:56<01:16,  5.07it/s] 43%|████▎     | 287/675 [00:57<01:16,  5.09it/s] 43%|████▎     | 288/675 [00:57<01:16,  5.07it/s] 43%|████▎     | 289/675 [00:57<01:16,  5.05it/s] 43%|████▎     | 290/675 [00:57<01:16,  5.04it/s] 43%|████▎     | 291/675 [00:57<01:16,  5.03it/s] 43%|████▎     | 292/675 [00:58<01:16,  5.03it/s] 43%|████▎     | 293/675 [00:58<01:15,  5.03it/s] 44%|████▎     | 294/675 [00:58<01:15,  5.03it/s] 44%|████▎     | 295/675 [00:58<01:15,  5.04it/s] 44%|████▍     | 296/675 [00:58<01:14,  5.06it/s] 44%|████▍     | 297/675 [00:59<01:14,  5.08it/s] 44%|████▍     | 298/675 [00:59<01:14,  5.08it/s] 44%|████▍     | 299/675 [00:59<01:14,  5.07it/s] 44%|████▍     | 300/675 [00:59<01:14,  5.05it/s] 45%|████▍     | 301/675 [00:59<01:14,  5.04it/s] 45%|████▍     | 302/675 [01:00<01:14,  5.04it/s] 45%|████▍     | 303/675 [01:00<01:13,  5.03it/s] 45%|████▌     | 304/675 [01:00<01:13,  5.03it/s] 45%|████▌     | 305/675 [01:00<01:13,  5.05it/s] 45%|████▌     | 306/675 [01:00<01:12,  5.07it/s] 45%|████▌     | 307/675 [01:01<01:12,  5.08it/s] 46%|████▌     | 308/675 [01:01<01:12,  5.05it/s] 46%|████▌     | 309/675 [01:01<01:12,  5.03it/s] 46%|████▌     | 310/675 [01:01<01:12,  5.02it/s] 46%|████▌     | 311/675 [01:01<01:12,  5.02it/s] 46%|████▌     | 312/675 [01:02<01:12,  5.01it/s] 46%|████▋     | 313/675 [01:02<01:12,  5.01it/s] 47%|████▋     | 314/675 [01:02<01:12,  5.01it/s] 47%|████▋     | 315/675 [01:02<01:11,  5.01it/s] 47%|████▋     | 316/675 [01:02<01:11,  5.00it/s] 47%|████▋     | 317/675 [01:03<01:11,  5.00it/s] 47%|████▋     | 318/675 [01:03<01:11,  5.01it/s] 47%|████▋     | 319/675 [01:03<01:11,  5.00it/s] 47%|████▋     | 320/675 [01:03<01:10,  5.00it/s] 48%|████▊     | 321/675 [01:03<01:10,  5.00it/s] 48%|████▊     | 322/675 [01:04<01:10,  5.00it/s] 48%|████▊     | 323/675 [01:04<01:10,  5.00it/s] 48%|████▊     | 324/675 [01:04<01:10,  5.00it/s] 48%|████▊     | 325/675 [01:04<01:10,  5.00it/s] 48%|████▊     | 326/675 [01:04<01:09,  5.00it/s] 48%|████▊     | 327/675 [01:05<01:09,  5.00it/s] 49%|████▊     | 328/675 [01:05<01:09,  5.00it/s] 49%|████▊     | 329/675 [01:05<01:09,  5.00it/s] 49%|████▉     | 330/675 [01:05<01:08,  5.00it/s] 49%|████▉     | 331/675 [01:05<01:08,  5.00it/s] 49%|████▉     | 332/675 [01:06<01:08,  5.00it/s] 49%|████▉     | 333/675 [01:06<01:08,  5.00it/s] 49%|████▉     | 334/675 [01:06<01:08,  5.00it/s] 50%|████▉     | 335/675 [01:06<01:07,  5.00it/s] 50%|████▉     | 336/675 [01:06<01:07,  5.00it/s] 50%|████▉     | 337/675 [01:07<01:07,  5.00it/s] 50%|█████     | 338/675 [01:07<01:07,  5.00it/s] 50%|█████     | 339/675 [01:07<01:07,  5.00it/s] 50%|█████     | 340/675 [01:07<01:06,  5.00it/s] 51%|█████     | 341/675 [01:07<01:06,  5.00it/s] 51%|█████     | 342/675 [01:08<01:06,  5.00it/s] 51%|█████     | 343/675 [01:08<01:06,  5.00it/s] 51%|█████     | 344/675 [01:08<01:06,  5.00it/s] 51%|█████     | 345/675 [01:08<01:05,  5.00it/s] 51%|█████▏    | 346/675 [01:08<01:05,  5.00it/s] 51%|█████▏    | 347/675 [01:09<01:05,  5.00it/s] 52%|█████▏    | 348/675 [01:09<01:05,  5.00it/s] 52%|█████▏    | 349/675 [01:09<01:05,  5.00it/s] 52%|█████▏    | 350/675 [01:09<01:05,  5.00it/s] 52%|█████▏    | 351/675 [01:09<01:04,  5.00it/s] 52%|█████▏    | 352/675 [01:10<01:04,  5.00it/s] 52%|█████▏    | 353/675 [01:10<01:04,  5.00it/s] 52%|█████▏    | 354/675 [01:10<01:04,  5.00it/s] 53%|█████▎    | 355/675 [01:10<01:03,  5.00it/s] 53%|█████▎    | 356/675 [01:10<01:03,  5.00it/s] 53%|█████▎    | 357/675 [01:11<01:03,  5.01it/s] 53%|█████▎    | 358/675 [01:11<01:03,  5.00it/s] 53%|█████▎    | 359/675 [01:11<01:03,  5.00it/s] 53%|█████▎    | 360/675 [01:11<01:02,  5.00it/s] 53%|█████▎    | 361/675 [01:11<01:02,  5.00it/s] 54%|█████▎    | 362/675 [01:12<01:02,  5.00it/s] 54%|█████▍    | 363/675 [01:12<01:02,  5.00it/s] 54%|█████▍    | 364/675 [01:12<01:02,  5.00it/s] 54%|█████▍    | 365/675 [01:12<01:01,  5.00it/s] 54%|█████▍    | 366/675 [01:12<01:01,  5.00it/s] 54%|█████▍    | 367/675 [01:13<01:01,  5.00it/s] 55%|█████▍    | 368/675 [01:13<01:01,  5.00it/s] 55%|█████▍    | 369/675 [01:13<01:01,  5.00it/s] 55%|█████▍    | 370/675 [01:13<01:00,  5.00it/s] 55%|█████▍    | 371/675 [01:13<01:00,  5.00it/s] 55%|█████▌    | 372/675 [01:14<01:00,  5.00it/s] 55%|█████▌    | 373/675 [01:14<01:00,  5.00it/s] 55%|█████▌    | 374/675 [01:14<01:00,  5.01it/s] 56%|█████▌    | 375/675 [01:14<00:59,  5.00it/s] 56%|█████▌    | 376/675 [01:14<00:59,  5.00it/s] 56%|█████▌    | 377/675 [01:15<00:59,  5.00it/s] 56%|█████▌    | 378/675 [01:15<00:59,  5.00it/s] 56%|█████▌    | 379/675 [01:15<00:59,  5.00it/s] 56%|█████▋    | 380/675 [01:15<00:58,  5.00it/s] 56%|█████▋    | 381/675 [01:15<00:58,  5.00it/s] 57%|█████▋    | 382/675 [01:16<00:58,  5.00it/s] 57%|█████▋    | 383/675 [01:16<00:58,  5.00it/s] 57%|█████▋    | 384/675 [01:16<00:58,  5.00it/s] 57%|█████▋    | 385/675 [01:16<00:57,  5.00it/s] 57%|█████▋    | 386/675 [01:16<00:57,  5.00it/s] 57%|█████▋    | 387/675 [01:17<00:57,  5.00it/s] 57%|█████▋    | 388/675 [01:17<00:57,  5.00it/s] 58%|█████▊    | 389/675 [01:17<00:57,  5.00it/s] 58%|█████▊    | 390/675 [01:17<00:56,  5.00it/s] 58%|█████▊    | 391/675 [01:17<00:56,  5.00it/s] 58%|█████▊    | 392/675 [01:18<00:56,  5.00it/s] 58%|█████▊    | 393/675 [01:18<00:56,  5.00it/s] 58%|█████▊    | 394/675 [01:18<00:56,  5.00it/s] 59%|█████▊    | 395/675 [01:18<00:55,  5.00it/s] 59%|█████▊    | 396/675 [01:18<00:55,  5.00it/s] 59%|█████▉    | 397/675 [01:19<00:55,  5.00it/s] 59%|█████▉    | 398/675 [01:19<00:55,  5.00it/s] 59%|█████▉    | 399/675 [01:19<00:55,  5.00it/s] 59%|█████▉    | 400/675 [01:19<00:54,  5.00it/s] 59%|█████▉    | 401/675 [01:19<00:54,  5.00it/s] 60%|█████▉    | 402/675 [01:20<00:54,  5.00it/s] 60%|█████▉    | 403/675 [01:20<00:54,  5.01it/s] 60%|█████▉    | 404/675 [01:20<00:54,  5.00it/s] 60%|██████    | 405/675 [01:20<00:53,  5.00it/s] 60%|██████    | 406/675 [01:20<00:53,  5.00it/s] 60%|██████    | 407/675 [01:21<00:53,  5.00it/s] 60%|██████    | 408/675 [01:21<00:53,  5.00it/s] 61%|██████    | 409/675 [01:21<00:53,  5.00it/s] 61%|██████    | 410/675 [01:21<00:52,  5.00it/s] 61%|██████    | 411/675 [01:21<00:52,  5.00it/s] 61%|██████    | 412/675 [01:22<00:52,  5.00it/s] 61%|██████    | 413/675 [01:22<00:52,  5.00it/s] 61%|██████▏   | 414/675 [01:22<00:52,  5.00it/s] 61%|██████▏   | 415/675 [01:22<00:51,  5.00it/s] 62%|██████▏   | 416/675 [01:22<00:51,  5.00it/s] 62%|██████▏   | 417/675 [01:23<00:51,  5.00it/s] 62%|██████▏   | 418/675 [01:23<00:51,  5.00it/s] 62%|██████▏   | 419/675 [01:23<00:51,  5.00it/s] 62%|██████▏   | 420/675 [01:23<00:51,  5.00it/s] 62%|██████▏   | 421/675 [01:23<00:50,  5.00it/s] 63%|██████▎   | 422/675 [01:24<00:50,  5.00it/s] 63%|██████▎   | 423/675 [01:24<00:50,  5.00it/s] 63%|██████▎   | 424/675 [01:24<00:50,  5.00it/s] 63%|██████▎   | 425/675 [01:24<00:49,  5.00it/s] 63%|██████▎   | 426/675 [01:24<00:49,  5.00it/s] 63%|██████▎   | 427/675 [01:25<00:49,  5.00it/s] 63%|██████▎   | 428/675 [01:25<00:49,  5.00it/s] 64%|██████▎   | 429/675 [01:25<00:49,  5.00it/s] 64%|██████▎   | 430/675 [01:25<00:48,  5.00it/s] 64%|██████▍   | 431/675 [01:25<00:48,  5.00it/s] 64%|██████▍   | 432/675 [01:26<00:48,  5.00it/s] 64%|██████▍   | 433/675 [01:26<00:48,  5.00it/s] 64%|██████▍   | 434/675 [01:26<00:48,  5.00it/s] 64%|██████▍   | 435/675 [01:26<00:47,  5.00it/s] 65%|██████▍   | 436/675 [01:26<00:47,  5.00it/s] 65%|██████▍   | 437/675 [01:27<00:47,  5.00it/s] 65%|██████▍   | 438/675 [01:27<00:47,  5.00it/s] 65%|██████▌   | 439/675 [01:27<00:47,  5.00it/s] 65%|██████▌   | 440/675 [01:27<00:46,  5.00it/s] 65%|██████▌   | 441/675 [01:27<00:46,  5.00it/s] 65%|██████▌   | 442/675 [01:28<00:46,  5.00it/s] 66%|██████▌   | 443/675 [01:28<00:46,  5.00it/s] 66%|██████▌   | 444/675 [01:28<00:46,  5.00it/s] 66%|██████▌   | 445/675 [01:28<00:45,  5.00it/s] 66%|██████▌   | 446/675 [01:28<00:45,  5.00it/s] 66%|██████▌   | 447/675 [01:29<00:45,  5.00it/s] 66%|██████▋   | 448/675 [01:29<00:45,  5.00it/s] 67%|██████▋   | 449/675 [01:29<00:45,  5.00it/s] 67%|██████▋   | 450/675 [01:29<00:45,  5.00it/s] 67%|██████▋   | 451/675 [01:29<00:44,  5.00it/s] 67%|██████▋   | 452/675 [01:30<00:44,  5.00it/s] 67%|██████▋   | 453/675 [01:30<00:44,  5.00it/s] 67%|██████▋   | 454/675 [01:30<00:44,  5.00it/s] 67%|██████▋   | 455/675 [01:30<00:43,  5.00it/s] 68%|██████▊   | 456/675 [01:30<00:43,  5.00it/s] 68%|██████▊   | 457/675 [01:31<00:43,  5.00it/s] 68%|██████▊   | 458/675 [01:31<00:43,  5.00it/s] 68%|██████▊   | 459/675 [01:31<00:43,  5.00it/s] 68%|██████▊   | 460/675 [01:31<00:42,  5.00it/s] 68%|██████▊   | 461/675 [01:31<00:42,  5.00it/s] 68%|██████▊   | 462/675 [01:32<00:42,  5.00it/s] 69%|██████▊   | 463/675 [01:32<00:42,  5.00it/s] 69%|██████▊   | 464/675 [01:32<00:42,  5.00it/s] 69%|██████▉   | 465/675 [01:32<00:41,  5.00it/s] 69%|██████▉   | 466/675 [01:32<00:41,  5.00it/s] 69%|██████▉   | 467/675 [01:33<00:41,  5.00it/s] 69%|██████▉   | 468/675 [01:33<00:41,  5.00it/s] 69%|██████▉   | 469/675 [01:33<00:41,  5.00it/s] 70%|██████▉   | 470/675 [01:33<00:40,  5.00it/s] 70%|██████▉   | 471/675 [01:33<00:40,  5.00it/s] 70%|██████▉   | 472/675 [01:34<00:40,  5.00it/s] 70%|███████   | 473/675 [01:34<00:40,  5.00it/s] 70%|███████   | 474/675 [01:34<00:40,  5.00it/s] 70%|███████   | 475/675 [01:34<00:39,  5.00it/s] 71%|███████   | 476/675 [01:34<00:39,  5.00it/s] 71%|███████   | 477/675 [01:35<00:39,  5.00it/s] 71%|███████   | 478/675 [01:35<00:39,  5.00it/s] 71%|███████   | 479/675 [01:35<00:39,  5.00it/s] 71%|███████   | 480/675 [01:35<00:38,  5.00it/s] 71%|███████▏  | 481/675 [01:35<00:38,  5.00it/s] 71%|███████▏  | 482/675 [01:36<00:38,  5.00it/s] 72%|███████▏  | 483/675 [01:36<00:38,  5.00it/s] 72%|███████▏  | 484/675 [01:36<00:38,  5.00it/s] 72%|███████▏  | 485/675 [01:36<00:44,  4.25it/s] 72%|███████▏  | 486/675 [01:36<00:42,  4.44it/s] 72%|███████▏  | 487/675 [01:37<00:40,  4.59it/s] 72%|███████▏  | 488/675 [01:37<00:39,  4.71it/s] 72%|███████▏  | 489/675 [01:37<00:38,  4.79it/s] 73%|███████▎  | 490/675 [01:37<00:38,  4.85it/s] 73%|███████▎  | 491/675 [01:37<00:37,  4.90it/s] 73%|███████▎  | 492/675 [01:38<00:37,  4.93it/s] 73%|███████▎  | 493/675 [01:38<00:36,  4.95it/s] 73%|███████▎  | 494/675 [01:38<00:36,  4.97it/s] 73%|███████▎  | 495/675 [01:38<00:36,  4.98it/s] 73%|███████▎  | 496/675 [01:38<00:35,  4.98it/s] 74%|███████▎  | 497/675 [01:39<00:35,  4.99it/s] 74%|███████▍  | 498/675 [01:39<00:35,  4.99it/s] 74%|███████▍  | 499/675 [01:39<00:35,  4.99it/s] 74%|███████▍  | 500/675 [01:39<00:35,  5.00it/s] 74%|███████▍  | 501/675 [01:39<00:34,  5.00it/s] 74%|███████▍  | 502/675 [01:40<00:34,  5.00it/s] 75%|███████▍  | 503/675 [01:40<00:34,  5.00it/s] 75%|███████▍  | 504/675 [01:40<00:34,  5.00it/s] 75%|███████▍  | 505/675 [01:40<00:33,  5.00it/s] 75%|███████▍  | 506/675 [01:40<00:33,  5.00it/s] 75%|███████▌  | 507/675 [01:41<00:33,  5.00it/s] 75%|███████▌  | 508/675 [01:41<00:33,  5.00it/s] 75%|███████▌  | 509/675 [01:41<00:33,  5.00it/s] 76%|███████▌  | 510/675 [01:41<00:32,  5.00it/s] 76%|███████▌  | 511/675 [01:41<00:32,  5.00it/s] 76%|███████▌  | 512/675 [01:42<00:32,  5.00it/s] 76%|███████▌  | 513/675 [01:42<00:32,  5.00it/s] 76%|███████▌  | 514/675 [01:42<00:32,  5.00it/s] 76%|███████▋  | 515/675 [01:42<00:31,  5.00it/s] 76%|███████▋  | 516/675 [01:42<00:31,  5.00it/s] 77%|███████▋  | 517/675 [01:43<00:31,  5.00it/s] 77%|███████▋  | 518/675 [01:43<00:31,  5.00it/s] 77%|███████▋  | 519/675 [01:43<00:31,  5.00it/s] 77%|███████▋  | 520/675 [01:43<00:30,  5.00it/s] 77%|███████▋  | 521/675 [01:43<00:30,  5.00it/s] 77%|███████▋  | 522/675 [01:44<00:30,  5.00it/s] 77%|███████▋  | 523/675 [01:44<00:30,  5.00it/s] 78%|███████▊  | 524/675 [01:44<00:30,  5.00it/s] 78%|███████▊  | 525/675 [01:44<00:29,  5.00it/s] 78%|███████▊  | 526/675 [01:44<00:29,  5.00it/s] 78%|███████▊  | 527/675 [01:45<00:29,  5.00it/s] 78%|███████▊  | 528/675 [01:45<00:29,  5.00it/s] 78%|███████▊  | 529/675 [01:45<00:29,  5.00it/s] 79%|███████▊  | 530/675 [01:45<00:28,  5.00it/s] 79%|███████▊  | 531/675 [01:45<00:28,  5.00it/s] 79%|███████▉  | 532/675 [01:46<00:28,  5.00it/s] 79%|███████▉  | 533/675 [01:46<00:28,  5.00it/s] 79%|███████▉  | 534/675 [01:46<00:28,  5.00it/s] 79%|███████▉  | 535/675 [01:46<00:28,  5.00it/s] 79%|███████▉  | 536/675 [01:46<00:27,  5.00it/s] 80%|███████▉  | 537/675 [01:47<00:27,  5.00it/s] 80%|███████▉  | 538/675 [01:47<00:27,  5.00it/s] 80%|███████▉  | 539/675 [01:47<00:27,  5.00it/s] 80%|████████  | 540/675 [01:47<00:26,  5.00it/s] 80%|████████  | 541/675 [01:47<00:26,  5.00it/s] 80%|████████  | 542/675 [01:48<00:26,  5.00it/s] 80%|████████  | 543/675 [01:48<00:26,  5.00it/s] 81%|████████  | 544/675 [01:48<00:26,  5.00it/s] 81%|████████  | 545/675 [01:48<00:25,  5.00it/s] 81%|████████  | 546/675 [01:48<00:25,  5.00it/s] 81%|████████  | 547/675 [01:49<00:25,  5.00it/s] 81%|████████  | 548/675 [01:49<00:25,  5.00it/s] 81%|████████▏ | 549/675 [01:49<00:25,  5.00it/s] 81%|████████▏ | 550/675 [01:49<00:24,  5.01it/s] 82%|████████▏ | 551/675 [01:49<00:24,  5.00it/s] 82%|████████▏ | 552/675 [01:50<00:24,  5.00it/s] 82%|████████▏ | 553/675 [01:50<00:24,  5.00it/s] 82%|████████▏ | 554/675 [01:50<00:24,  5.00it/s] 82%|████████▏ | 555/675 [01:50<00:23,  5.00it/s] 82%|████████▏ | 556/675 [01:50<00:23,  5.00it/s] 83%|████████▎ | 557/675 [01:51<00:23,  5.00it/s] 83%|████████▎ | 558/675 [01:51<00:23,  5.00it/s] 83%|████████▎ | 559/675 [01:51<00:23,  5.00it/s] 83%|████████▎ | 560/675 [01:51<00:22,  5.00it/s] 83%|████████▎ | 561/675 [01:51<00:22,  5.00it/s] 83%|████████▎ | 562/675 [01:52<00:22,  5.00it/s] 83%|████████▎ | 563/675 [01:52<00:22,  5.00it/s] 84%|████████▎ | 564/675 [01:52<00:22,  5.00it/s] 84%|████████▎ | 565/675 [01:52<00:21,  5.00it/s] 84%|████████▍ | 566/675 [01:52<00:21,  5.00it/s] 84%|████████▍ | 567/675 [01:53<00:21,  5.00it/s] 84%|████████▍ | 568/675 [01:53<00:21,  5.00it/s] 84%|████████▍ | 569/675 [01:53<00:21,  5.00it/s] 84%|████████▍ | 570/675 [01:53<00:20,  5.00it/s] 85%|████████▍ | 571/675 [01:53<00:20,  5.00it/s] 85%|████████▍ | 572/675 [01:54<00:20,  5.00it/s] 85%|████████▍ | 573/675 [01:54<00:20,  5.00it/s] 85%|████████▌ | 574/675 [01:54<00:20,  5.00it/s] 85%|████████▌ | 575/675 [01:54<00:19,  5.00it/s] 85%|████████▌ | 576/675 [01:54<00:19,  5.00it/s] 85%|████████▌ | 577/675 [01:55<00:19,  5.00it/s] 86%|████████▌ | 578/675 [01:55<00:19,  5.00it/s] 86%|████████▌ | 579/675 [01:55<00:19,  5.00it/s] 86%|████████▌ | 580/675 [01:55<00:18,  5.00it/s] 86%|████████▌ | 581/675 [01:55<00:18,  5.00it/s] 86%|████████▌ | 582/675 [01:56<00:18,  5.00it/s] 86%|████████▋ | 583/675 [01:56<00:18,  5.00it/s] 87%|████████▋ | 584/675 [01:56<00:18,  5.00it/s] 87%|████████▋ | 585/675 [01:56<00:17,  5.00it/s] 87%|████████▋ | 586/675 [01:56<00:17,  5.00it/s] 87%|████████▋ | 587/675 [01:57<00:17,  5.00it/s] 87%|████████▋ | 588/675 [01:57<00:17,  5.00it/s] 87%|████████▋ | 589/675 [01:57<00:17,  5.00it/s] 87%|████████▋ | 590/675 [01:57<00:16,  5.00it/s] 88%|████████▊ | 591/675 [01:57<00:16,  5.00it/s] 88%|████████▊ | 592/675 [01:58<00:16,  5.00it/s] 88%|████████▊ | 593/675 [01:58<00:16,  5.00it/s] 88%|████████▊ | 594/675 [01:58<00:16,  5.01it/s] 88%|████████▊ | 595/675 [01:58<00:15,  5.01it/s] 88%|████████▊ | 596/675 [01:58<00:15,  5.00it/s] 88%|████████▊ | 597/675 [01:59<00:15,  5.00it/s] 89%|████████▊ | 598/675 [01:59<00:15,  5.00it/s] 89%|████████▊ | 599/675 [01:59<00:15,  5.00it/s] 89%|████████▉ | 600/675 [01:59<00:14,  5.00it/s] 89%|████████▉ | 601/675 [01:59<00:14,  5.00it/s] 89%|████████▉ | 602/675 [02:00<00:14,  5.00it/s] 89%|████████▉ | 603/675 [02:00<00:14,  5.00it/s] 89%|████████▉ | 604/675 [02:00<00:14,  5.00it/s] 90%|████████▉ | 605/675 [02:00<00:13,  5.00it/s] 90%|████████▉ | 606/675 [02:00<00:13,  5.00it/s] 90%|████████▉ | 607/675 [02:01<00:13,  5.00it/s] 90%|█████████ | 608/675 [02:01<00:13,  5.00it/s] 90%|█████████ | 609/675 [02:01<00:13,  5.00it/s] 90%|█████████ | 610/675 [02:01<00:12,  5.00it/s] 91%|█████████ | 611/675 [02:01<00:12,  5.00it/s] 91%|█████████ | 612/675 [02:02<00:12,  5.00it/s] 91%|█████████ | 613/675 [02:02<00:12,  5.00it/s] 91%|█████████ | 614/675 [02:02<00:12,  5.00it/s] 91%|█████████ | 615/675 [02:02<00:11,  5.00it/s] 91%|█████████▏| 616/675 [02:02<00:11,  5.00it/s] 91%|█████████▏| 617/675 [02:03<00:11,  5.00it/s] 92%|█████████▏| 618/675 [02:03<00:11,  5.00it/s] 92%|█████████▏| 619/675 [02:03<00:11,  5.00it/s] 92%|█████████▏| 620/675 [02:03<00:10,  5.00it/s] 92%|█████████▏| 621/675 [02:03<00:10,  5.00it/s] 92%|█████████▏| 622/675 [02:04<00:10,  5.00it/s] 92%|█████████▏| 623/675 [02:04<00:10,  5.00it/s] 92%|█████████▏| 624/675 [02:04<00:10,  5.00it/s] 93%|█████████▎| 625/675 [02:04<00:09,  5.00it/s] 93%|█████████▎| 626/675 [02:04<00:09,  5.00it/s] 93%|█████████▎| 627/675 [02:05<00:09,  5.00it/s] 93%|█████████▎| 628/675 [02:05<00:09,  5.00it/s] 93%|█████████▎| 629/675 [02:05<00:09,  5.00it/s] 93%|█████████▎| 630/675 [02:05<00:08,  5.00it/s] 93%|█████████▎| 631/675 [02:05<00:08,  5.00it/s] 94%|█████████▎| 632/675 [02:06<00:08,  5.00it/s] 94%|█████████▍| 633/675 [02:06<00:08,  5.00it/s] 94%|█████████▍| 634/675 [02:06<00:08,  5.00it/s] 94%|█████████▍| 635/675 [02:06<00:07,  5.00it/s] 94%|█████████▍| 636/675 [02:06<00:07,  5.00it/s] 94%|█████████▍| 637/675 [02:07<00:07,  5.00it/s] 95%|█████████▍| 638/675 [02:07<00:07,  5.00it/s] 95%|█████████▍| 639/675 [02:07<00:07,  5.00it/s] 95%|█████████▍| 640/675 [02:07<00:06,  5.00it/s] 95%|█████████▍| 641/675 [02:07<00:06,  5.00it/s] 95%|█████████▌| 642/675 [02:08<00:06,  5.00it/s] 95%|█████████▌| 643/675 [02:08<00:06,  5.00it/s] 95%|█████████▌| 644/675 [02:08<00:06,  5.00it/s] 96%|█████████▌| 645/675 [02:08<00:05,  5.00it/s] 96%|█████████▌| 646/675 [02:08<00:05,  5.00it/s] 96%|█████████▌| 647/675 [02:09<00:05,  5.00it/s] 96%|█████████▌| 648/675 [02:09<00:05,  5.00it/s] 96%|█████████▌| 649/675 [02:09<00:05,  5.00it/s] 96%|█████████▋| 650/675 [02:09<00:04,  5.00it/s] 96%|█████████▋| 651/675 [02:09<00:04,  5.00it/s] 97%|█████████▋| 652/675 [02:10<00:04,  5.00it/s] 97%|█████████▋| 653/675 [02:10<00:04,  5.00it/s] 97%|█████████▋| 654/675 [02:10<00:04,  5.00it/s] 97%|█████████▋| 655/675 [02:10<00:03,  5.00it/s] 97%|█████████▋| 656/675 [02:10<00:03,  5.00it/s] 97%|█████████▋| 657/675 [02:11<00:03,  5.00it/s] 97%|█████████▋| 658/675 [02:11<00:03,  5.00it/s] 98%|█████████▊| 659/675 [02:11<00:03,  5.00it/s] 98%|█████████▊| 660/675 [02:11<00:02,  5.00it/s] 98%|█████████▊| 661/675 [02:11<00:02,  5.00it/s] 98%|█████████▊| 662/675 [02:12<00:02,  5.00it/s] 98%|█████████▊| 663/675 [02:12<00:02,  5.00it/s] 98%|█████████▊| 664/675 [02:12<00:02,  5.00it/s] 99%|█████████▊| 665/675 [02:12<00:01,  5.00it/s] 99%|█████████▊| 666/675 [02:12<00:01,  5.00it/s] 99%|█████████▉| 667/675 [02:13<00:01,  5.00it/s] 99%|█████████▉| 668/675 [02:13<00:01,  5.00it/s] 99%|█████████▉| 669/675 [02:13<00:01,  5.00it/s] 99%|█████████▉| 670/675 [02:13<00:00,  5.00it/s] 99%|█████████▉| 671/675 [02:13<00:00,  5.00it/s]100%|█████████▉| 672/675 [02:14<00:00,  5.00it/s]100%|█████████▉| 673/675 [02:14<00:00,  5.00it/s]100%|█████████▉| 674/675 [02:14<00:00,  5.00it/s]100%|██████████| 675/675 [02:14<00:00,  5.65it/s]100%|██████████| 675/675 [02:14<00:00,  5.01it/s]
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"Thresh_{i}"] = epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"Thresh_{i}"] = epsilon
Running POT with q=0.001, level=0.995..
Initial threshold : 0.093486935
Number of peaks : 3922
Grimshaw maximum log-likelihood estimation ... [done]
	γ = -0.018511971458792686
	σ = 0.021121047422428617
	L = 11279.66109710831
Extreme quantile (probability = 0.001): 0.12697669398167294
  0%|          | 0/172701 [00:00<?, ?it/s]100%|██████████| 172701/172701 [00:00<00:00, 5436672.48it/s]
0
172701
Finding best f1-score by searching for threshold..
Results using epsilon method:
 {'f1': 0.16147783903252044, 'precision': 0.0878311163462686, 'recall': 0.9999999989976948, 'TP': 9977, 'TN': 59108, 'FP': 103616, 'FN': 0, 'ROC/AUC': 0.6816204124775693, 'threshold': 0.06526202475652099, 'latency': 38.571153063192405, 'reg_level': 0}
Results using peak-over-threshold method:
 {'f1': 0.16789638906865326, 'precision': 0.09225187357822952, 'recall': 0.9327453132878167, 'TP': 9306, 'TN': 71154, 'FP': 91570, 'FN': 671, 'ROC/AUC': 0.6850066631584051, 'threshold': 0.12697669398167297, 'latency': 73.76866331797447}
Results using best f1 score search:
 {'f1': 0.168026744710681, 'precision': 0.09233058834285836, 'recall': 0.9327453132878167, 'TP': 9306, 'TN': 71240, 'FP': 91484, 'FN': 671, 'ROC/AUC': 0.6852709142830087, 'threshold': 0.12940000000000002, 'latency': 85.46088107014562}
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:188: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df["A_True_Global"] = true_anomalies
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:189: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df["Thresh_Global"] = global_epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df["Thresh_Global"] = global_epsilon
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  train_pred_df[f"A_Pred_Global"] = (train_anomaly_scores >= global_epsilon).astype(int)
/home/alexey/School/Research/submodules/mtad-gat-pytorch/prediction.py:196: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  test_pred_df[f"A_Pred_Global"] = test_preds_global
Saving output to output/mypkg_WADI/01052024_131325/<train/test>_output.pkl
-- Done.
